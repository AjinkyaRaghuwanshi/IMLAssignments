{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SHALAAssignment5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjinkyaRaghuwanshi/IMLAssignments/blob/master/SHALAAssignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lnS8bdSWnuK",
        "colab_type": "text"
      },
      "source": [
        "# **Assignment 1** (Intro to Machine Learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0_VaZIOWzut",
        "colab_type": "text"
      },
      "source": [
        "## Note:\n",
        "\n",
        "* The dataset to be used is `attrition.csv`. This dataset reveals whether a particular employee left the company or not.  \n",
        "* In this dataset, the column named `Attrition` is the target variable and the remaining columns are features. Please note that `Attrition = 1` means the employee left the company, whereas `Attrition = 0` means the opposite of this statement. \n",
        "*  This dataset has been loaded in this assignment as shown below. In case, you are not able to load this data, please note that this data is stored separately as well in the assignment folder. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bF8pLu6VdCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ABlrvQjXFgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_url = \"https://raw.githubusercontent.com/shala2020/shala2020.github.io/master/Lecture_Materials/Assignments/MachineLearning/L1/attrition.csv\"\n",
        "attrition_data = pd.read_csv(data_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljGWG-REXpeg",
        "colab_type": "code",
        "outputId": "c5c6e144-767a-4c11-e07d-564745d431a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "attrition_data.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EmployeeCount</th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobRole</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>OverTime</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1102</td>\n",
              "      <td>Sales</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Female</td>\n",
              "      <td>94</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Sales Executive</td>\n",
              "      <td>4</td>\n",
              "      <td>Single</td>\n",
              "      <td>5993</td>\n",
              "      <td>19479</td>\n",
              "      <td>8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>279</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Male</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Research Scientist</td>\n",
              "      <td>2</td>\n",
              "      <td>Married</td>\n",
              "      <td>5130</td>\n",
              "      <td>24907</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1373</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Other</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Male</td>\n",
              "      <td>92</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>3</td>\n",
              "      <td>Single</td>\n",
              "      <td>2090</td>\n",
              "      <td>2396</td>\n",
              "      <td>6</td>\n",
              "      <td>Yes</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>1392</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>Female</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Research Scientist</td>\n",
              "      <td>3</td>\n",
              "      <td>Married</td>\n",
              "      <td>2909</td>\n",
              "      <td>23159</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>591</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>2</td>\n",
              "      <td>Married</td>\n",
              "      <td>3468</td>\n",
              "      <td>16632</td>\n",
              "      <td>9</td>\n",
              "      <td>No</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age  Attrition  ... YearsWithCurrManager  ID\n",
              "0   41          1  ...                    5   0\n",
              "1   49          0  ...                    7   1\n",
              "2   37          1  ...                    0   2\n",
              "3   33          0  ...                    0   3\n",
              "4   27          0  ...                    2   4\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LvrYTtpIKXK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ed81c1a-14a6-43d0-f593-14b1f2fdee38"
      },
      "source": [
        "attrition_data.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1028, 34)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiByk21xYXod",
        "colab_type": "text"
      },
      "source": [
        "## Instructions:\n",
        "\n",
        "* You are required to use a classifier, which can predict the `Attrition` for the employees. \n",
        "* Before implementing any model, you will have to apply suitable encoding to the features and implement exploratory data analysis to know your data better. \n",
        "* You can either define your own custom-made classifer or select classifier(s) available in the `scikit-learn`.\n",
        "* You are supposed to implement a minimum of three classifiers (e.g.  `RandomForestClassifier`, `XGBClassifier`, `DecisionTreeClassifier`, `KNeighborsClassifier`, etc.) and evaluate which one is giving the best peformance. \n",
        "* For each of the classifier,  report the accuracy, precision, recall, roc curve, etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFMp-MZ2IBrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "atc = attrition_data.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYMvmU2TI1FA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "f85e01b6-3de8-49d9-e683-a89615651961"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(atc)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd1e61634a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAAFvCAYAAAD6wZqgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd5xdVdW/n28mkw4JJbQABmnSklClSxfeF8ECIqIIKCgKiv7AyquADUQs9CYdaQICgoCUANKSUNIgtBCE0AwlkJA2M+v3x943OZnMzF0zcydz72Q9+ZxP7jlnnXX2OffOXXfvs9f6yswIgiAIgqB99OruBgRBEARBLRIBNAiCIAg6QATQIAiCIOgAEUCDIAiCoANEAA2CIAiCDhABNAiCIAg6QATQIAiCoEcj6RJJb0ua1Mp+STpT0ouSJkjawuM3AmgQBEHQ07kM2LuN/fsA6+flKOA8j9MIoEEQBEGPxsweBN5tw2R/4ApLPAYMkbR6Ob8RQIMgCIJlnWHAq4X11/K2NundZc0JljqSPgvcDGxkZlMq7X/BjKll6z4OHLazy9e2K2/ospvVNM9l9+m+a7vsAH477a9lbXYYtpvL18BefVx2c5oWuOwGOP1dutbcsjb7vdzg8vX3tetddl+Z7vu9fXTjqi6703jFZddgjS67dfqs5LJ7t3GOy+7Oo8t2QADY47zpLru5jfNddj/V8LI2U3wfE3cPaZ58dvcueMPpER6efp/Ta8t4vm9K9Bm67jdJQ68lLjSzCztzfg8RQHsWBwP/zv//opvbEgRB0HGafD+cAHKw7EzAnA6sVVhfM29rkxjC7SFIGgTsCHwd+FLe1kvSuZKmSPqXpDskHZD3bSnpAUlPSLrLM94fBEGw1LAm/9J5bgUOzbNxtwVmmlnZ7nb0QHsO+wN3mtnzkt6RtCWwDjAc2BhYBXgWuERSPXAWsL+Z/VfSQcCvgSO6p+lBEATNaKpIYARA0jXALsDKkl4jjdDVA5jZ+cAdwP8ALwIfAYd7/EYA7TkcDPw5v742r/cGbjCzJuBNSffn/RsCmwL/kgRQB7T4a0vSUeRnC+ee8Su+cejBXXYBQRAEJazR9wzf5cuszS8uS7qe32mv3wigPQBJKwK7AZtJMlJANNKEohYPASab2XblfBefLbTnoX4QBEGnqMzQbJcSz0B7BgcAV5rZx8xsuJmtBbxMynv6Qn4WuippCAPgOWCopO0AJNVL2qQ7Gh4EQdAiTY3+pZuIHmjP4GDgtGbbbgQ2IuUzPUPKcXqS9HB8fp5MdKakwaTPwZ+AyW2dxJOiMnv6g64Gj9j4Sz67/mu47G6bM9VlB/Bbh00/+f40npzpO+/wgb7UjrHvvODz93b5X+dDBwx2+Vp3/Acuux1X3shl95fe77jsBjb1ddk14Rv4eH7u2y67qR/4UjEGn+LLBNt4RV8K1RxnGss35jzmspvXUD41asMha7p8vfjB6y67bVfcwGVXEWqgBxoBtAdgZru2sO1MSLNzzWyWpJWAMcDEvP9pwJe0GQRBVeEJnjVPBScRdRURQHs+/5A0BOgD/NLM3uzuBgVBEJTDogcadDdmtkt3tyEIgqDdVHAWblcRATQIgiCoPrpxcpCXCKBBEARB9RFDuEEQBEHQAWISURAEQRB0gOiBBj0JjwSZN79zwjPXuuz2GvVNl505cwW9TJs7w2W36fK+HMA6Z82SPVcZ4bJ73yHJ1beX78+7YaDvWdNbC3z5oqvWL++y87YvVVkrT/86n8bXbkM3ddktwPcF7pWq8+aBrjVwqMtuhd4Dy9q81zDb5Wvd5X1aEt6/i4pQAz3QqETUBUhqlPS0pMmSxkv6f5LavNeS1pD0t/x6F0n/KGN/kqTp+TzPSCpbpFbScZIGtO9qgiCoNjzBs9axpgXupbuIANo1zDGzUWa2CbAnsA9l9DnN7HUzO6Cd5/mjmY0iKbFckFVW2uI4IAJoEATVT1OTf+kmIoB2MWb2NknN5JisNTdc0kOSnszL9gB5+6TisbmG7QuShhbWXyytF87xAkmCZ4Vsd56kcbkHfHLe9l1gDeD+kiqLpL0kPZrbcUPWFA2CIOh+lq4eaIeIALoUMLOpJIWUVYC3gT3NbAvgIODMNo5rAq4CDsmb9gDGm9l/i3aStgBeyMEa4GdmthUwAviUpBG5tN/rwK5mtquklYETgT1yW8YBP6jMFQdBEHSSKCYftEA9cLakUUAjUK468yXALaRi70cAlxb2fV/S4dnHZwrbv5h1PHsDq5MEtSc087tt3v5w1gTtAzza/ORFPdD1Bm/I6gOHOS4xCIKgk8Qs3ABA0sdJwfJt0rPQt4CRpBGAuW0da2avSnpL0m7ANizqjUJ6Bvp7SfsBf5G0LilgHg9sbWbvSboM6NdSs4B/OYRmF+qB7jxs99ADDYJg6VADpfxiCLeLyc8rzwfOzqrng4E38vDsV0lDu+W4mDSUe4OZLTFeYWa3koZgvwYsD8wGZmYN0H0Kph8Cy+XXjwE7SFovt3OgpKWoVRQEQdAGNTCJKHqgXUN/SU+ThmsbgCuBP+R95wI3SjoUuJMU7MpxK2no9tI2bE4B/krSAH0KmELSAH24YHMhcKek1/Nz0MOAaySVhBlPBJ5v7QSzmuaVbahXv9Ob33n30xe47HYfeaTLzssafVdw2X3Q2OYAwkKG1Q/pTHOWYJbjvE349Dbfd+YKrlbv0xed6chRBVipt2/Omsk38DGwl+96vbzrvC99nNqxveX5rQz1DrtZjXPp26vcpHsYUOe7J72Qy25w36U4ib8G8kAjgHYBZtbqX0CeMVvMlv9R3j4N2DS/Hg2MLtiMJE0eWqjwa2YnNfP7BFCqdHBYK+c+CzirsH4fsHWbFxMEQdXhCZ61TguDbVVHBNAqR9KPgaNZ/NlnEARBzyZ6oEFnMbNTgVO7ux1BEARLlZiFGwRBEAQdoAZm4UYADYIgCKqPGMINgiAIgg4QQ7hBEARB0AGiBxr0JD7dt7z25W1zprp8efU7vfmd946/yGXnpcGpBenNPfTk0II/H2+Tvqu67F5ueL+szeb9fOUZn5o73WW3Y3+fRuoT89502c0337OwIXW+HMX3m3y5u1v39WlkPjr3NZfd0PrlyhsBK9T1d9nVt62QCOD8FEO9s6bOfxpmOj1WgBoIoFGJqIIUdEBLy49bsCmr9dmB8+5SUnXJ69/KhRqCZRhP8AxqE0/wrHlqQI0leqCVZU7W51za7ALMAh4BMLPzu6ENQRAElaPCs3Al7Q38mVQ+9eKcIljcvzZwOTAk2/zYzO5oy+cy8DOm+5G0t6Qpkp4EPl/YfpKk4wvrkyQNz68PlTRB0nhJV+Ztn5H0uKSnJN0jadVs/y2SMsvTknYq+pU0StJj2dfNkkqaoaMlnSZpjKTnJe20lG5HEARBeSpYC1dSHXAOqTb4xsDBkjZuZnYicL2ZbQ58iVR2tU0igFaW/s2GcA+S1A+4iCQ3tiWwWjknkjYhvZm7mdlI4Ht517+BbfMbfC3ww1wC8HySMssoM3uombsrgB+Z2QhgIkkNpkRvM9sGOK7Z9iAIgu6lskO42wAvmtlUM5tP+v7cv/kZSWIckEQ/Xi/nNIZwK8sSQ7hZ9/PlXAMXSVeR9TXbYDeS8soMADN7N29fE7hO0uok/c6X23IiaTAwxMweyJsuB24omNyU/38CGN6Kj4V6oHuvuDWjlluvTNODIAgqQGUnEQ0jiWuUeA34ZDObk4C7JR0LDAT2KOc0eqDdSwOLvwct6XYWOYski7YZ8E2HfTlKU0MbaeXHlJldaGZbmdlWETyDIFhqtGMIV9JRksYVlnKdlJY4GLjMzNYE/ge4Ump7tlYE0K5nCjA8i11DepNKTAO2AJC0BbBO3n4fcKCklfK+FfP2wUApl+BrBT9Fnc+FmNlM4L3C882vAg80twuCIKg6GhvdS/GHfl4ubOZtOrBWYX1NFn2Xlvg6cD2AmT1K6qCs3FYTI4BWlubPQE81s7mkIdDb8ySitwv2NwIrSpoMHEPW4jSzycCvgQckjWeRluhJwA2SngBmFPzcBnyuNImoWZu+BpwuaQIwiqQbGgRBUN1UVlB7LLC+pHUk9SFNErq1mc1/gN0BJG1ECqD/bcupzHwJ7UEAzuoHQRAEOKuCtMKcq37m/r7p/5Vflz2XpP8B/kRKUbnEzH4t6RRgnJndmmflXgQMIn3X/dDM7m7LZ0wiCoIgCKqPClciyjmddzTb9vPC62eAHdrjMwJoEARBUH3UwOhoBNAgCIKg+qiBWrgRQIMgCILqIwS1gyAIgqD9WFMM4QZBEARB+4kh3CAIgiDoAN0oU+YlAmjgZodhu5W16SffR2ra3BnljYA1+q7gsvMKYAM8Ov3+sjYLZviEwffZ/GiXnTff+iNb4LIb2KtPWZs35/vEj4f18d3jOU3zXXaNznThdxZ86LLzMqthjstuwwFruOwanZ+puU2+Z3We9wxggTWWtfHeY69A+zynaPnDEy512QHUr/xxt22L1MAQbs1VIvKIVnfQ7zRJbZZtqhT5XDcW1g+QdFmFfC8mkRYEQVCTNDT4l26iFnug3SVaXWm2lLRxTt6tCiSJVJ2q+sdOgiDo2dRAHmjN9UBbI/fqfpt7peMkbSHpLkkvSfpWttlF0oOSbpf0nKTzW6q2L+kHWdx6kqTj8rZTSq/z+q8lfS+/PkHS2CxafXLB5itZsPppSRdkUdcSZwA/a+HcLYps52WKpMuyAPbVkvaQ9LCkFyRtU3AzUtKjefuRBV9LtDP7fU7SFcAkFi+4HARB0D1UthZul1CLAXQJ0erCvv/k3ulDwGXAAcC2wMkFm22AY0mq5OsCny86l7QlcDhJK25b4EhJmwOXAIdmm16kYsRXSdoLWD/7HUXqWe6cixEfBOyQ29QIHFI41fXAFpLaoxG2HinwfiIvXwZ2BI4HflqwG0HSFN0O+LmkNVprZ7ZfHzjXzDYxs1ea3Y+FMkFvzi6rLxsEQVAZmsy/dBM9bQi3VF1/IjDIzD4EPpQ0T9KQvG+MmU0FkHQNKQD9reBjR+BmM5udbW4CdjKzMyW9k4PpqsBTZvZODkx7AU/l4weRAtIIYEtgbBoZpT+LK7E0AqcDPwH+6bz2l81sYm7XZOBeMzNJE1lcEPsWM5sDzJF0Pylo7thKO/8DvGJmj7V0wiwLdCHADsN2q/4xlSAIegY18CSpFgNoW5QEopsKr0vrpWttHgTaExQuBg4DViP1SCEpDvzWzC4oGiqpml9uZj9pw9+VpAA6qbCtLZHt5tdUvN7ie9nSNbbWzuHA7DbaGARBsPSJWbhVyTZZE64XaYj13832PwR8VtIASQOBz+VtADcDewNbA3flbXcBR0gaBCBpmKRVgHuBA/JrJK0o6WPFE5nZAuCPwPcLm6fRssh2e9hfUj8lQe5dSFp4rbUzCIKg6rCGRvfSXdRiD7S/pKcL63eaWXtSWcYCZ5OeJ95PCooLMbMnc0rJmLzpYjN7Ku+bn4dE3zdLyVpmdnd+3vloHqqdBXzFzJ6RdCJwdw7WC4DvAIs9YwT+ApxYWL8RODQP0T5OFtluJxPyta0M/NLMXgdeb6mdpKFkF548tidn+vInN11+bZfdB41zXXYDe/V12Xnx5nf+86nzXHYbb3Sgy26YM+91viP3cOX6QS5fHzT57rE3x3eBM6ew0TlE17dXvctujX4rueyanINOjd7c3aZ55Y2Afr2c98+RfzpAvnvivdYGZ1/K+3cBcM+rd5U3aosYwq08ZlbXyvbhhdeXkSYRLbYvB44PzGzfMsf/AfhDc5scCLcFFvs2NLM/A39uwed1wHVlzjUPWKOwPof0rLIlNi3YHVZ4Pa20z8xOauXYVttZ9BsEQVAVxBBuz0FJrfxF0sSdF7q7PUEQBD2aGkhjqbkeaGcws9HA6A4e+wzQydpUQRAEgYsa6IEuUwE0CIIgqBHiGWgQBEEQtJ/unF3rJQJoEARBUH3EEG4QBEEQdIAIoEFPYk5Tea3K4QNXdfmqc04AH1Y/pLwRMMuZi+fFq9/pze985tkbXHb7bf4dl92MpvLFo96dN8vla2if5V12M5t8epuD6/q77FaqX85l581ltHYVFSuPVyPTm6e6wPlMb4Ejx3eG+T7v3lzberWYHbgE3lzgilADz0AjjaUDSJrVbP0wSWd3lf8W9u8iaWYupj9F0u8dPj+bU3GCIAiqnxooJh8BtIqQ2vXz7qFcVH9zYF9JO5Sx/yxJgSYIgqDqsYYm99JdRACtMFlf876suXmvpLXz9sskHVCwm5X/30XSQ5JuBZ5p5usKSZ8trF8taf+iTa5c9DQwLNscmTU/x0u6Mdf03R7YDzg991rXzcudkp7I5/9EF92SIAiC9lMDhRQigHaMxTRJgVMK+84iqbCMAK4GznT42wL4nplt0Gz7X0jqL0gaDGwP3F40kLQCSZbswbzpJjPb2sxGAs8CXzezR0hSbyeY2Sgze4kkUXasmW1J0hM9t6WGLa4HOt1xKUEQBBWgBoZwYxJRx1hMk1TSYcBWeXU7Fol0Xwn8zuFvjJm93HyjmT0g6VxJQ4EvADeaWUOu6buTpPGk4PknM3szH7appF8BQ0ian0tUdM6KLNsDN2RfAC1WYy/qge40bPfqnxYXBEHPoAZm4UYPdOmxUOczF6UvSpu0NaXyCpJqyuEs0iCF9Ax0JLAJ8HVJpYB+GXCMmW0GnMzieqIlepEUZUYVlo06cE1BEARdgpm5Fw+S9pb0nKQXJbWo4CXpi5KekTRZ0l/L+YwAWnkeAb6UXx/CIi3RacCW+fV+gG/uewqIx8HCeryLkXuupwI/ypuWA96QVJ/PX+LDvA8z+wB4WdKBAEqMdLYnCIKg66ngEK6kOuAcYB/SZMqDm2clSFof+Amwg5ltQv7ebYsYwq08xwKXSjoB+C+p5whwEXBLHna9k7Z7nQsxs7ckPQv8vQ2z84HjJQ0H/o+kI/rf/H8p2e5a4CJJ3wUOIAXX87JmaX3eP76ttgxw6IGOfccnVLPnKiNcdl56ofJG7eAjK5/zCn79Tm9+561PneOy22nEEWVtBvaurEZqb2euoDf3cL4zz7JOvt/5a/T25bPON1+JuDn4PgPzHHmbACZfT6mX43oHO/4WAT5qmu+yW6l3ZbVjK0GFZ9duA7xoZlMBJF0L7M/iEzePBM4xs/cAzOztck4jgHYAMxvUbP0ysv6omb0C7NbCMW+RtERL/ChvH00zhZiif0kDSM85rynsX+yYPBN3WF49Ly/Nz/8wS6ax7L3ExQVBEFQDlX0GOgx4tbD+GvDJZjYbAEh6GKgDTjKzO9tyGkO4VYykPUgzac8ys5nd3Z4gCIKlRpN/KWYL5OWoDpyxN6mzsgtwMGnErs1SaNEDrWLM7B7gY93djiAIgqWNtaMHWswWaIXpwFqF9TXztiKvAY+b2QLSHJHnSQF1bGtOowcaBEEQVB+VzQMdC6wvaR1JfUgTPW9tZvN3Uu8TSSuThnSntuU0eqBBEARB9VHBOUQ5f/4YUl58HXCJmU2WdAowzsxuzfv2kvQM0EgqPPNOW34jgAZBEARVhzVUtpCCmd0B3NFs288Lrw34QV5cRAANgiAIqo72PAPtLiKABm4uXat8Dtjwt33jLu83+rQlZzX68s426evTIfUy0JlnN9+ZA+jR7wRffifAQxMuKWvzyc0Odfl68N+eapPw6Z1/5rLbpPeKLrt/zvLlDHvzQL06pN737P4zPuWy2/X/PeCy87bv6o0/Kmvz8iRfzut7Tb5c4D7zfbmxv+qzFAu3V78caEwiWtq0pfWZlVn+0cq+afnBdle0qaJ6pkEQBJ3FmvxLdxE90CAIgqD6iB5o0BK59uzpkiZJmijpoMLu5SXdnosen58Lz7fmZ2jW/Byblx0k9cq91SEFuxckrdqSfZdeaBAEQQexBv/SXUQA7R4+D4wCRgJ7kISuV8/7tiHV090YWJdF0mgt8Wfgj2a2NUnu7GIzawJuAT4HIOmTwCu5lOAS9uUaWqzwcdVbr7f/SoMgCDpADOEGrbEjcI2ZNQJvSXoA2Br4gKQNWip4fE22/VsrfvYANi5oei6ftT6vA34OXEpKGL6ujH2rFCt8vL79rtU/LS4Igh5BdwZGLxFAq4/mQaqtoNUL2NbMFpuqKulRYL0sxP1Z4Fdl7DvX4iAIggpTCwE0hnC7h4eAgyTV5SC3MzAm79sml5vqBRwE/LsNP3eThnsBKIlq54Tgm4E/AM8Wqmm0aB8EQVB1mPxLNxE90KWIpN7APFJw246kv2nAD83sTUmfINVsPBtYD7g/25aYIKn0u+x64LvAOZImkN7LB4Fv5f3XZV+HFY5vy74s+71c/mn90AGDXb769vJ99Jrw5bG93PC+y87Lm/N94jcr1/t0FN+d12r20mJ4NTw9OZ6PT7yiYr4AVqgb4LK7a/aLLrtV+vo+K3MbfZqWsxrnuey8Ob6f/P7dLrsVew902U2dW1ZeEoA9x/cra1OnGS5fC+TL72xwaqRq/tILVrXQA40AunTZBHgp9xBPyMtCss7nzi0daGbDW/F5UEsbzWwcLK4ybWYzWrIv6pkGQRBUA00N1f9oKQLoUkLSt0g9wOO6uy1BEATVjnXj0KyXCKBLCTM7Hzi/u9sRBEFQC8QQbhAEQRB0AGuKHmgQBEEQtBurgazzCKBBEARB1RE90CAIgiDoAE2NEUCDHsTf164va7Pu+A9cvhoG+vLO3m/w6Whu3m+Yy87LsD4ruOw+aPLplQ7t49Nv9OLR8PTmd3rzRXcfeaTLbp+B67ns7pz9ksuul7NS1tD65Vx2c5oWuOwe//1uLrvdfvSIy27tviu57P66Xvm81+emDHX5mmV1LjvDd4/P7lPZfOu2qIUeaI+vRCTJJF1VWO8t6b+t6W46/A2R9O3CelsanqMlbVXGny/DPgiCYBnCTO6lu+jxARSYDWwqqSQHvycwvRP+hgDfLmsVBEEQdJhaUGNZFgIowB3A/+bXBwPXlHZIWlHS3yVNkPSYpBF5+0mSLsm9yKmSvpsPORVYV9LTkk7P2wZJ+pukKZKuVrPq7JKOkPSnwvqRkv7YzGaXfK4l/EjaWtIjksZLGiNpOUn9JF2a9USfkrRrtj0sX8+/si7oMZJ+kG0ek7RitltX0p2SnpD0UC4jGARBUBU0mdxLd7GsBNBrgS9J6geMAB4v7DsZeMrMRgA/BYoPhD4BfJqk0fkLSfXAj0nl+EaZWakU3+akCkMbAx8HmgtVXw98Jh8PcDhwSQvtXMKPpD6kurbfM7OSfugc4DukuvGbkX4UXJ6vD2BTko7o1sCvgY/MbHPgUaD0YOxC4Fgz2xI4Hji3pRtX1AO9+u3QAw2CYOnQ1NjLvXQXy8QkIjObIGk4KdDc0Wz3jiRxaczsPkkrSSrN+LjdzOYB8yS9DazayinGmNlrAJKeBoZTUFExs1mS7gP2lfQsUG9mE51+ZgJvmNnY7OuDvH9H4Ky8bYqkV4ANsp/7zexD4ENJM4Hb8vaJwIisAbo9cEOhs9xiFfOiHuhrn9ytBjKzgiDoCUQeaHVxK/B7YBfANx0uKaeUaKT1++Wxu5jUw51CErruzPnKUfTTVFhvyj57Ae+bWciZBUFQlcQs3OriEuDkFnp+DwGHQHoOCcwo9fJa4UPAN1++gJk9DqwFfJnCM1gHzwGrS9o6t3G5LItWbPcGwNrZ1tOWD4CXJR2Yj5ekke1oUxAEQZdSC89Al5keaB4aPbOFXScBl2SNzI+Ar5Xx846khyVNAv4J3N6OZlwPjDKz97wHmNl8SQcBZ+WZxHNIz0HPBc6TNBFoAA4zs3ly5syRgu95kk4E6knPice3dcBXppf/vbXjyhu5Tv7WAl++6Gr1Ps3Ip+Z2ZmL1ksxp8mlQ9pPvT2hm0xyXXW/58vY+vfPPytp49Tu9+Z33jr/IZbfTiCNcdkPqfTqaXt5r/Mhl19Dky0H+9I8ec9n1db5n7zpzmveaUn7ssl5vunw50ztpwjdeOqjJp1dbCWpBjUVWCwPNPYScL/pHM7u3u9vSEXZZc4+yH5Y656CGN4CuWu8rQPDmAp8ANsDktx4va7PzsN1dvurku96ZjZUNoB5R6F7Ob88FTjHlSgdQ75e2F3P68wbQ5erKC1uDv9DDzAbfZ8BzX+qdnxMv7gDayx9AH5x+b6ci4IThn3F/QEZMu61bou0y0wPtTiQNAcYA42s1eAZBECxNGpuq/wlj9bewB2Bm75vZBmZ2YHe3JQiCoBYw8y8eJO0t6TlJL0r6cRt2X8gV7NqsIgfRAw2CIAiqkEpODpJUB5xDqkT3GjBW0q1m9kwzu+WA77F4rYBWiR5oEARBUHVUuBbuNsCLZjbVzOaTJk3u34LdL4HTAJdKRATQIAiCoOpoTxpLsWJaXo5q5m4Y8Gph/bW8bSGStgDWMjN3ZkUM4QZBEARVR3vmaBcrpnUESb2APwCHtee4CKCBm6MbW6tkuIi/9H7H5cubnuJN/9ix/9ouOy+Nzj/fBdbgshtc17+8EdDolJbYpPeKZW3umv2iy5dXv9ObnvLQhJbKPC/JLiO/4bLz4k2xmCNfju+BvVZ32Z0773mXnTfvddrst8ra9O/tu1bvOd+e59P57N9/FZddJajwLNzppEI2JdZkcVWu5Ug1xEfnXPrVgFsl7Wdm41pzWpEW5hlLZxTWj5d0UiV8Z3+HSppUUB45vlK+K4GkrSS1VKSh3HF/lHRcYf0uSRcX1s+Q9IN2+CurP9rGsZdJOqAjxwZBEFSapnYsDsYC60taJwt0fIlU3hUAM5tpZiub2XAzGw48BrQZPKFyz0DnAZ+XtHKF/C1E0j4khZK9svLItqQC61WDmY0zs++Wt1yCh0lF3UtDCCsDmxT2bw+45O7zLLMgCIIegSH3UtaXWQNwDHAX8CxwvZlNlnSKpP062sZKBdAG0vjz95vvaN6zkTQr/7+LpAck3aKkt3mqpEOy3uVESevmQ34CHG9mrwOY2Twzuyj7GJU1LidIulnSCnn76Ny7GyfpWSU9zZskvSDpV9lmuBbpbj6rpMM5IO/7uaSxudd7obRQl3O0pNNyG5+XtFPhWv6RX4TLpUsAACAASURBVA9U0hEdk3vL++ftm+RtT+f2rk8Kjtvl69wEmERSUFlBUl9gI+BJSbtnXxOz777Z57TcnieBhTmmknrl+/4rSXWSTs/XM0HSN7ONJJ2d86LuAZbe2EwQBEEZmsy/eDCzO3I+/rpm9uu87edmdmsLtruU631CZWfhngMcIslXvDQxEvgWKVB8FdjAzLYhKZccm202BZ5o5fgrgB9lLc+JwC8K++ab2VbA+cAtJP3MTYHDJJXUWDYEzjWzjYAPgG/n7Web2dZmtinQH9i34Ld3buNxzc5X4mfAfdlmV+B0SQPzdf45K6BsBbyWfxQ0SFqb1Nt8lJR/tF22mUh6jy4DDso98N7A0YXzvWNmW5jZtaX2AVcDL5jZicDXgZlmtjVJH/RISesAn8vXvzFJI3T7Vu5xEATBUqcJuZfuomIBNCt8XAG0ZyhzrJm9kTU3XwLuztsnkrQwWyUH6iFm9kDedDmwc8Gk9KtiIjC5cJ6pLHqY/KqZPZxfX0XSBgXYVdLjSoXad2PxYdWb8v9PtNLGvYAfK+l5jgb6kZRSHgV+KulHwMfMrDQ75hFS8CoF0EcL6w+TgtzLZlaaqdD8Oq9rdv4LgEmlX1i5PYfm9jxOknJbP/u4xswacyC/r4VrWWx6+D0f+SalBEEQdJZG5F66i0rngf6J1OMpTv1qKJ0nP+crVsEup1sJMBnYsgNtKfpqfp6S7+adf5PUj6R0ckDu8V1ECoLN/bam1yngC2Y2Ki9rm9mzZvZXYD+SmsodknbL9qXnoJuRhnAfI/VAvc8/m0s8PEL6AVBqs4BjC+1Zx8zuxomZXWhmW5nZVnsM8M3WDIIg6CyVfAbaVVQ0gJrZuyTJrq8XNk9jUQDcjySd1R5+SxoGXQ1AUh9J3zCzmcB7peeQpCHgB1pz0gprSyo9g/wy8G8WBcsZkgYB7Z2ZehdwbOG56eb5/48DU83sTNKQ8ohs/whpiPjd3Bt8FxhCCqKPkDQ+h0sqRa9y1/kX4A7geiXd0LuAoyXV53ZskIeUHwQOys9IVycNNwdBEFQFFZ6F2yV0RR7oGaTZTiUuAm6RNB64kyV7TG1iZndIWhW4JwclI4ljQ9LuPD9P/pkKHN7Otj4HfEfSJcAzwHlm9pGki0i9wTdJ05/bwy9JPfEJucf9MilAfhH4qqQF2e9vsv1E0uzbvxZ8TAQGmdkMAEmHAzfkgDiW9Fy3VczsD3mI+0qS7udw0mQkAf8FPgvcTBqefgb4D2nouE1O45VyJgx06gX27eX76K3Ue5DL7ol5Tn1EJ+8s+NBl583bXKnep8E+35lX+s9ZL5S1WaWvbzrCnbNfctl5cwq9+Z2jx19c3ghouN2XH7/1D0e77AbU+T6j3vzO5Xr7cnw/dMqZDe5T/j4PckqteaXqVurjy8v2/l1Ugu4MjF6WWT1QScOBf+SJQoGDLVbfseyHZaAzmd0bQL36ou80zHLZAYx746GyNp9YZWuXr+4KoDMXlBeP9gbQd+b7vhS9AdSrVVntAdQb8LwB9KPGeeWNgAZH0Kt0APUyr2mB23bK22M7NbZ6+6oHu4PT/751TeiBBkEQBAFAU/c92nSzzAZQM5tGSmsJgiAIqozunF3rZZkNoEEQBEH1UgvPQCOABkEQBFVHk6IHGgRBEATtphamt0YADYIgCKqOGMINehSe6fVNzt+N3vQpk8/Om/5Rafr28tUF8d6XOvnSdjx2cxt9upe9ummozJue0vt/j3LZDfrJYy47Oa+3n/O99fxdgP8+D3Ckgg1ypuLM87bNOWGnPWksnaWhBoZwK13KryJIasyqJZMk3VBSSWnH8adLmizp9K5qY1eRFV+ekzQ+K6iMKmM/RNK3C+trSPpb17c0CIKg67B2LN1FVQZQYE6u27opMJ+kZFKWXKkH4ChghJmd0M7jqoVDzGwkqSZvuR8BQ1ikIoOZvW5mIYwdBEFN0yT/0l1UawAt8hCwXhs6m4dJulXSfcC9km4FBgFPSDpISffzvqyFeW+WDivplJ4v6XHgd3n9PCV90alKGp+XKGmFXlZqTLYZl3u4Jxe2T5N0sqQns27nJ/L2QZIuzdsmSPpC3r6XpEez/Q257m5zHgWGFfzcW/C/f7Y5FVg399hPz9c7qXBvbpJ0p5IW6u8K7f26kqbpGEkXSTq7Mm9XEARB51lWa+FWjNwz3IdUQ7eks3mEpCHAGCUhaIAtSD3Od/Nxs7LuJpJuAy43s8slHQGcSaoFC7AmsL2ZNeYguQKpiPt+JDm0HYBvAGMljTKzp4Gfmdm7kupIAXuEmU3I/maY2RZ5SPX4fOz/kfQ4N8vtWUHSysCJwB5mNltJ4uwHwCnNbsHewN/z67nA58zsg3z8Y/nHwo+BTQvXO7yZj1HA5iQVmecknUVSkvm/fN8+JEmZjS/3fgRBECwtYhZux+mvpF8JqQf6F5IyyX6Sjs/bSzqbAP8qBc8W2A74fH59JfC7wr4bzBZ7yn6bmZmSDuhbZjYRQNJkUkH2p4EvSjqKdO9WJwlSlwJoUSu0dM49gC+VTmBm70naNx/3cJ7Q0IfFi7lfLakPqSddegYq4DeSdib96BoGrNrKNRe5NyvXIOkZ4GOk4vUPFH5w3ABs0NLB+VqPAhi23DqsOMBzyiAIgs4Rpfw6zpxSj6pEVhL5gpk912z7J2mnwkuB5se1qSEqaR1Sz3LrHAgvo31aoQubTQr6B7ey/xBSED4dOIsUjA8BhgJbmtkCSdOanbs1itdRrl1LYGYXAhcCjFhtu1r4URgEQQ+ge+bVt49aeAZaokWdTQePsKgHeAipR9tRlicF3ZlKEmv7OI75F/Cd0oqkFUii2Tsoa3zm57uL9QAt5Xn8H7Btfp46GHg7B89dST1JSEOwPqmPRYwFPpWHk3sDX2jn8UEQBF2Kyb90F9XaA22J1nQ2y3EscKmkE0hamO3VDF2ImY2X9BQwBXgVeNhx2K+Ac/LEnkbgZDO7SdJhwDWSSgldJwKLCRCa2RxJZwAnAD8CbsvDy+NyGzCzdyQ9nP3/EzjHcR3TJf0GGAO8m33NLHfcOn1WKnuxz899u6wNQP+6Pi47rzzakLp2ZTqVZZZTymqNfuXvCYA5n+is0dunyzi4rryE1iynfNZQp9Tae43lJdQABjnfM6/8mDe/86EJl5Q3Ajbf5Msuu2F9VnDZzWz0fVa898UjB/dhk++9XcH5dzHL6c/7d1EJaqGQwjKrB7qsI2mQmc3KPdCbgUvM7Oa2jtl/7X3Lfli6K4C250fog9PvLWuz5oo+oZ7uCqCzrXxCuzeALu/UlvQG0BXrfLqh0+e/57Lzal9WewDt49RJreYA+soc3983wGvvTupU3/Dstb7iDk7HvHpVt/RDa2kIN6gsJ+WJWpNIvfm/l7EPgiBYatRCIYVaGsINKoiZHV/eKgiCoHuIWbhBEARB0AFqYRZuBNAgCIKg6qiF2TkRQIMgCIKqI4ZwgyAIgqAD1EIaSwTQwM27jun6Uz94w+Vrt6G+NBEv7zfNrai/DQes4bLz6nx6me/Ub5zfVP4J0cBevlShOU6Nx4YmX9vmyKdDOsCpaSmnLqQ3PeWpyX912e004giXnfc+e9OAVu7dkq7E4qza25e7O8+pk9vfqX3q/buoBJUewpW0N/BnoA642MxObbb/B6T65Q2kmgFHmNkrbfms6TQWST/LqigTshrJJyUdp3bqhxb8nVSotVvcLkknZkWT5yXdL2kTh7/DJK1RWL9Y0saVbFulkDSrq3wHQRC0lwbMvZQji3+cQ6oetzFwcAvfxU8BW5nZCOBvLF43vUVqNoBK2o5UiWiLfMF7kKoDHQdUtixNKsW3PTDSzDYAfgvcKqlchvdhwMIAambfMLNnKty2IAiCHkeF80C3AV40s6lmNh+4Fti/aGBm95tZaZjgMZJaV5vUbAAlKaHMMLN5AGY2AziAFLDul3Q/gKSDs37mJEmnlQ6WtHfW1hwvaYnSNJKOlPRPSf1JZfSOKd1cM7ubVGP3kGw7S9Ifc2/4XklDJR0AbEVSVnlaUn9JoyVtVaZdsyT9OrfrsVxzt1UknSBpbO6Fn5y3nSqpWH93Ye+1JfsgCIJqoz16oJKOUtJpLi1HNXM3jNTBKvFa3tYaXyeVRm2TWg6gdwNr5SHVcyV9yszOBF4HdjWzXfPw6WnAbiRZsK0lfVbSUOAikrrLSODAomNJx5B6t58F6oGBZja12fnHAaVh3IHAODPbBHgA+IWZ/S3bHGJmo8xs4QPE1tpV8PVYbteDwJGt3QBJewHrk35djQK2zHJn1wFfLJh+EbiuDfsgCIKqokn+xcwuNLOtCsuFHT2vpK+QOj+nl7Ot2QBqZrOALUlalf8lBYjDmpltDYw2s/+aWQNwNbAzsC3woJm9nH0VtUQPJY2TH1Dq3TpoIgUtgKuAHcvYt9YugPnAP/LrJ0g6pK2xV16eAp4EPgGsb2ZPAatIWkPSSOA9M3u1Nfu2Glr8Zffm7OllLisIgqAyNGHuxcF0YK3C+pp522JI2gP4GbCf5/u/pmfhZjHs0cDorFLytQq4nUjqna0JvGxmH0iaLenjzXqhW5J6my02rRPnX2CLKvx7dEV/a2YXtLDvBtKQ9mosCu5t2bdIUQ90p2G710JucxAEPYAKf9mMBdZX0nSeTpK4XGzatpJE5gXA3mbmqppfsz1QSRtKKvaeRgGvsLg+5hiS7uXKeRbWwaSg9xiwc76ZSFqx4Ocp4JukSUKlCUCnA2fm56GlXyk7AqX58L1IwQrSm/Lv/Lo1rc7W2tVe7gKOkDQot2uYpFXyvutIH5IDSMG0nH0QBEHVUMlZuHmk7xjSd+CzwPVmNlnSKZL2y2anA4OAG/K8lVvL+a3lHugg4CxJQ0h5Oy+ShnMPBu6U9Hp+Dvpj4H5S7+t2M7sF0tAkcJOStujbwJ4lx2b27zzp5nZJewJnASsAEyU1Am8C+xeea84GtpF0YvZ1UN5+GXC+pDnAdgX/b7TWrjKcKOm4gp81JW0EPKqUKzcL+ApJeHuypOWA6Wb2Rra/uzV7x7m58+jVy9oMPmWKxxULnGnS7zbMdtlt3bd829pDo7N9jU45QG8+3hx8OZn3n/Gpsjaf/P7dLl+P/343l92nf+TT5Tywl++9OHfe8+WNgH7OHEWv/Jg3v9Mrj7bNpl912fV1XseN+5fv17x+jy8n9/0PfAkJyw/05VF/e47v81kJKj3cZWZ3AHc02/bzwus92uuzZgOomT1BSi1pzll5KdldA1zTwvH/pNksKzM7qfD6LtKvlRIn56W19vyghW03AjcWNu3iaNegwuu/kfKRSm07qQX7P5OSg1tq02Ze++J5gyAIupuoRBQEQRAEHaDSVb66ggigFSB6b0EQBJWl+sNnBNAgCIKgCokh3CAIgiDoAI010AeNABoEQRBUHfEMNAiCIAg6QPWHT5A589iCYLthu5b9sMxu9OWTLVfX32XXaL4nIR81easuwoQ3Hy1rs+0au1T0vN4cQK/mpsdfv16+38fznBqkfVXnsntr/gcuu+V6+z4DDc729ZHver36nd4c5DGTrnTZ7bf5d8obAe85dHcB5jSV1131aq4ucOjLAvR2fgYAHnt9tE/ItRW+OfxAd3C6YNoNnTpXR+mSSkSSVsqVHJ6W9Kak6YX1Nj+9kraSdKbjHI90sG2HF9oyPyuiPJ0VTE7JVYa6hKIaSyd8/DT/L0n/lrRPYd+Bku7sbDuDIKhuPMGz1mmPGkt30SVDuGb2Dqm0HpJOAmaZ2e9L+yX1zqWVWjp2HEnFpNw5Wiqi4GnbpcCluR3TSMotMzriq5v4KfAbMzNJ3yKVnbqf9F7+Bti7o47bel+CIAiWJrUwiWip1cKVdJmk8yU9DvxO0jaSHpX0lKRHJG2Y7XaR9I/8+iRJl+Se21RJ3y34m1WwHy3pb5KmSLpauU6dpP/J256QdGbJb5k2HpBfT5P029w7HSdpC0l3SXopB67SMS3pcQ6UdLuSpuckSQe1cc7hkh5S0iZ9UtL2efvqkh7M558kaSdJpwL987arzWwScBtJr/TnwBXAm/mejcn3dv8y59klb78VCLHvIAiqAmvHv+5iaU8iWhPY3swaJS0P7GRmDXnY9DfAF1o45hPArqSi7M9JOs/Mmhdk3Jykzfk68DCwg6RxpMr6O5vZy5KWKJvn4D9mNkrSH0l1bXcA+gGTSDVui/qaIhWg3xkYCrxuZv8LIGlwG+d4G9jTzOYqFce/hqRF92XgLjP7tVLB+QFm9pCkY8xsVOH4k0nSZPPzcb8A7jOzI5TqBI+RdE8b5wHYAti0JO8WBEHQ3UQe6JLckCXIAAYDl+cvcyMJV7fE7VmXbZ6kt4FVSWriRcaY2WsAkp4maWjOAqYWgsI1pGLz7aFUjX8iMMjMPgQ+lDQvB6eiviakAvfrAw8BZ0g6DfiHmT3UxjnqgbMljSLJl22Qt48FLpFUD/zdzJ5u6WAzmy3pOtIw+bwc1PdTKoYPKeCvTfpx0dJ5IN2/FoOnUtH9owDWGbwBqw5coyWzIAiCitJUAxNcl7acWXFa2y+B+81sU+AzpC/6lihOc2xNH9Nj0xFKfpuanaMpn6OkrzkqL+uZ2V/M7HlSr24i8CtJP6d1vg+8BYwk9Qj7AJjZgySR7enAZZIObcNH8Vm6gC8U2rS2mT3b2nkyrU43LCq9R/AMgmBpYe1Yuovu1AMdzCJF8MO6wP9zwMclDc/rrT6H7AQt6msq6Yh+ZGZXkTTmtmjDx2DgDTNrAr4K1GVfHwPeMrOLgIsLPhbkXmlbbTq28Bx487bOEwRBUI00Ye6lu+jOQgq/Iw3hngjcXmnnZjZH0rdJ2qCzSUOilT5Ha/qa6wGnS2oCFgBHFw67XVLpGe6jpFm1N+Ye5p0s6g3uApyQbWcBpR7ohcAESU+a2SEtNOuXwJ+yTS/gZWBf4NxWzuNmbmP5qfNzHDbtsfPmnQ2tb0m3vON4cwW9uZYLnPmsJt+XwWBHHu3UuS6ZV9buu5LLzpsXOaR+oMvuwwZfvmMv+VL8BvXy5Ty+1/iRy86bu+vN77z1qXNcdruPPLKsTZ+6/tQ7/jbmO3NocX6OvX8XlaAWZuH26EIKkgaZ2azcGzsHeMHM/tjd7apVNl9th7IfllnOQgpeuiKAPjj93rI2u6+5l8uXV3jbG0DnNfkEi1fqXV4AqLsCaL8635dspQPokDqfePQsZ/ELb2GGFZxFQSoZQD3BE/wBtMH5OW5PAL3n1bs6VdzgwI/t7w5ON7xyS88ppFBFHJknFU0mDWFe0M3tCYIgCBxEGks3k3ub0eMMgiCoMSKNJQiCIAg6QC08XowAGgRBEFQdIWcWBEEQBB2gFmbhRgANgiAIqo7ogQY9ip9qeFmbb8x5zOVrrYFDXXbe6freVAIvC5zT/xd401iceou95JsYf/XG5XMZ9xzfWnGvxfnrer6c3L2m+L7Qps1+y2U3uI8vX3SAM7/T+1lZ2ZECBHDj/r73Ys+bfHmlnvQUgHvHX+Sya7jl3LI2C8ZMdPmq33oTl92nfzHeZVcJauEZaM2nsSix1HQxJa0saUEzRZYhuWhD0W4DSXdIeiGrn1wvadWuaFMQBMsWnuBZ69SCHmjNB1BLP1O+BfxBUr9cVu83gK88SDOkstnTBwKPAQcXtg0BFgZQSf1I1ZXOM7P1zWwLUiUgX7crCIJgGacW8kBrPoACtKCLeRXws45qYpbR8zwY+H/AMElr5m2nAutmnc7TSVJkj5rZbYU2jjazSTnIXyppYm7brrkNh0n6u6R/KWmRHiPpB9nmMUkrZrvRkv6sRTqh2+TtremrHibpJkl35t7w7/L2IyT9qdQ+SUdm2bYgCIJup9Ga3Et30SMCaOZkUuDah6Tscp+ZbUPSEj1d0kAWaWJuQSouf2bh+C2A75nZBsDeJD3PkVkt5k4ASWsBq5vZGOB6FhWo/zHwUlY/OQHYFHiilXZ+h9Rx3owUjC/PPVbycZ8HtgZ+TSpIvzmpZm5RjWVA1gT9NnBJ3jaFpK+6OelHxG8K9qNyWzcDDsrXcT3wmUJh+sMLvoIgCLqVWigm32MCqJnNBq4DrgT2BH6cy/iNZpEmZj1wkaSJwA3AxgUXRU3MicCekk6TtJOZzczbDyIFHoBrWXwY18uOpB4yZjYFeIVF2pz3m9mHZvZfYCapV11qz/CCj2vy8Q8Cy2dt0sHADZImkaovFWcF3GtmM81sLvAM8DEzmwXcB+wr6RNAvZktMeNA0lGSxkkad89HL3bgcoMgCNpPpYdwJe0t6TlJL0r6cQv7+0q6Lu9/vKDk1So9bRZu6ZlySRPzueJOSSexSBOzF1CsfL6wUraZPS9pC+B/SHqe95rZKaSAuZqkkgrKGkqC4M0rgE8GPtWB9jfXHC3qkRbfq+afGGORvurn8hs/uhW/Rb3Ui0lqMFOAS1tqkJldSFKA4YbVD6n+aXFBEPQIKimoLamOJCiyJ/AaMFbSrWb2TMHs68B7ZraepC8Bp1FGBrPH9ECb0SlNTLWg5ylpA2CQmQ0zs+FmNhz4LSmofggU5UD+Cmwv6X8LPneWtCnwEHBI3rYBqWe8WKB3cFA+fkdgZu4ht1tf1cweB9YiDX1f0842BEEQdBkVFtTeBnjRzKaa2XzSCOL+zWz2By7Pr/8G7F6KIa3R03qgJTqribkZS+p5Hgzc3MzuRuA6MztF0sN5+PSfZnaCpH2BP+WJOguACcD3chvOy8PIDcBhZjavzPvUnLmSniINSR+Rt3VUX/V6YJSZvVfOcIpDyWheg0+Oa4XevhxAbz5mvTN/0ou3CsqANrXNFzHDfBJag51yUS9PWr6szYV1cHTTjLJ2z03x5uS+6bLr39uXtzmozpenOqjO5+9Dp0zZqr190nev3+P77M1p8uXRDnTmn3pTVHrv/22HDcz86uHl7db/wHVOb95zJWjPs01JRwFHFTZdmEfPSgwDXi2svwZ8spmbhTZm1iBpJrAS0OofUY8KoGZ2UmH1my3sfwEYUdj0o7x9NIUhTzO7i9SLLTKuBX8TgI3y6y832zeFNBmpJZb4RJvZZcBlhfXhre0DrjKz45od/yiLnqUCnNiK332bnXpHQrGmR+IJnkFt4gme4Aue1Up7ZtcWHzUtTXrqEG5Qhlz84XlgjpmVV5gOgiBYilR4Fu500uOqEmuy6JHXEja5HsBg4J22nPaoHuiygJntUiE/77N4jzUIgqBqqHCBhLHA+pLWIQXKL5HmfhS5FfgaKW3wAFIqZJuNiAAaBEEQVB2VrIWbn2keQ3o0VwdcYmaTJZ0CjDOzW4G/AFdKehF4lxRk2yQCaBAEQVB1VLpAgpndAdzRbNvPC6/nkkq1uokAGgRBEFQd3Vmiz0sE0CAIgqDq6M4i8V4igAZBEARVRyUrEXUVEUADN56cpw2HrFneCHivobUaFoszwJlEX+nBnl74Clt4n9N4h6M+ciblv9dU/r4skK8QwCzzCVE7bwlD6itbJGOe026FugFOfz5x8/c/8PkbUDe3vBEw3yvS7hDBnv03X37n4CtbrNC5BG/s7RP79v5dVIJa6IG2+Z2oxFIRq5a0b5biGi/pGUnfzNu/lSsHVfJcl0k6oJM+jpM0oLA+LUuUTZB0t6TVOt9Sd1s+K2njwvopkvZYWucPgiCoNE1m7qW7aDOALi2x6iypdSHwGTMbCWxOrgxkZueb2RUdOV8XcxzQ/CfqrmY2glS16KfFHfnHSFcVrvgsBWUZM/u5md3TRecKgiDocnqEoPZSEqtejjSc/E4+57ySkoqkkyQdn1+PzhJjYyQ9L2mnvL1O0u+zvwmSjs3bt5T0gKQnJN0lafXWrlPSIEn35rZPLFzXEu2V9F1gDeB+Sfe34O5BYL18T56TdAUwCVhL0unZz8R87aV79ICkWyRNlXSqpEPydU6UtG7hHt+Xr/FeSWvn+7wfqXbv05LWLfawJe2e36eJki6R1Ddvnybp5ML1fqLcZyEIgmBp0ZMEtbtUrNrM3iVVgXhF0jU5eLTWtt753McBv8jbjiLpZY7KPcCrc6/2LOAAM9uSJBb96zaucS7wudz+XYEzJKmV9p4JvE7qce7agq99SRqeAOsD55rZJsBWJHHrkcAe+d6VgvpIUm9/I5JSzAb5Oi8Gjs02ZwGXl64RONPMHsn37oQs6P1SqRFKQt2XAQdlAe/epML4JWbk6z0POL6lm6KCHujYWaEHGgTB0qHmh3BLLA2xajP7BrA7MIb0ZX5JK825Kf//BItEpvcALjBLswNyQN4Q2BT4V27riaT6h60h4DeSJgD3kCrzr9pae1vh/nyu5UlSZwCvmNlj+fWOwDVm1mhmbwEPAFvnfWPN7A0zmwe8BNydtxfFtLcjSaVBei92bKMtkO7By2b2fF6/HNi5sL+le7kYZnahmW1lZlttPWi9MqcLgiCoDLUwhNueWbhdLVaNmU0EJkq6kiRBdlgL7ShpFhWFoVtCwGQz2855fYcAQ4EtzWyBpGlAv7ba2wK7mtlCCQxJQ2hdMq05XjHtSuK9l0EQBEsVq4FCCh2Z1NIVYtWDJO1SMBsFvNKONv0L+GZpkpKkFUki1UMlbZe31UvapA0fg4G3c/DcFfhYa+3N9s1FtD08BByUn9kOJfUGx7Tj+EdYVJ/xkOyvrbY8BwyXVOo6fpXU6w2CIKhqKqzG0iV0pNfRFWLVAn4o6QJgTj72sHa06WKSssgESQuAi8zs7DyR5kxJg0nX+idgcj7mAiWxa0giqp8BbstD0OOAKW20F9Ks4Tslvd7Kc9CWuJk0DDueJKT+QzN7sx0TeI4FLpV0AvBfFumKXksaPv8uSUUASLUdJR0O3JB/XIwFzneeawnmOVLAXvzgdZevdZdvdT7XYnjzzuorrMznzRVscJ63Xr5cy5Wcost95pfPKWxw5h1ahXNe3573vstupT7lQV2tiwAAIABJREFURcHB/xmY5RTU7t/LJ4K+/EBffueCWb7PCr18X7f1W7f1Oz/hFcD25neufudFLrsFI5aevmgli8l3FaqFRgbVwc+HH1L2w3LG2w+7fHkD6IBevkIKH6sf4rIDuO6Vv5e12WaNT7l81Tkzk+Y2+gokrFLvCyo/mV8+0H6H/7h8/Y6Pu+z+r9erLrtKB9BBdf1cdl68AfSsfr4fPV+d9aHLrt4ZQO87efOyNva+L4DOuPbl8kb4A+gO7QigY15/oFNVF4atsIk7OE1/b/LSq/BQIJ57BUEQBFVHlPILgiAIgg5QC6X8IoAGQRAEVUctPF6MABoEQRBUHd05u9ZLBNAgCIKg6mhsqv480AigQRAEQdVRC0O4kcYSuNlh2G5lPyz9WhbcWYJpc2eUNwLW6LuCy66hHYqgj05vqf7/4iyYMdXla5/Njy5vhF8PdK4z/3Rgrz5lbd6c31bVyUWs1cd3j2c7tUobnUNv7yzwpX94mdUwx2W34YA1XHbeIcQ5TQtcdoOc2rbzm8p/BhY4P+/eHFqvNuvDE3z6ogD1K3+8U6klgwet6w5OM2e91C1pLF0lrxVUGZJm5f+HS5qTFVqezYovh3Vz84IgCBbDzNxLdxFDuMsmL5nZ5gCSPg7cJElm5v95GQRB0IXUQh5o9ECXccxsKvAD4Lvd3ZYgCIIStaDGEgE0AHgSaLEeb1EP9M3Zvjq3QRAEnaWxqcm9dBcRQAOg9ZkGRT3Q1Qb6Jl8EQRB0llrogcYz0ABgc+DZ7m5EEARBiVrIEIkAuowjaTjwe+Cs7m1JEATBImohgLZrqnAstbsAs/L/w0maq0+Rep1jgMM64feoCrezYv6quW3hr7r8VXPblkV/tbJEIYWgU0gaZ2ZbVaO/am5b+Ksuf9XctmXRX60Qk4iCIAiCoANEAA2CIAiCDhABNOgsF1axv2puW/irLn/V3LZl0V9NEM9AgyAIgqADRA80CIIgCDpABNAgCIIg6AARQIMgCIKgA0QloiBoBUkC1jSzV7u7LSUknQWtF/80s1DVWcpIqgMmm1mLggwd9HkGcImZTa6Qvw2AE4CPUfjeN7PdKuF/WSUCaNAuJK0K/AZYw8z2kbQxsJ2Z/aUTPgcA/w9Y28yOlLQ+sKGZ/aMDvnYATmLRF4UAM7OPt9eXmZmkO4DN2ntsG+3bADgPWNXMNpU0AtjPzH7ldDGuUm1piQq0r+Tn823tN7ObOti+M1vYPBMYZ2a3dMRnZzGzRknPSVrbzP5TIbfPAhdK6g1cClxjZjM74e8G4HzgIqCxs42T9DXge8CGedOzwJlmdkVnfdcSMQs3aBeS/kn6g/6ZmY3Mf+BPmVmHg4yk64AngEPzl/YA4BEzG9UBX1OA72d/C78ozOydDrbtcuBsMxvbkeNb8PcAqSdwgS0SNZ9kZpt20N8AM/uoEm2rZPsklcTZVwG2B+7L67uS3tt9O9i+C0nSezfkTV8AXgZWAqaa2XEOHx+yqBdfUiIyFv3YWr4D7XqQJMowBphd2m5m+7XXVzO/GwKHAwcDDwMXmdn9HfDzhJlt2Zm2FHx9DTiOpCP8JOm+bQGcDvzJzK6sxHlqgeiBBu1lZTO7XtJPAMysQVJnf9Gua2YHSTo4+/woD592hJlm9s9OtqfIJ4FDJL1C+mIsfcmO6KC/AWY2ptnlNbTXiaTtgL8Ag4C1JY0Evmlm3+5guyraPjM7PLfzbmBjM3sjr68OXNaJ9o0AdjCzxuzvPOAhYEdgorNty3Xi/K3xf5V2mIeGP5GXGcB44AeSvmlmX2qnu9skfRu4GZhX2mhm73agaUcDnzOzaYVt90n6AnAtEAE0CFphtqSVyL/gJW1LGkLrDPMl9S/4XJfCH3k7uV/S6cBNLP5F8WQH/X26g8e1xox8faVrPQB4owN+/kRq260AZjZe0s5V1L4Sa5WCZ+YtYO1O+FuB9KOh9JkbCKyYh1Hb/ZmRtCOwvpldKmllYDkze7m9fszsgfYeU6ZdfwQ+A9wL/MbMxuRdp0l6rgMuv/b/2zvvMEuqan2/3wwZGYKXi6BkJInkbAIUf3gFMSEZFK+IIhIU9V68gKAiQRFBVBQQSQoiQZAsUSQzMKQRRFSUoCgwDiDp+/2xdk2f7jkdalc1p6dnv89znu5TZ2r1Pn16atVe4Vvp6/4dxwzUTm0AkwY4zzBmPyyp9u59VqY40EJd9iMu2stL+g2wKPDhhjYPBi4BlpR0OvAWImyVwwbpa6ewtYGsYgnbfxxwkV2UuIDnsieh2rKypL8Q4ccdM9f25wE7xca5Lbqvb6cG9q6UdClwZnq+LXBFA3tHAJMlXU1EA94OfF3S/HXtSjqI+DtZiUhLzAWcRvz91SLdSB4LrJLsTASm54SDE3cBX7Y9vctr69c1ZnvZzHV047nM18YdJQdaqE3Ke65EXMCm2n6xBZuvBTZMNm+0/femNtug8yJre0VJSwBn2659kU32lrX9h3TBn2B7WnWspp2fA98CjiNuGvYG1s0I7Q1mf8b6WrD1AcLRAVxr+9yG9hanz4ncYvuvmXYmE3nL2zvyvXflhOcl3QpsR+Rm1wV2AVa0/T85a0s2X8/MVbPXZtqakwi9Vp/D1USeu/b/XUnPAg92ewlYzvb8OWucFSk70EItulRXrijpaWCK7ScybV5p+53ARV2O1bW1IHAQfReKa4BDGlQwfoB0kQWw/VdJTXJo5wBrD9hZ/ByoW+CxB3AM8HrgL8BlxO6xEZIWIi7+ywBzVDvchu0xtwPTbF8haT5JCzR0zBOAvxHXrxUkrZDpWF5IldZVuLrRhd/2g5ImpvzsyZLuALIcqKRvEA75XvoiCwayHChRWT0ncHx6vnM69t8ZtlbJXMO4ozjQQl0+DmwEVJWAmxAVr8tKOqROBZ6keYD5gP+QtDB9FZGTCMeQw0nA3cBH0vOdifDckG0VQ9DKRVbSysCbgAUH3IRMAubJMWk7K/Q7DL8CbiQKcl5pakzSJ4DdgUWA5YnP9ftA7ZujZO9wIgx8T8f6ch3LWZJ+ACyU1rkb0eaRw7OS5iLCy0cQeeMmQjUfIKIeubUAA1nP9hodz38t6c4cQ7b/2NKaZnmKAy3UZQ5gFduPw4y+0J8QYcRrqVeB90miHH4JwglXDvQZIjSZw/K2P9Tx/CspVJdLWxfZlYAtgYWI4pCKacAnMuz9RtLDwM+Ac2w/lWGjG/PY3q8lWxC74vWBmwBsPyDpPxvYez8tORbbR0nanPh7Wwk40PblmeZ2JhzmZ4g2qiWJFptcHiJ2jG050JclLW/79wCSliMzZz6gDajfS2S2Ac2qFAdaqMuSlfNMPJGO/UNSrXyK7WOAYyTtZfvYltb3nKS32r4eZggrZBc2DLjIrkjmRTY1+Z8vaSPbv81dT4e9FSWtT4T5DpB0L/BT26c1NH1qulG4kObtDgD/tv1CFQpO+fMmhRetORZJ+wE/a+A0Z5CKzeYFFrf9lab2gGeJ3eyV9P8cckPp+xMV6g8Rjm5pMgv1RqkNaJakONBCXa6WdCH9G9mvTqHNrF2Q7WMlrQasSkc4M1PV5FPAKSkXKuAfwEdz1tXBFKBqsxlRr+EQ3CFpTyKc2/led6trKLU23Czp60RB0SlEFWkTXiAa4g+gz9HltjsAXCPpf4F5043Ip4FfNlhfm45lAeAySf8gdvJnD7g5HDGStgKOIipwl5W0JpF7zxVSuCA9WsH2lUoKX+nQ1BbDw7MtpQq3UAvFVuKDROM6wD8J2bfsApZU6boJ4UB/BbwHuN52dntM1Y9m+5lcG8nOfwMHEko6At5BXBhPyrR3NnA/sANwCNHCcp/tvWvamUTkybYjcovnAmfZvi1nXR12HwLWb6sKWtIEIm/+buL3d6nt3DxjpYIzE7ZPaWBzdSKv+iHgEdvvyrBxG9EqdXVHRe8UN1DoagNJm9n+dZfiPyBfUrEQlB1ooRapoOYhouVkG6JP8JyGZj8MrEFIAn4s5VVr7aQk7WT7tBSW6zxerftbmWvbH1jLSQowtdvcQBQr5bCC7W0kbW37FElnEEo6dbkTOI9w5o1Dwh08SOzy2uJg2weS8saSJko6PbcAqomjHIIngMeAJwnpwRxetP30gL7c7N1J2i0exsxRmbqRgHcQN39bdXnNhOBIIZPiQAsjQiEyvn16/J0Iecn2pi2Yf872K5JeSjurJ4gijDpU1bHd8jNNwixPEoU+FdPSsVyqPPFTKWz9GHkX7eXSzcx8DdbSjelEiPQq2sm9LSnpf2wflqpUzwJqF3VJOsv2RyRNocvnmdm7+WmiWntRIiXxCdv31rWTuEfSDsDE5Pw+S9xo5XIy0Y51NKEf/DEyqnptH5S+PWRgr7GkNsUVZkuKAy2MlPuJndKWth8EkLRvS7ZvTf2HPySqcf8F1NpV2f5B+vYK27/pfC0VEtWiYyf7IHCTpPOJC/fWhEpMLieklp0vEzmu15Cno7qhpNHQwj0vPdpiN+B0hXbypsDFto/OsFOFuLNE6AdhSWAf29lV2oppPZ8G9iLyxv8mVJcuBQ5tsLZ5U95SqW3k4BQmPjDT3jmE4HsnOf3HhQ5KDrQwIiS9n8i3vYWQ3fsp8KOWJcKQtAyhtZnlpCTdbnvt4Y6NwM5BQ73eUqVl9bNqj8GSdBMR+r7ALUx1GWB7LqLiGDKVpiR1/r7nBH5ATBM5EfK1iSUdbvuLwx2rYW8mmcaBO7Vhzt8G+BpRwHVEzu9qELs3EHUGPydCsH8BvmF7pSFPnNlO1X98BP11cCcB+9t+UxvrnV0pDrRQi1RtuzURyt2M6AE91/ZlmfYmAgtXRSvp4v1RYF/bI1Y8UUwn2ZjoK+3c4UwiJkes0fXEV5G0xtcTcnZPpOKVLwFvs10rZC3pJtsbSLqjw4He2fR9StqEcAYPE0U/SwK71lX6SSHgwbAzBzkPcoOUK7/XikyjpCqKsAXRBz1DgCI39y5pPWLG5kLETnZBwkHfWNPO1kTv7PvoX9U7jWh7ahJmnu0pIdxCLRwSdGcAZ6RQ5DbAFwkpuVpI2o7YmUyX9ABxJ38ScAv1BdbnIsKZc9A/D/oMDcTuJa1LhOYGapLWumArJsRsSeT/vqgQWP9volCkdgsL8GdJGwNW6JzuTVxwm/JN4N22p6Z1r0iEJGuF+mxvmipwt7H9s6aLkvQpIlS6nKTO6MQCxM42h7ZkGl8gcsdzp/U0VnBymj+bfoefdab0Ydv9x4UB2C6P8ujJg5DcWyF9vzaRP9qqoc2lW17jVOLufVnCiS6d8zMITdN50vcLE3neZRqs6z+A04nxYE8QVcuLtPB+7xrJsRr2bm3pc1iQ0Oc9s/NzaPKegZvT19vT1/nrvldi13kv8A1ilmpbf3frEj3HD6fHncA6Dey9gWh1eiI9zgHe0NZ6Z9dHCeEWesbAcFwbObyUx/oCMwsV5IYMr7f91uH/5bB2Br7XGaHXtpB0lO3PN7RxErGDqtqIdgQmOkPoIdn7Bn1V2zME9J2vbFTZ/U/6f761csjJxueBNwKb0xcJONP2d2rYuA7Yw/Y9dX/+MHbvAva0fV16/lbgeGcOcpd0ORE5qqQ2dwJ2tL15G+udXSkOtNAzJD1CKOhU7Nf53Bn5I0mXERfrzxMTS3YF/ub8IpN3Evnegco3tfrnJD1Fn+C5gLd1PMf5ijWdP+NPtpsMq0bS3IR+bXXTcB1x4c5SrZHUrSDHrt/PWNnbivgbWYLYSS1NCFFkFcMo1JE6RR6yZP0knWp75+GO1bA30w1WTjFcx7kz5cclTba9Zo69QlAcaKFnjEalq6TbbK/TWVgi6Rbb62Wu8TRgZQZM/6i7I5P0jqFet31NzvoG/Iw/u2YxUhcb8wPPO0ZyVUVec9tuU1whG8UEkc2IdqW1JG0K7GT74y3Zz7oJ6RJhmEiM+Fs1cx3fJuQjzyTap7YFnidFBlyzilkhfXgyfYPNtwc+5oyRgYU+ShFRoWdUDlLSa52UflqgaiN4VNJ7gb8So7RyWc81Wwe6UTnItIO6yHZWoYmkwd6L0qMpVwLvInK0EBfxy4gK59qoxUHOiRdtPylpgqQJtq9KzqYtav0OU39rpfVbyUaKKCw6ocE6qt3iwJvMtQiHWjclsRtwLFGhbkLkIUtMvtBH2YEWek6qwJ1M3CFf7AZ/lJK2JMKOSxIXjEnAV2xnCXNLOhk40vkKNQPtnUbMUz0HOMn2/TXP/wNxAex2oc8OjXbYnyms1yTUJ+lHRB9oJcG3M/Cy7ZxBzki6gmjLOIwopHqCuMnJcvBd7OfuQA+znTU8uzDrUhxooedIErHr2Q1Yj5B7+7Ht3/V0YYCk+wix9j8QOdBq5mFWMUeyOYkUQiOc4clE8UpWq0KbSPoNsFcVIpS0DnCc7Y0y7XXLvWX3q1YhZuJz2JGozj2tTlGSBugld74EHGC7dsRCoXY12fZ0STsRVeXHOHP4tEKZaxei8rizfSpLUlEh27dXF3uNc++zM8WBFsYUKad1GtFScCfwJdfoX5N0CrC304Dp1Kv6zQZVpEt3O557Yeyw+1piN7YP0b+5AvAd15iLqpiw8VbCCV9nu7EEX2rg/ykR+hbwOmBbZ055kXQ70QvaOcj557nFMF3srwR83vaIh5KPUu79LiLsujrwY+BHwEdsD5n7HsLeDcCNRCtLpzBDlph+yh2f2MVe49z77EzJgRZ6TnImOxEO5XHiTvkCYE1C5LuOXODqlfMEsP1PSU3aRVq9w5T0PmLnuQKh4rS+Q5VoPqKfcEQOVNLxyUZVFLKHpM3dYKwcRAO/Qv6tc25kE3m6VgY5K1SbjiKqb88DvgscB2xAiD+MmBwHOQJesu2k/HOc7RMlNSlsmsf2YDvlHJ6v055TGBnFgRbGAr8l+tPeb/uRjuO3Svp+TVsTJC1s+58wo+imyd/5RfTlHOchnPlUos80hw8BR3uANJ7tZ2tecDcDVqnyxWnn3VYv4nr0hfrWloRrDjeXtA9RqHIN0WvZdJDzD4HvEX8rWxA581OIXsbnM+xVPcOfYOawZk60YloqKNoJeHtSEJozZ12JUyV9AriQ/u1Tuf2zx6Sd92UD7GVpEheC4kALY4GVBiscsn14TVvfBH6rGFwtQsbva7kL84CByAqR9OyJJ7a7DoROr11Zw9SDwFJAFUpeMh1rhKRTiZzvZODlamnEbrkObwC+TbQATSHk9m4AHqHjAl6DuW3/OH0/VdLetr+QYaeT84mCsyvoe6+5bEsMSf+47cckLQUc2cDeC+n8A+iLghjILRJ7MxHh2YyOdizqV/MWOig50ELPkPRLhgiR5hY4SFqVvgvDr9uqoO2wP2WgYx3BOdPo/l6roqRJI7RT/c4WJHaKN6eX1iek6Taps64u9u8DVm1SCT3A3lyELN3GRPXxRsBTdfsjJd1PFF5V1cenEw5LkLeTGstCAinkvb7TkIUW7D1IfK4vtGGvEJQdaKGXHNW2wXTn/y86Jk8oY1xYx7mdeagJRHXlX+vasZ0jUt6N1n9nA7ibKBx6tCV78xKtRAumx1+JHWldHqW/atVjHc9zd1IXSvov27/KOLcfkjYk8terEIMNJgL/sr1gpskHgTbFK+4mJrs80aLN2Z6yAy2MKyRNoW+nNy8pZ+l8qbfOis2XCGHvc3Lybkmd5h7bK+espYu9xYhdKMTus/HFUTGGbE1iZ9uZK6sVDZB0ApEnngbcRFSU3ljlpscCKSowPxEurQqlRhwNGGDrVmJe7tnEjnsXYMXc3lBJ5xK/v6vo/znktrFcTVQI30KDz7XQn7IDLfQMSWfZ/sgApzeDnF7LUchZtlaxaftlSVOb7IgrJH2EyJFdTYQxj5W0v+2fN1zmwQ3Pr1iKGO/1ADEM+hHgqSHPGAGpWnk/YCnbu0t6I5FDv7CurRajApW9ByVNdMggnizpDiBXXOG89GiLIVt3CnmUHWihZ0ha3Pajo9Vr2fFzcnKWJzN4ftbO1F6VdC0hx3Yz/aeT1N3h3QlsXu06U0XpFbkCBaNBEsh4E5H/3BhYDfgH8FvbWRd0ST8DbgN2sb1acqg3NFBKeh8dMoM5jjjZuZYQA/kREV5+FPhok88j5Y9XTE+bthONSsRidqfsQAs9w/aj6WsrjhLay1kS7QMDWRLYl8hv5fJ/Dc7tZMKAC+CTxPvNoqPISfS/cahV5NRJKkS6WzGJ5un02JIoeMrdES1ve1tJ26ef8Wxy1LVRjFpbjyhIAthb0lsyw647E7//zxB/I0sCH8xZV1rbJkSbzsPEZ7CkpF0Htj/VsDdaEYvZmrIDLfScQQowpmfmolrLWXbYXI4QDH87IcZ9Yq+rGSUdSeS0KiGF7Yhh0E1bO1pB0mfp23m+SLSwVI8pzhfTvwF4J/Ab22tLWp6QQVw/w9ZdwJrVWlKO+o6c1MEg9n9me9vMc28DdrA9NT1fkXif62TaG/MRi1mRsgMtjAWOo0sBRo6hNnOWSZHny0TI9UhicPJLDW12trPMRTTb175ZsL1/kvJ7Szr0fbcj5fdN4gahaevPMsTnuW8VaWiJg4BLiB3Z6cT7/2gDewsRYWWIKuE2ydIPTsxZOU8A279TTLbJpdWIRSEoDrQwJmhagNF2T2kSYliHEGbYl2i0n1RFC3MVYToLV1LocWtgwxrr6nTAnaHL3SU9D/yeEESvI8rQyX3ADyXNQZ/I/dN1jVQydJKWlzS37X+nsOTqwE/cIbdY0+7lCn3dDYn3v3eDXsnDgDtS5bGICMOXMm21za2KSTanpec7Abc2sHeJpEvpi1hsCzRu35ndKSHcQs9powBDfQOrP0j0MVYXnu2Bx23vW3NND9NfAabTWdkNx4YN+Fl32G6i11vZmUgU6pxue7WGtlYiNGu3J1SEfmj7qgw7k4mowjLEBft84E22/ytzXR8gxDGeTs8XAjbJ3X1LWpz+hTWP1Tx/MFF8ARfaXjxzXXMDexLDAgCuBb7nDBnEdKP2BuJ9Vvaus31uztoKfRQHWug5qQr3cSKkuS8RSjvedm1pOkm32l53uGO9IoVdKyYQzuUdzhwXNsjP+KTtHzQ4fyJR7PMxohjmLOLCO932djVt3Z5ylfsTgubHNrlh6KYeVNeepJVt3z+Y86ujapR2r4Nie9OR2kr2FgUWHRhCl/Qm4Anbf6tjr+P82pXoheEpIdxCz7H9x3ThaCOHOb+k5Ww/BFRzEOfPNZbu3ncElrV9aFI6ep3tm4c5dTC26vi+KnLaOnd93WjoPI8m1ngl8PWO93m4pKmDnzkoL6aK2V3pe++NcnldjtW9ju0H7E73KS61VI3qOsgRcCxwfJfjixC6uDtk2r1d0nq2b8leWWEmyg600DOSczqIKP2fQIS9XgKOtX1Ips0tgBOAzvFZn7R9aaa97xHi25vZXkUxX/Qy2+sNc+osiaSPAWfZnt7ltQXr5kMVusR7EL2fZ6Ybmo+4/pCAyt5JhCDDd9OhPYFFbH80w9Y8A6uzux0boa1tgEtsT5P0ZaJ96lDbd9S0M2i0RNLduaF5hZbwG4kbtunQfDB8oTjQQg9JPZvvAXa3/Yd0bDlibNUlto/OtDs3MQUE4P6cvFGHrSoEOSNMKOnO3PJ/SW8gdhlV9ex1RCHMI4OfNfoMkcsDmo29kjQvoRyUs4MdaGt+opf2XenQ5cBXuzn8Edi63QMGe3c7NkJbd9leXdJbga8SVdsH2t6gpp2ptleq+9oI7I6qWMnsSgnhFnrJzkRv2owqStsPSdqJmFs4Ygcq6Qu2j0hP32f77I7Xvm77fzPX+GLKCVZzNxelbxxUDicDZwDbpOc7pWObN7DZBkMNpc4eeyVpK0IAfy5gWUlrAofUrYqesZBwlI0qZSW9Dng9MK9i2HpVIDYJmC/TbDUO7b3ACbYvkvTVDDsPqovAvaT3EFGVWkj6T6KHeQVCxP8w289krKvQhbIDLfSMoUJSdcNVnTuHgbuI3F1FOndHouR/HeDHxHzRL3c66Jr2uhXBjNmxWk1JggCbETJ51Q6+SShyReDzzDwEe8QOXtKuRO/ouvRvDZkG/Nj2LzLWdSGh+bs5Eb59jqjqrRWpUGj7XkQITtyWDq9L9JRuaft3Ne1dkuxcSxSGLZAT7i50p+xAC71kKDWfuko/GuT7bs9HjO3TkxN4Z7Lzftv35doDnkw77Kofb3uiqX3MIGljZnZQdQdqV7xo+2n1V9trsoM/G/g+0fKUNQTb9inAKZI+ZPucBmvp5CPAFsBRtp9K7TH7Z6ztAUlvJoqFqpuMa4g8fo6a1uK2D0jfX5p6aAstURxooZesIalbOEnAPDVteZDvuz2vy38Az9o+WdKikpatcrYZ7EbkQI9O67qBaBcZE0g6FVgemEyfgzKQ60DvkbQDMDHtrj5LvOdcXrL9vQbnd3K1pO8QLToGrifCy7VvaByavE8kWw8QxXAP5CwqiU6sbPtzncclHW77i3XtpcK36g5mYudzZwqCFIISwi2MCyS9TF914bz0DSMWMI/trNYJhbbuusTIrBUlLQGcbfstw5w6SyLpPmBVt3RhUExLOQB4N/FZXEpUp2ZpE0s6mBgKfS7951rWdgSSLidCm5Xoxo6EKMO7Bj9rUFut/p0MUuB0V92qWYUgyCt0j8LYLQqCzI4UB1ooDIFCSWct4PaOHF7OhexYhpYazBqU3DYKCcPPul392taQ1G3nn+UIuuVicwUHWvw7+RQxv3Y5QpaxYgFibNuOdddWGD1KCLdQGJoXbFtSVYWbK8rQWazyFcbYgGP1aQkvANwr6Wb67/Dqagl/2/Y+GkSjuEEV7rI55w3CZZK2I5SWIArEsvqFae/v5AzgYkKnt7PaeFqTcKukK22/c7hjhXqUHWihMASSPk80oG9OXNR2A86wfWwDm61o37aJ+rSEu2L7mpr21rF922B269obYHs1YFU68uQ5RU4KYf756StqmkDfkHO7xoSc0fgPG0AoAAATSklEQVQ76bC9PFFUtJ3tN9U8dx7iPf4a2IT+LTuX2F55kFMLI6A40EJhGCRtTkcOz/blDe1lt9WMNt0KVXKLV0aDlGvchHCgvyKEOK63/eFergva/TtJOdRtCcf5ZsIp/8L2lJp29gb2AZYg2mwqB/oMMSDguNw1FooDLRSGRNJewGm2/9mizbHsQFspXuk49y3AwYSk4hz0SchlFa9ImgKsQQy+XkPSYsTnU0uIQtJcRNFQtaO7h5hi02hQuqRJ9G//qRV2lbQ70dr0eiK0fBZwftPQtaS92tgNF/pTcqCFwtAsBtyS+udOInYWte861X+O53wd7TuVQ6k1ULttOotXJN3V8dICNGs7OZGYsHMbmX2bA3jO9iuSXkrO6gliYsyIUejzXkCMaavECjYBDpC0te176i5K0ieJ3Pbz9FW9migGqsNxwG+BHWzfmmy3sct5TNIC7q/V+1U3kGgslB1ooTAsChWAdxP9musSu4ITbf9+yBNnISQtCCxM+8UrN7mmHuww9o4npOm2Az4H/AuYbHvEvbSSrgS+MTDEKuldxDDy2hNWJD0AbOT84d6VndcSMo/bE3NtzyJm49a6SehitxWt3kJ/igMtFEaApDUIB7oFcBWwIXC57S/0dGGjgEL7dzH6hyL/lGnrG8BE4Bf0r+ptvPORtAwwyfZdw/zTgefdP1jxjKT7bK+SsZZLgA/afnbYfzxym28g8qDbE4VA5zpT07kqXJN0GDDF9hljsZhtVqM40EJhCFIRxi7A3wn5uPNsvyhpAvCA7eV7usCWkfQZImf5OH3VqW6QA+02cNquoV3bxebqzCw1OGL9Wkm/A97sAVN6UsXqFNtvzFjTWsRQgJvof6PQSn9vUnHa3vlj/lrR6i30p+RAC4WhWYTYWfQb+5TycFv2aE2jyT6Emk4r+rw54dChUMwDXZ0o+pnh4Ikd7kj5CXCOpD2rzzXtZr8DnJq5tB8QrSJTaKb1S1pPt/miOdNdKlrR6i30p+xAC4VhSOHbt6Wn19m+s5frGU3SjnFz2y+1aPO9RLVrZ99m7k7qXturtrCmzwBfoG982XTCuWRVqrYdDh2tnKVivFnn55AVmi8EZQdaKAyBpM8Cu9O3wzlN0gnjuCXgIUJk/SL6hyK/lWNM0vcJJ7UpEQL/MHBzg/X9VtKqtu9tYAPbx0n6ETBnej4trXeRzKKpi1MLyi9pqNGbaGu+KACS3kfMfF2CqFxeCrifvjaeQgZlB1ooDEFq6djIMci5kmj7bW5OcKyThApmwvZXMu1VO6nq62uAi22/bdiTu9t7B9GC8hjhqKo2oNqfR7pJ2Lrabaew5oW218mw1ZpGb7LXas5S0p3EXNYrUjHRpsBOtj+eY68QlB1ooTA0on//4st0n2wxLqgcZXJ02P5XQ5PPpa/PJnWdJ4HFG9g7EdiZdnKN5wFnS/ow0Ut6ATGsuzYta/RC+znLF20/KWmCpAm2r5L07XaWOvtSHGihMDQnAzdJOjc9fz9xER+XJJ3ZU4niKST9HdglR1wgcaGkhYgc3u1Ewc8PGyzxb7YvaHD+DGz/MCkSnUdU9X7Sdi3RCEmb2f61pA8O8jPqFDdVNicSU11mtNo4puM0mZDzVLopuhY4XTG7dPow5xSGoYRwC4VhkLQ2MSgZoojojl6uZzSRdAMhJnBVer4J8HXbG7dge25iNuvTDWwcDyzEzLnGOm0s+3U+JdqU7gLuSLZGnO+VdLDtgyWd3OVl295tpLYG2D0f2KutIp+UeniOEMzfEViQkEAsA7UbUHaghUIXJC3S8fTh9Jjx2ji+8MxfOU8A21crfzRX1Vv5aeIGxMD1kr7nzIHaxLD0fxPKUDOWSb02lgUGPP/FIMdHwlwAdZSQRsjCwD2KsXIzdorOHwNX2XgFOAVA0m+AcTkY/tWi7EALhS6kohDTPd+ZXRwy1kmh6tvp64fcCVjH9gcy7Z0FTANOS4d2ABayvU2GrYnA4baz8pSjgUZpMIBGYQxcl5/x56YSgbM7ZQdaKHRhFIpCZhV2I0TRq13ZdelYLqsN6Nu8SlJWC4rtlxXTXVpB0uXANrafSs8XBn5q+//VMDMxnde1sCw3UtGmoxzqx7wKP2NcUxxooTAMqUCkCkFeZ/u8Hi9p1HCMbWtFfi5xu6QNbd8IIGkD4NYG9iZLugA4m/6hzdrFOsCilfNMNv6ZhAbqsDIx0aVrpIL601gAkLQhcCywChEmnghMd82pPYMVNxHrnTdnbYU+igMtFIYgFa2sAJyZDu0haXPbe/ZwWa2TnNKg5ObegHWAGyRVxTBLAVMVcz1z+jfnIVphOrV06+ZAK16WtFRVqCNpaervyu4dJUH244iJM2cTE4B2AVbMsLPVEK9dmGGv0EHJgRYKQyDpfmAVp/8oSUT+npyJHWMZSX8D/kzcKNzEgB1VbkgxOaVBGagx/GoiaQvgBOAa4v2+Ddjd9qU1bIzKRBNJt9peVx3DzMv0lLFH2YEWCkPzILFrqi70S6Zj443XEao32xOFPhcBZzbo/wTCQaYc4ZL0n56SNc4sjfg6lr7q0euAvW0/krG2S1KL0obp0D6uP8/zmLo/d4Q8m3pUJ0s6gugBnZBrTNJiwNeBJWy/RzFUfCPb47an+dWg7EALhSGQdA2wHn36resRObynoVFoc8yS+jW3J8QPvmL7uAa2DgU+CvyevvConTnOLBX+nEH/KuEdbW+eae99wNvT06ttZ4U1Jf2SmcO/TxN/Kz+o27aTdu6PE/nPfYm+zeNtZ928SbqYEAU5wPYakuYA7rD95hx7haA40EJhCAZrJ6h4laolXxWS43wv4TyXIaTtTrL9lwY2pxKzN19oaY2Tba853LER2voGcUN0ejq0PXCLM4ZWSzoGWJS+XPm2wDOEU51ke+cMm/MCS9meWvfcLrZusb1eZxg49/dW6KOEcAuFIagcpKRJ9A9BjishBUk/AVYDfkXsOu9uyfTdhHLQEy3Ze1LSTvQ5qu2JoqIc/gtY0/YrAJJOIdSIajtQYGPb63U8/2WH06odBpe0FXAUsQNdVtKawCENIh7TJb2WtEtOVb7ZilCFoDjQQmEI0oiqQ4DnCRUX0aA9YQyzE9EWsjfwWWlGDVE17aRW+0QHhwF3SLqb/tJ7uY5gNyIHejTxOdwANFEBWgioboYWbGDnNQMqepcCXpNey9l9HwysD1wNYHuypCa9yfsREYXlkwLRosRouUIDigMtFIZmf0IMoG5xySyF7ewClWE4BTichtNTJB1u+4vA+i3mnSvnfhVxo/B24H8ybX2OkCn8fbK1LPDpJIN4Soa9F20/3XEjAw2ED2zfntIRK6X1TbX9Yq69QlByoIXCEEi6BPig7Wd7vZZZkSqM2YKdKcDqwG1tSuelMWHV+m62/VgDW3MTwgoQDqq23q+kXwF7Al8GrgS+BHyIELeY0/YemWvbEzh9gOrS9raPz7FXCIoDLRSGQNJapJFm9A9BtqnWM26R9C3i93YB/X9/tdpYJB0JfIIIiz5LXyg9O8Qs6Urb7xzuWA17GxPFV5258p/UtLEN8DWiynheorUI4FLgUNv/HuzcYex2K74qfaUNKQ60UBiCNA3jegaEIG3nhOVmO1J4dCBN2ljOt711wzXNA8wHXAVsQp9oxCTgEnfM4axh81RgeWAyfQPYnXOjpZjb+X/EQO1T6d/+M+JRawNsTgFW7xAEmQjcZftNOfYKQcmBFgpDM6ft/Yb/Z4Vu2N60LVvpop9bzNTJJ4F9gCUIHduKaYSEXg7rAqu6nR3JC0RB19zEjrsNm5cAP5P0g/T8k+lYoQHFgRYKQ3NxqsQdOMB5XLWxjBaSFgQOok+s4BqiHaN2C0WaxvKKpAVzzu/gBuAs4MO2j5W0K5FnfJgQacjhbkLN6dEG66rkBb9FhLzXbjH3/kXCaX4qPb8c+FFLtmdbSgi3UBiCNBd0IPY4nQfaNpLOIZxLFfLeGVjD9mBTQoazdz6wFuEAOqexjDhUKul24F22/yHp7cBPgb2ANQnd49rtHSlUvSahWJXdriPpOmCPphKKhVeH4kALhcKo0aZyUDp3127H6+SkJd1pe430/XeBv9k+uMnaBlOsGitKVWmO6sHA0kTksSq+KjeCDSgh3EKhC5K+YPuI9P02ts/ueO3rOXJvsynPSXqr7ethxoX8uVxjtk9pQeJuoqQ5bL8EvBPYveO1rGviWHGUQ3Aioal7G31FToWGjFbzdKEwq7Ndx/cDm+u3eDUXMouzB/BdSQ9Lepgo0snqZYQZEneTSQUwktYcbpZpF84Erknh4OeIiS5IWoGa8naSqhuDaZKe6XhMk/RMzXWNJk/bvtj2E7afrB69XtSsTgnhFgpdGCC63a9frvTP1SdpCWO7kVORdBsxTPvqjs/nbtur1bSzIbA4cJnt6enYisBr6vaozgok4fyJxODx7H7cQn9KCLdQ6I4H+b7b88IAJO1H7HpOhD7HKenjwAK2v51pupvEXW2JQNs3djn2u8w1ATPabBajv5DCn5rYbJEN0td1O46ZuBkpZFJ2oIVCFyS9TFR5ilCEqdoJBMxje85erW1WIO0UNxyot6oYEn2r7dUz7Z5IixJ3bSFpL6Jd53H6HLpz32dh1qA40EKh0Dqdla5dXpvizEHOkuYDDgDenQ5dCnw1R3e2TSQ9CGww1vKKknayfVqKCMxErrJRISgh3EKhMBpMkLSY7cc7D0paLMdYkt/bA1iBkFXcKFXRjhX+zNicrzl/+rpAT1cxTik70EKh0DqSdiHCq58DqkKVdYAjgePqaglL+hnwIlEx+x7gYdv7tLfiZqTQ8krARfQv0ik7vHFM2YEWCoXWsf0TSX8jhpFXFbJ3AwfavjjD5KpV2Dc5q5vbWWlr/Ck95kqPMYGkTxAVyw8oKq9OJHLHfwR2tX1HTxc4i1N2oIVCYcwj6fbOOaADnxe6I+luYC3bL0ragYgIvJuQQzzI9tt6usBZnLIDLRQKo4akZQmd2WXo395RSyMWWKNDmEDAvOl59jzQNpD0bdv7SPolXdqbMt5n27zUUQm9JfCTVOh0haQjeriucUFxoIVCYTQ5jwgb/pKMfs0K2xNbW1G7nJq+HtXTVQzOK5IWB/5JyBZ+reO1eXuzpPFDcaCFQmE0ed72d3q9iNHC9m3p61jVwj0QuJVQIbqgmvKSxO8f6uXCxgMlB1ooFEaNlHd7I3AZ41hCTtIbgcOAVYF5quNjYdqJpDkI9ad/dhybD5hg+1+9W9msT9mBFgqF0eTNxAzQzehQ6GH8ScidTCgRHQ1sCnyMMTKsw/ZLkt4l6RLb0yR9GVgbOBQoVbgNKDvQQqEwaiSFnlVtv9DrtYwmkm6zvU6nylJ1rNdrA5B0l+3VJb0V+CrRj3ug7Q2GObUwBGPiDqlQKIxb7gYW6vUiXgX+LWkC8ICkz0j6APCaXi+qg2oG6HuBE2xfxBjqV51VKTvQQqEwaki6GlgduIX+OdBet3e0iqT1gPuIm4VDgUnAkd2mvvQCSRcCfwE2J8K3zwE3D6ZXXBgZxYEWCoVRI1V7zsQYrlqtTRpjdrjtz/d6LYORioa2AKYkVaLFgTfbvqzHS5ulKQ60UCgUMpE0RyrSudH2hr1eTzeSg7/H9sq9Xst4o1ThFgqFUUPSNPoUeuYC5gSm90o5aBS4mQiJ3iHpAuBsYo4sALZ/0auFdazhZUlTJS01hgZ8jwuKAy0UCqOG7RljtJKY+dbAmNypNWQe4EmiPcckiUGg5w40sTBwj6Sb6e/gx1Uu+tWmhHALhcKriqQ7bK/V63W0gaRHgG/R5zDV8bLHyjiz2SEX3QvKDrRQKIwakj7Y8XQCsC7wfI+WMxpMJNpV1OW1MbM7KY5ydCgOtFAojCZbdXz/EvAwEcYdLzxq+5BeL2I4JG0IHAusQuSiJzK+ctE9oTjQQqEwatj+WK/XMMp023mORY4DtiOKnNYFdgFW7OmKxgElB1ooFFpH0oFDvGzbh75qixlFJC1i+x+9XsdwSLrV9rqVpF86Nm5y0b2i7EALhcJoML3LsfmBjwOvJdR6ZnlmBeeZeFbSXMDkNEj7UYqUa2PKDrRQKIwqkhYA9iac51nAN20/0dtVzV5IWhp4nMh/7gssCBxv+8GeLmwWpzjQQqEwKkhaBNgP2BE4BTimcyZl4dVF0rzAUran9not44WyhS8UCq0j6UhCQH4aobl6cHGevUPSVsBk4JL0fM2knFRoQNmBFgqF1pH0CjF95SX690OKKCIq7ROvIpJuI1SSrq4KhzpnlxbyKEVEhUKhdWyX6NbY4kXbT4ea4gzK7qkh5Y+8UCgUximSfiVpWUIHdwdgoqQ3SjoWuKHHy5vlKQ60UCgUxi8nA5cSClCrEWH1M4CnicroQgNKDrRQKBTGMZJeA/wfMVD7VPpCt2NG7H5WpeRAC4VCYXzzAiFsMTchfF92TS1RHGihUCiMUyRtQYxbuwBY2/azPV7SuKKEcAuFQmGcIuk6YA/b9/R6LeOR4kALhUKhUMigVOEWCoVCoZBBcaCFQqFQKGRQHGihUCgUChkUB1ooFAqFQgbFgRYKhUKhkEFxoIVCoVAoZPD/AQHVXivTTCziAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6Z7spcObKvd",
        "colab_type": "text"
      },
      "source": [
        "## Resources:\n",
        "\n",
        "* You might want to refer to the [lecture notebook](https://github.com/shala2020/shala2020.github.io/tree/master/Lecture_Materials/Google_Colab_Notebooks/MachineLearning/L1) for revising the concepts.\n",
        "* You can also refer to the pre-work material for the first lecture on ML.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "bgYtBzelQQ6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "r--gY8YzQQ6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "import csv\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from math import *\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cXaNhZhWQQ6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "df = pd.read_csv('attrition.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8pjvjoyMKx7",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2-B3tV8-QQ6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy0 = pd.get_dummies(df.BusinessTravel)\n",
        "dummy1 = pd.get_dummies(df.Department)\n",
        "dummy2 = pd.get_dummies(df.EducationField)\n",
        "dummy3 = pd.get_dummies(df.Gender)\n",
        "dummy4 = pd.get_dummies(df.JobRole)\n",
        "dummy5 = pd.get_dummies(df.MaritalStatus)\n",
        "dummy6 = pd.get_dummies(df.OverTime)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "l1WwvwhQQQ6w",
        "colab_type": "code",
        "outputId": "24819d1f-3522-4328-e695-e0bc016ce529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "merged =pd.concat([df,dummy0,dummy1,dummy2,dummy3,dummy4,dummy5,dummy6],axis='columns')\n",
        "display(merged)\n",
        "final = merged.drop(['BusinessTravel','Department','EducationField','EmployeeCount','EmployeeNumber','Gender','JobRole','MaritalStatus','OverTime','ID'],axis= 'columns')\n",
        "display(final)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EmployeeCount</th>\n",
              "      <th>EmployeeNumber</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobRole</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>OverTime</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>ID</th>\n",
              "      <th>Non-Travel</th>\n",
              "      <th>Travel_Frequently</th>\n",
              "      <th>Travel_Rarely</th>\n",
              "      <th>Human Resources</th>\n",
              "      <th>Research &amp; Development</th>\n",
              "      <th>Sales</th>\n",
              "      <th>Human Resources</th>\n",
              "      <th>Life Sciences</th>\n",
              "      <th>Marketing</th>\n",
              "      <th>Medical</th>\n",
              "      <th>Other</th>\n",
              "      <th>Technical Degree</th>\n",
              "      <th>Female</th>\n",
              "      <th>Male</th>\n",
              "      <th>Healthcare Representative</th>\n",
              "      <th>Human Resources</th>\n",
              "      <th>Laboratory Technician</th>\n",
              "      <th>Manager</th>\n",
              "      <th>Manufacturing Director</th>\n",
              "      <th>Research Director</th>\n",
              "      <th>Research Scientist</th>\n",
              "      <th>Sales Executive</th>\n",
              "      <th>Sales Representative</th>\n",
              "      <th>Divorced</th>\n",
              "      <th>Married</th>\n",
              "      <th>Single</th>\n",
              "      <th>No</th>\n",
              "      <th>Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1102</td>\n",
              "      <td>Sales</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Female</td>\n",
              "      <td>94</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Sales Executive</td>\n",
              "      <td>4</td>\n",
              "      <td>Single</td>\n",
              "      <td>5993</td>\n",
              "      <td>19479</td>\n",
              "      <td>8</td>\n",
              "      <td>Yes</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>279</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Male</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Research Scientist</td>\n",
              "      <td>2</td>\n",
              "      <td>Married</td>\n",
              "      <td>5130</td>\n",
              "      <td>24907</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1373</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Other</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>Male</td>\n",
              "      <td>92</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>3</td>\n",
              "      <td>Single</td>\n",
              "      <td>2090</td>\n",
              "      <td>2396</td>\n",
              "      <td>6</td>\n",
              "      <td>Yes</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>1392</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>Female</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Research Scientist</td>\n",
              "      <td>3</td>\n",
              "      <td>Married</td>\n",
              "      <td>2909</td>\n",
              "      <td>23159</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>591</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>2</td>\n",
              "      <td>Married</td>\n",
              "      <td>3468</td>\n",
              "      <td>16632</td>\n",
              "      <td>9</td>\n",
              "      <td>No</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1255</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>1441</td>\n",
              "      <td>1</td>\n",
              "      <td>Female</td>\n",
              "      <td>90</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Research Scientist</td>\n",
              "      <td>1</td>\n",
              "      <td>Married</td>\n",
              "      <td>2066</td>\n",
              "      <td>10494</td>\n",
              "      <td>2</td>\n",
              "      <td>No</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1023</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>359</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1</td>\n",
              "      <td>1443</td>\n",
              "      <td>1</td>\n",
              "      <td>Female</td>\n",
              "      <td>82</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>Research Director</td>\n",
              "      <td>3</td>\n",
              "      <td>Married</td>\n",
              "      <td>17169</td>\n",
              "      <td>26703</td>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>1024</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>1476</td>\n",
              "      <td>Sales</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Medical</td>\n",
              "      <td>1</td>\n",
              "      <td>1445</td>\n",
              "      <td>4</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Sales Executive</td>\n",
              "      <td>3</td>\n",
              "      <td>Married</td>\n",
              "      <td>4162</td>\n",
              "      <td>15211</td>\n",
              "      <td>1</td>\n",
              "      <td>Yes</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1025</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>601</td>\n",
              "      <td>Sales</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>Marketing</td>\n",
              "      <td>1</td>\n",
              "      <td>1446</td>\n",
              "      <td>4</td>\n",
              "      <td>Male</td>\n",
              "      <td>97</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>Sales Executive</td>\n",
              "      <td>4</td>\n",
              "      <td>Married</td>\n",
              "      <td>9204</td>\n",
              "      <td>23343</td>\n",
              "      <td>4</td>\n",
              "      <td>No</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1026</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>401</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>1</td>\n",
              "      <td>1447</td>\n",
              "      <td>4</td>\n",
              "      <td>Female</td>\n",
              "      <td>86</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Laboratory Technician</td>\n",
              "      <td>2</td>\n",
              "      <td>Married</td>\n",
              "      <td>3294</td>\n",
              "      <td>3708</td>\n",
              "      <td>5</td>\n",
              "      <td>No</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1027</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1028 rows × 62 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Age  Attrition     BusinessTravel  DailyRate  ... Married  Single  No Yes\n",
              "0      41          1      Travel_Rarely       1102  ...       0       1   0   1\n",
              "1      49          0  Travel_Frequently        279  ...       1       0   1   0\n",
              "2      37          1      Travel_Rarely       1373  ...       0       1   0   1\n",
              "3      33          0  Travel_Frequently       1392  ...       1       0   0   1\n",
              "4      27          0      Travel_Rarely        591  ...       1       0   1   0\n",
              "...   ...        ...                ...        ...  ...     ...     ...  ..  ..\n",
              "1023   56          0      Travel_Rarely       1255  ...       1       0   1   0\n",
              "1024   47          0      Travel_Rarely        359  ...       1       0   1   0\n",
              "1025   24          0      Travel_Rarely       1476  ...       1       0   0   1\n",
              "1026   32          0      Travel_Rarely        601  ...       1       0   1   0\n",
              "1027   34          0      Travel_Rarely        401  ...       1       0   1   0\n",
              "\n",
              "[1028 rows x 62 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobLevel</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>Non-Travel</th>\n",
              "      <th>Travel_Frequently</th>\n",
              "      <th>Travel_Rarely</th>\n",
              "      <th>Human Resources</th>\n",
              "      <th>Research &amp; Development</th>\n",
              "      <th>Sales</th>\n",
              "      <th>Human Resources</th>\n",
              "      <th>Life Sciences</th>\n",
              "      <th>Marketing</th>\n",
              "      <th>Medical</th>\n",
              "      <th>Other</th>\n",
              "      <th>Technical Degree</th>\n",
              "      <th>Female</th>\n",
              "      <th>Male</th>\n",
              "      <th>Healthcare Representative</th>\n",
              "      <th>Human Resources</th>\n",
              "      <th>Laboratory Technician</th>\n",
              "      <th>Manager</th>\n",
              "      <th>Manufacturing Director</th>\n",
              "      <th>Research Director</th>\n",
              "      <th>Research Scientist</th>\n",
              "      <th>Sales Executive</th>\n",
              "      <th>Sales Representative</th>\n",
              "      <th>Divorced</th>\n",
              "      <th>Married</th>\n",
              "      <th>Single</th>\n",
              "      <th>No</th>\n",
              "      <th>Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1102</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>94</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5993</td>\n",
              "      <td>19479</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>279</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>61</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5130</td>\n",
              "      <td>24907</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>1373</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>92</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2090</td>\n",
              "      <td>2396</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>1392</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>56</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2909</td>\n",
              "      <td>23159</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>591</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3468</td>\n",
              "      <td>16632</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>1255</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>90</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2066</td>\n",
              "      <td>10494</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1024</th>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>359</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>82</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>17169</td>\n",
              "      <td>26703</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1025</th>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>1476</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4162</td>\n",
              "      <td>15211</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026</th>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>601</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>97</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>9204</td>\n",
              "      <td>23343</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1027</th>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>401</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>86</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3294</td>\n",
              "      <td>3708</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1028 rows × 52 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Age  Attrition  DailyRate  DistanceFromHome  ...  Married  Single  No  Yes\n",
              "0      41          1       1102                 1  ...        0       1   0    1\n",
              "1      49          0        279                 8  ...        1       0   1    0\n",
              "2      37          1       1373                 2  ...        0       1   0    1\n",
              "3      33          0       1392                 3  ...        1       0   0    1\n",
              "4      27          0        591                 2  ...        1       0   1    0\n",
              "...   ...        ...        ...               ...  ...      ...     ...  ..  ...\n",
              "1023   56          0       1255                 1  ...        1       0   1    0\n",
              "1024   47          0        359                 2  ...        1       0   1    0\n",
              "1025   24          0       1476                 4  ...        1       0   0    1\n",
              "1026   32          0        601                 7  ...        1       0   1    0\n",
              "1027   34          0        401                 1  ...        1       0   1    0\n",
              "\n",
              "[1028 rows x 52 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3ThKJ9WXQQ6y",
        "colab_type": "code",
        "outputId": "e0ccf3d7-3ea5-4c10-f795-350de6a9b482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "X = final.drop(['Attrition'],axis= 'columns')\n",
        "Y = final[['Attrition']]\n",
        "\n",
        "# encode = LabelEncoder()\n",
        "print('Original Features: \\n',list(X.columns),'\\n')\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Features: \n",
            " ['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'Non-Travel', 'Travel_Frequently', 'Travel_Rarely', 'Human Resources', 'Research & Development', 'Sales', 'Human Resources', 'Life Sciences', 'Marketing', 'Medical', 'Other', 'Technical Degree', 'Female', 'Male', 'Healthcare Representative', 'Human Resources', 'Laboratory Technician', 'Manager', 'Manufacturing Director', 'Research Director', 'Research Scientist', 'Sales Executive', 'Sales Representative', 'Divorced', 'Married', 'Single', 'No', 'Yes'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIhdb8bIQJHE",
        "colab_type": "text"
      },
      "source": [
        "# XGBClassifier training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rfL-WR3yQQ62",
        "colab_type": "code",
        "outputId": "9771687b-ca08-43be-9fc5-167fe5b069b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "#Normalizing X\n",
        "cols = []\n",
        "count = 1\n",
        "for column in X.columns:\n",
        "    if column == 'Human Resources':\n",
        "        cols.append(f'Human Resources{count}')\n",
        "        count+=1\n",
        "        continue\n",
        "    cols.append(column)\n",
        "X.columns = cols\n",
        "\n",
        "x = X.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(X)\n",
        "X = pd.DataFrame(x_scaled)\n",
        "\n",
        "# display(X)\n",
        "# split data into train and test sets\n",
        "seed = 7\n",
        "test_size = 0.33\n",
        "X_train, X_test0, y_train, y_test0 = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "X_test, X_test1, y_test, y_test1 = train_test_split(X_test0, y_test0, test_size=0.2, random_state=seed)\n",
        "\n",
        "# # fit model no training data For XGBoost\n",
        "\n",
        "\n",
        "classifier = XGBClassifier(\n",
        " learning_rate =0.1,\n",
        " n_estimators=10000,\n",
        " max_depth=25,\n",
        " min_child_weight=1,\n",
        " gamma=0,\n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " objective= 'binary:logistic',\n",
        " nthread=4,\n",
        " scale_pos_weight=1,\n",
        " seed=7)\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "y_predXG = classifier.predict(X_test)\n",
        "predictionsXG = [round(value) for value in y_predXG]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictionsXG)\n",
        "print(classification_report(y_test, predictionsXG))\n",
        "print(confusion_matrix(y_test, predictionsXG))\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(predictionsXG)\n",
        "display(y_predXG)\n",
        "\n",
        "print(\"\\n \\n \\n\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.93      0.92       227\n",
            "           1       0.59      0.49      0.54        45\n",
            "\n",
            "    accuracy                           0.86       272\n",
            "   macro avg       0.75      0.71      0.73       272\n",
            "weighted avg       0.85      0.86      0.85       272\n",
            "\n",
            "[[212  15]\n",
            " [ 23  22]]\n",
            "Accuracy: 86.03%\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W5eRWcOQeRK",
        "colab_type": "text"
      },
      "source": [
        "# Logistic regression training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjYSLs8TQYog",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "1bc6e306-86fd-4a2e-a523-6e8ccf689e5d"
      },
      "source": [
        "#Now the model of Logistic regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        " \n",
        "\n",
        "logmodel = LogisticRegression()\n",
        "logmodel.fit(X_train, y_train)\n",
        " \n",
        "predictionsLR = logmodel.predict(X_test)\n",
        "print(classification_report(y_test, predictionsLR))\n",
        "print(confusion_matrix(y_test, predictionsLR))\n",
        "print('Accuracy :',end=\" \")\n",
        "print(accuracy_score(y_test, predictionsLR)*100)\n",
        "display(predictionsLR)\n",
        "print(\"\\n \\n \\n\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92       227\n",
            "           1       0.62      0.44      0.52        45\n",
            "\n",
            "    accuracy                           0.86       272\n",
            "   macro avg       0.76      0.70      0.72       272\n",
            "weighted avg       0.85      0.86      0.85       272\n",
            "\n",
            "[[215  12]\n",
            " [ 25  20]]\n",
            "Accuracy : 86.39705882352942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWK3-MfLQkFy",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJtUZcu_OK5P",
        "colab_type": "code",
        "outputId": "f35a8dbf-0453-4380-c254-fc88b766c825",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "# Now using Random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42,max_depth=100)\n",
        "# Train the model on training data\n",
        "rf.fit(X_train, y_train);\n",
        "\n",
        "\n",
        "predictionsRF = rf.predict(X_test)\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",100*metrics.accuracy_score(y_test, predictionsRF.round()))\n",
        "display(predictionsRF)\n",
        "print(\"\\n \\n \\n\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 86.39705882352942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0.213, 0.027, 0.092, 0.04 , 0.06 , 0.089, 0.23 , 0.655, 0.08 ,\n",
              "       0.059, 0.219, 0.294, 0.411, 0.087, 0.295, 0.11 , 0.214, 0.027,\n",
              "       0.091, 0.138, 0.123, 0.092, 0.151, 0.096, 0.014, 0.257, 0.355,\n",
              "       0.346, 0.121, 0.184, 0.197, 0.708, 0.065, 0.057, 0.406, 0.106,\n",
              "       0.062, 0.715, 0.086, 0.192, 0.17 , 0.033, 0.03 , 0.157, 0.264,\n",
              "       0.444, 0.119, 0.157, 0.317, 0.378, 0.602, 0.117, 0.047, 0.13 ,\n",
              "       0.191, 0.166, 0.257, 0.12 , 0.434, 0.515, 0.162, 0.397, 0.338,\n",
              "       0.443, 0.055, 0.247, 0.035, 0.2  , 0.205, 0.128, 0.332, 0.714,\n",
              "       0.012, 0.631, 0.259, 0.721, 0.167, 0.085, 0.618, 0.09 , 0.2  ,\n",
              "       0.071, 0.106, 0.295, 0.107, 0.174, 0.433, 0.053, 0.083, 0.264,\n",
              "       0.046, 0.108, 0.07 , 0.102, 0.714, 0.587, 0.103, 0.155, 0.059,\n",
              "       0.225, 0.245, 0.16 , 0.228, 0.212, 0.271, 0.04 , 0.419, 0.172,\n",
              "       0.434, 0.061, 0.494, 0.166, 0.378, 0.504, 0.236, 0.095, 0.062,\n",
              "       0.016, 0.099, 0.22 , 0.3  , 0.106, 0.136, 0.112, 0.102, 0.081,\n",
              "       0.291, 0.336, 0.3  , 0.245, 0.245, 0.112, 0.346, 0.083, 0.256,\n",
              "       0.167, 0.071, 0.088, 0.05 , 0.266, 0.221, 0.467, 0.14 , 0.289,\n",
              "       0.032, 0.18 , 0.422, 0.347, 0.398, 0.077, 0.046, 0.065, 0.175,\n",
              "       0.153, 0.405, 0.018, 0.101, 0.316, 0.41 , 0.136, 0.256, 0.14 ,\n",
              "       0.055, 0.175, 0.048, 0.071, 0.056, 0.421, 0.194, 0.218, 0.096,\n",
              "       0.027, 0.356, 0.03 , 0.196, 0.132, 0.424, 0.33 , 0.098, 0.246,\n",
              "       0.195, 0.054, 0.235, 0.337, 0.1  , 0.374, 0.452, 0.037, 0.45 ,\n",
              "       0.037, 0.101, 0.078, 0.254, 0.14 , 0.088, 0.065, 0.119, 0.219,\n",
              "       0.02 , 0.146, 0.082, 0.091, 0.052, 0.099, 0.106, 0.034, 0.03 ,\n",
              "       0.015, 0.027, 0.154, 0.04 , 0.23 , 0.222, 0.313, 0.079, 0.209,\n",
              "       0.151, 0.266, 0.153, 0.287, 0.138, 0.035, 0.133, 0.01 , 0.281,\n",
              "       0.372, 0.108, 0.024, 0.234, 0.407, 0.291, 0.264, 0.059, 0.201,\n",
              "       0.195, 0.238, 0.024, 0.053, 0.135, 0.163, 0.07 , 0.209, 0.283,\n",
              "       0.06 , 0.167, 0.03 , 0.035, 0.06 , 0.16 , 0.094, 0.033, 0.087,\n",
              "       0.161, 0.12 , 0.034, 0.162, 0.034, 0.528, 0.173, 0.163, 0.059,\n",
              "       0.599, 0.059, 0.255, 0.379, 0.009, 0.227, 0.159, 0.09 , 0.292,\n",
              "       0.427, 0.021])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1oZfmqLQny3",
        "colab_type": "text"
      },
      "source": [
        "# SVM Classifier training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfmS9CPzPFw0",
        "colab_type": "code",
        "outputId": "1a20bafc-ddbe-41ef-963e-44542d2a8d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "# Now using SVM Classifier\n",
        "from sklearn.svm import SVC\n",
        "svclassifier = SVC(kernel='linear')\n",
        "svclassifier.fit(X_train, y_train)\n",
        "\n",
        "y_predSVM = svclassifier.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_predSVM))\n",
        "print(classification_report(y_test,y_predSVM))\n",
        "print('Accuracy :',end=\" \")\n",
        "print(accuracy_score(y_test, predictionsLR)*100)\n",
        "display(y_predSVM)\n",
        "print(\"\\n \\n \\n\")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[218   9]\n",
            " [ 23  22]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       227\n",
            "           1       0.71      0.49      0.58        45\n",
            "\n",
            "    accuracy                           0.88       272\n",
            "   macro avg       0.81      0.72      0.76       272\n",
            "weighted avg       0.87      0.88      0.87       272\n",
            "\n",
            "Accuracy : 86.39705882352942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrC69JvAQq3w",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpsRhPVgRPSo",
        "colab_type": "code",
        "outputId": "8678480c-78d0-4729-c14b-22764bbe8302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "\n",
        "#Initializing Neural Network\n",
        "classifierNN = Sequential()\n",
        "classifierNN.add(Dense(104, input_dim = 51, activation = 'relu'))\n",
        "classifierNN.add(Dense(5, activation = 'relu'))\n",
        "classifierNN.add(Dense(8, activation = 'relu'))\n",
        "classifierNN.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling Neural Network\n",
        "classifierNN.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Training our Model\n",
        "for i in range(0,51):\n",
        "  for j in range(0,688):\n",
        "    if X_train.iloc[j,i] < 0.5:\n",
        "      X_train.iloc[j,i] = -1\n",
        "classifierNN.fit(X_train, y_train, batch_size = 10, epochs = 1000)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_predNN = classifierNN.predict(X_test)\n",
        "y_predNN = y_predNN.round()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_predNN)\n",
        "print(cm)\n",
        "print(classification_report(y_test,y_predNN))\n",
        "print('Accuracy :',end=\" \")\n",
        "print(accuracy_score(y_test, y_predNN)*100)\n",
        "# display(y_predNN)\n",
        "\n",
        "\n",
        "print('\\n\\n\\n')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.8212\n",
            "Epoch 2/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.3864 - accuracy: 0.8343\n",
            "Epoch 3/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.3521 - accuracy: 0.8343\n",
            "Epoch 4/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8445\n",
            "Epoch 5/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.3121 - accuracy: 0.8590\n",
            "Epoch 6/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.2998 - accuracy: 0.8692\n",
            "Epoch 7/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.2866 - accuracy: 0.8735\n",
            "Epoch 8/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.8823\n",
            "Epoch 9/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.2548 - accuracy: 0.8895\n",
            "Epoch 10/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.2387 - accuracy: 0.9026\n",
            "Epoch 11/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.9055\n",
            "Epoch 12/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.9113\n",
            "Epoch 13/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9273\n",
            "Epoch 14/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.9360\n",
            "Epoch 15/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.1606 - accuracy: 0.9477\n",
            "Epoch 16/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.1492 - accuracy: 0.9549\n",
            "Epoch 17/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.1316 - accuracy: 0.9637\n",
            "Epoch 18/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.9695\n",
            "Epoch 19/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.1022 - accuracy: 0.9738\n",
            "Epoch 20/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0998 - accuracy: 0.9709\n",
            "Epoch 21/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0764 - accuracy: 0.9826\n",
            "Epoch 22/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9826\n",
            "Epoch 23/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9811\n",
            "Epoch 24/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9898\n",
            "Epoch 25/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0502 - accuracy: 0.9898\n",
            "Epoch 26/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0439 - accuracy: 0.9855\n",
            "Epoch 27/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9942\n",
            "Epoch 28/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9898\n",
            "Epoch 29/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 0.9927\n",
            "Epoch 30/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9942\n",
            "Epoch 31/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 0.9985\n",
            "Epoch 32/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 33/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 0.9956\n",
            "Epoch 34/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.9985\n",
            "Epoch 35/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 36/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 37/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 0.9956\n",
            "Epoch 38/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9898\n",
            "Epoch 39/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9942\n",
            "Epoch 40/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.9985\n",
            "Epoch 41/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0159 - accuracy: 0.9956\n",
            "Epoch 42/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 43/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 44/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 45/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 46/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 47/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 48/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 49/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 50/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 51/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 52/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 53/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.8467e-04 - accuracy: 1.0000\n",
            "Epoch 54/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.7498e-04 - accuracy: 1.0000\n",
            "Epoch 55/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.2120e-04 - accuracy: 1.0000\n",
            "Epoch 56/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.4163e-04 - accuracy: 1.0000\n",
            "Epoch 57/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.8300e-04 - accuracy: 1.0000\n",
            "Epoch 58/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.2756e-04 - accuracy: 1.0000\n",
            "Epoch 59/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.8159e-04 - accuracy: 1.0000\n",
            "Epoch 60/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.5621e-04 - accuracy: 1.0000\n",
            "Epoch 61/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.0524e-04 - accuracy: 1.0000\n",
            "Epoch 62/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.7139e-04 - accuracy: 1.0000\n",
            "Epoch 63/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.4783e-04 - accuracy: 1.0000\n",
            "Epoch 64/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.0846e-04 - accuracy: 1.0000\n",
            "Epoch 65/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.8351e-04 - accuracy: 1.0000\n",
            "Epoch 66/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.5702e-04 - accuracy: 1.0000\n",
            "Epoch 67/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.3780e-04 - accuracy: 1.0000\n",
            "Epoch 68/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.1764e-04 - accuracy: 1.0000\n",
            "Epoch 69/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.9863e-04 - accuracy: 1.0000\n",
            "Epoch 70/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.7467e-04 - accuracy: 1.0000\n",
            "Epoch 71/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.5919e-04 - accuracy: 1.0000\n",
            "Epoch 72/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.4849e-04 - accuracy: 1.0000\n",
            "Epoch 73/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2347e-04 - accuracy: 1.0000\n",
            "Epoch 74/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1027e-04 - accuracy: 1.0000\n",
            "Epoch 75/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9924e-04 - accuracy: 1.0000\n",
            "Epoch 76/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8214e-04 - accuracy: 1.0000\n",
            "Epoch 77/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7019e-04 - accuracy: 1.0000\n",
            "Epoch 78/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6036e-04 - accuracy: 1.0000\n",
            "Epoch 79/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4980e-04 - accuracy: 1.0000\n",
            "Epoch 80/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4266e-04 - accuracy: 1.0000\n",
            "Epoch 81/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3489e-04 - accuracy: 1.0000\n",
            "Epoch 82/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2665e-04 - accuracy: 1.0000\n",
            "Epoch 83/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2370e-04 - accuracy: 1.0000\n",
            "Epoch 84/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1425e-04 - accuracy: 1.0000\n",
            "Epoch 85/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1218e-04 - accuracy: 1.0000\n",
            "Epoch 86/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0602e-04 - accuracy: 1.0000\n",
            "Epoch 87/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.9880e-05 - accuracy: 1.0000\n",
            "Epoch 88/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.5772e-05 - accuracy: 1.0000\n",
            "Epoch 89/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.2314e-05 - accuracy: 1.0000\n",
            "Epoch 90/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.7900e-05 - accuracy: 1.0000\n",
            "Epoch 91/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.2508e-05 - accuracy: 1.0000\n",
            "Epoch 92/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.1765e-05 - accuracy: 1.0000\n",
            "Epoch 93/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.5999e-05 - accuracy: 1.0000\n",
            "Epoch 94/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.3074e-05 - accuracy: 1.0000\n",
            "Epoch 95/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.9822e-05 - accuracy: 1.0000\n",
            "Epoch 96/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.8377e-05 - accuracy: 1.0000\n",
            "Epoch 97/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.5727e-05 - accuracy: 1.0000\n",
            "Epoch 98/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.1603e-05 - accuracy: 1.0000\n",
            "Epoch 99/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.0362e-05 - accuracy: 1.0000\n",
            "Epoch 100/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.6741e-05 - accuracy: 1.0000\n",
            "Epoch 101/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.5292e-05 - accuracy: 1.0000\n",
            "Epoch 102/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.3151e-05 - accuracy: 1.0000\n",
            "Epoch 103/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.0283e-05 - accuracy: 1.0000\n",
            "Epoch 104/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.8453e-05 - accuracy: 1.0000\n",
            "Epoch 105/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.7207e-05 - accuracy: 1.0000\n",
            "Epoch 106/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.5723e-05 - accuracy: 1.0000\n",
            "Epoch 107/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.3727e-05 - accuracy: 1.0000\n",
            "Epoch 108/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.2277e-05 - accuracy: 1.0000\n",
            "Epoch 109/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.1847e-05 - accuracy: 1.0000\n",
            "Epoch 110/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.9747e-05 - accuracy: 1.0000\n",
            "Epoch 111/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.8526e-05 - accuracy: 1.0000\n",
            "Epoch 112/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.6554e-05 - accuracy: 1.0000\n",
            "Epoch 113/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.5878e-05 - accuracy: 1.0000\n",
            "Epoch 114/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.4462e-05 - accuracy: 1.0000\n",
            "Epoch 115/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.3223e-05 - accuracy: 1.0000\n",
            "Epoch 116/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.2309e-05 - accuracy: 1.0000\n",
            "Epoch 117/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.1110e-05 - accuracy: 1.0000\n",
            "Epoch 118/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.0192e-05 - accuracy: 1.0000\n",
            "Epoch 119/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.8909e-05 - accuracy: 1.0000\n",
            "Epoch 120/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.7940e-05 - accuracy: 1.0000\n",
            "Epoch 121/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.6477e-05 - accuracy: 1.0000\n",
            "Epoch 122/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.5705e-05 - accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.4807e-05 - accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.3976e-05 - accuracy: 1.0000\n",
            "Epoch 125/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.3053e-05 - accuracy: 1.0000\n",
            "Epoch 126/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 2.2401e-05 - accuracy: 1.0000\n",
            "Epoch 127/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1918e-05 - accuracy: 1.0000\n",
            "Epoch 128/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1151e-05 - accuracy: 1.0000\n",
            "Epoch 129/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.0725e-05 - accuracy: 1.0000\n",
            "Epoch 130/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9774e-05 - accuracy: 1.0000\n",
            "Epoch 131/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9264e-05 - accuracy: 1.0000\n",
            "Epoch 132/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8556e-05 - accuracy: 1.0000\n",
            "Epoch 133/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8128e-05 - accuracy: 1.0000\n",
            "Epoch 134/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7539e-05 - accuracy: 1.0000\n",
            "Epoch 135/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7083e-05 - accuracy: 1.0000\n",
            "Epoch 136/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6524e-05 - accuracy: 1.0000\n",
            "Epoch 137/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6153e-05 - accuracy: 1.0000\n",
            "Epoch 138/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6042e-05 - accuracy: 1.0000\n",
            "Epoch 139/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.5726e-05 - accuracy: 1.0000\n",
            "Epoch 140/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4869e-05 - accuracy: 1.0000\n",
            "Epoch 141/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4569e-05 - accuracy: 1.0000\n",
            "Epoch 142/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4051e-05 - accuracy: 1.0000\n",
            "Epoch 143/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3728e-05 - accuracy: 1.0000\n",
            "Epoch 144/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3338e-05 - accuracy: 1.0000\n",
            "Epoch 145/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3029e-05 - accuracy: 1.0000\n",
            "Epoch 146/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2721e-05 - accuracy: 1.0000\n",
            "Epoch 147/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2210e-05 - accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1896e-05 - accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1475e-05 - accuracy: 1.0000\n",
            "Epoch 150/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1397e-05 - accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0963e-05 - accuracy: 1.0000\n",
            "Epoch 152/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0825e-05 - accuracy: 1.0000\n",
            "Epoch 153/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0413e-05 - accuracy: 1.0000\n",
            "Epoch 154/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0123e-05 - accuracy: 1.0000\n",
            "Epoch 155/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.9090e-06 - accuracy: 1.0000\n",
            "Epoch 156/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.6605e-06 - accuracy: 1.0000\n",
            "Epoch 157/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.5306e-06 - accuracy: 1.0000\n",
            "Epoch 158/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.0981e-06 - accuracy: 1.0000\n",
            "Epoch 159/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.8803e-06 - accuracy: 1.0000\n",
            "Epoch 160/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.5989e-06 - accuracy: 1.0000\n",
            "Epoch 161/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.4926e-06 - accuracy: 1.0000\n",
            "Epoch 162/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.2676e-06 - accuracy: 1.0000\n",
            "Epoch 163/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.9739e-06 - accuracy: 1.0000\n",
            "Epoch 164/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.8559e-06 - accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 7.7181e-06 - accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.3601e-06 - accuracy: 1.0000\n",
            "Epoch 167/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.1617e-06 - accuracy: 1.0000\n",
            "Epoch 168/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.0274e-06 - accuracy: 1.0000\n",
            "Epoch 169/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.8222e-06 - accuracy: 1.0000\n",
            "Epoch 170/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.6470e-06 - accuracy: 1.0000\n",
            "Epoch 171/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.4375e-06 - accuracy: 1.0000\n",
            "Epoch 172/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.3473e-06 - accuracy: 1.0000\n",
            "Epoch 173/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.1049e-06 - accuracy: 1.0000\n",
            "Epoch 174/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.9843e-06 - accuracy: 1.0000\n",
            "Epoch 175/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.7853e-06 - accuracy: 1.0000\n",
            "Epoch 176/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.6761e-06 - accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.5350e-06 - accuracy: 1.0000\n",
            "Epoch 178/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.6293e-06 - accuracy: 1.0000\n",
            "Epoch 179/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.1306 - accuracy: 0.9738\n",
            "Epoch 180/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.2646 - accuracy: 0.9433\n",
            "Epoch 181/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9797\n",
            "Epoch 182/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9956\n",
            "Epoch 183/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 185/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 186/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 187/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 188/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 190/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 191/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 192/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 193/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.3942e-04 - accuracy: 1.0000\n",
            "Epoch 194/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.9066e-04 - accuracy: 1.0000\n",
            "Epoch 195/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.3171e-04 - accuracy: 1.0000\n",
            "Epoch 196/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.8160e-04 - accuracy: 1.0000\n",
            "Epoch 197/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.4556e-04 - accuracy: 1.0000\n",
            "Epoch 198/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.0722e-04 - accuracy: 1.0000\n",
            "Epoch 199/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.6948e-04 - accuracy: 1.0000\n",
            "Epoch 200/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.2928e-04 - accuracy: 1.0000\n",
            "Epoch 201/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.0100e-04 - accuracy: 1.0000\n",
            "Epoch 202/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.7864e-04 - accuracy: 1.0000\n",
            "Epoch 203/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.4842e-04 - accuracy: 1.0000\n",
            "Epoch 204/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.1606e-04 - accuracy: 1.0000\n",
            "Epoch 205/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.9044e-04 - accuracy: 1.0000\n",
            "Epoch 206/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.6428e-04 - accuracy: 1.0000\n",
            "Epoch 207/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.5212e-04 - accuracy: 1.0000\n",
            "Epoch 208/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.2853e-04 - accuracy: 1.0000\n",
            "Epoch 209/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.0994e-04 - accuracy: 1.0000\n",
            "Epoch 210/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 3.9394e-04 - accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.7964e-04 - accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.6405e-04 - accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.4949e-04 - accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.3641e-04 - accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.2482e-04 - accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.0963e-04 - accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.0296e-04 - accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.8600e-04 - accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.7669e-04 - accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.6695e-04 - accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.5643e-04 - accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.4505e-04 - accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.3285e-04 - accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2515e-04 - accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1512e-04 - accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.0538e-04 - accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9475e-04 - accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8791e-04 - accuracy: 1.0000\n",
            "Epoch 229/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7880e-04 - accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6852e-04 - accuracy: 1.0000\n",
            "Epoch 231/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6058e-04 - accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5409e-04 - accuracy: 1.0000\n",
            "Epoch 233/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4544e-04 - accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3801e-04 - accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2880e-04 - accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1944e-04 - accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1302e-04 - accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0640e-04 - accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0077e-04 - accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.6528e-05 - accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 9.2017e-05 - accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.7899e-05 - accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.3621e-05 - accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.0264e-05 - accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.6417e-05 - accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.3191e-05 - accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.9731e-05 - accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.7084e-05 - accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.3997e-05 - accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.1237e-05 - accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.8970e-05 - accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 5.6528e-05 - accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.4437e-05 - accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.1366e-05 - accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.8709e-05 - accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.6312e-05 - accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.4068e-05 - accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.2165e-05 - accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.0675e-05 - accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.8432e-05 - accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.6628e-05 - accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.5289e-05 - accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.3552e-05 - accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.2162e-05 - accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.1479e-05 - accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.9924e-05 - accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.8727e-05 - accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 2.7380e-05 - accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.6634e-05 - accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.5546e-05 - accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.4349e-05 - accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.3088e-05 - accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2127e-05 - accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1343e-05 - accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.0335e-05 - accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9624e-05 - accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8798e-05 - accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8111e-05 - accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7329e-05 - accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6744e-05 - accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6128e-05 - accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5539e-05 - accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5204e-05 - accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4594e-05 - accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4054e-05 - accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3763e-05 - accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3292e-05 - accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2959e-05 - accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2508e-05 - accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2166e-05 - accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2051e-05 - accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1608e-05 - accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1321e-05 - accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0715e-05 - accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0341e-05 - accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.5867e-06 - accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.9109e-06 - accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.8802e-06 - accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.0863e-06 - accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.5098e-06 - accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.0016e-06 - accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.6410e-06 - accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.2999e-06 - accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.0727e-06 - accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.8715e-06 - accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.6154e-06 - accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.4299e-06 - accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.2413e-06 - accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.0844e-06 - accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.9250e-06 - accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.7821e-06 - accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.6264e-06 - accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.5133e-06 - accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.3901e-06 - accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.3229e-06 - accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.2139e-06 - accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.0736e-06 - accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.9545e-06 - accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.8788e-06 - accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.7902e-06 - accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.6984e-06 - accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.6215e-06 - accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.5447e-06 - accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.4653e-06 - accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.3919e-06 - accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.3334e-06 - accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2732e-06 - accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1948e-06 - accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1415e-06 - accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.0859e-06 - accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.0306e-06 - accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9676e-06 - accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9166e-06 - accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8605e-06 - accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8106e-06 - accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7728e-06 - accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7189e-06 - accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6786e-06 - accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6366e-06 - accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5899e-06 - accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5438e-06 - accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5051e-06 - accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4687e-06 - accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4267e-06 - accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3908e-06 - accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3497e-06 - accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.3212e-06 - accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3547e-06 - accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2853e-06 - accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2382e-06 - accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1996e-06 - accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1663e-06 - accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1390e-06 - accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1076e-06 - accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0734e-06 - accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0448e-06 - accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0173e-06 - accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.8990e-07 - accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.6596e-07 - accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.3896e-07 - accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.1357e-07 - accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.9102e-07 - accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.6555e-07 - accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.4226e-07 - accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.1980e-07 - accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.9766e-07 - accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.7709e-07 - accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.5830e-07 - accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.3349e-07 - accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.1281e-07 - accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.9323e-07 - accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.7475e-07 - accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.5640e-07 - accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.3522e-07 - accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.1661e-07 - accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.9861e-07 - accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.8175e-07 - accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.6123e-07 - accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.4280e-07 - accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.2644e-07 - accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.1050e-07 - accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 4.9302e-07 - accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 4.7611e-07 - accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.7363e-07 - accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.1420e-07 - accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.6160e-07 - accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.3954e-07 - accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.2170e-07 - accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.0511e-07 - accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.8897e-07 - accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.7467e-07 - accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.6036e-07 - accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.4670e-07 - accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.3366e-07 - accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.2233e-07 - accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.0862e-07 - accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.9734e-07 - accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.8594e-07 - accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.7374e-07 - accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 2.6287e-07 - accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.5293e-07 - accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.4232e-07 - accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.3394e-07 - accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2418e-07 - accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2859e-07 - accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1704e-07 - accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.0454e-07 - accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.9436e-07 - accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8566e-07 - accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7633e-07 - accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6796e-07 - accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6009e-07 - accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5310e-07 - accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4619e-07 - accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3912e-07 - accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3238e-07 - accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2652e-07 - accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3735e-07 - accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2857e-07 - accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1971e-07 - accuracy: 1.0000\n",
            "Epoch 421/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1230e-07 - accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0688e-07 - accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0001e-07 - accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.4961e-08 - accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.0364e-08 - accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.5664e-08 - accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.2008e-08 - accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 7.7721e-08 - accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.4135e-08 - accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.0841e-08 - accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 6.7494e-08 - accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.4445e-08 - accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.1599e-08 - accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.8680e-08 - accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.6040e-08 - accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.3504e-08 - accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.1011e-08 - accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 4.8789e-08 - accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.3097e-08 - accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.8827e-08 - accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.5718e-08 - accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.3034e-08 - accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.1154e-08 - accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.9202e-08 - accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 3.7206e-08 - accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.5502e-08 - accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 3.4101e-08 - accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.2381e-08 - accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.1119e-08 - accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.9649e-08 - accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.8513e-08 - accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.7355e-08 - accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.6178e-08 - accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.4894e-08 - accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.5452e-08 - accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.4484e-08 - accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.3278e-08 - accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2164e-08 - accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1126e-08 - accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.0505e-08 - accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9371e-08 - accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8516e-08 - accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7739e-08 - accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6940e-08 - accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6280e-08 - accuracy: 1.0000\n",
            "Epoch 466/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5670e-08 - accuracy: 1.0000\n",
            "Epoch 467/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5003e-08 - accuracy: 1.0000\n",
            "Epoch 468/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4448e-08 - accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4910e-08 - accuracy: 1.0000\n",
            "Epoch 470/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4357e-08 - accuracy: 1.0000\n",
            "Epoch 471/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3587e-08 - accuracy: 1.0000\n",
            "Epoch 472/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2972e-08 - accuracy: 1.0000\n",
            "Epoch 473/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2344e-08 - accuracy: 1.0000\n",
            "Epoch 474/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1840e-08 - accuracy: 1.0000\n",
            "Epoch 475/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1517e-08 - accuracy: 1.0000\n",
            "Epoch 476/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0994e-08 - accuracy: 1.0000\n",
            "Epoch 477/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0671e-08 - accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0465e-08 - accuracy: 1.0000\n",
            "Epoch 479/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.9495e-09 - accuracy: 1.0000\n",
            "Epoch 480/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.6739e-09 - accuracy: 1.0000\n",
            "Epoch 481/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.3183e-09 - accuracy: 1.0000\n",
            "Epoch 482/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.9961e-09 - accuracy: 1.0000\n",
            "Epoch 483/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.2928e-09 - accuracy: 1.0000\n",
            "Epoch 484/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.7383e-09 - accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.3444e-09 - accuracy: 1.0000\n",
            "Epoch 486/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.2168e-09 - accuracy: 1.0000\n",
            "Epoch 487/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.9028e-09 - accuracy: 1.0000\n",
            "Epoch 488/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.6133e-09 - accuracy: 1.0000\n",
            "Epoch 489/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.3406e-09 - accuracy: 1.0000\n",
            "Epoch 490/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.1860e-09 - accuracy: 1.0000\n",
            "Epoch 491/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.0224e-09 - accuracy: 1.0000\n",
            "Epoch 492/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.7770e-09 - accuracy: 1.0000\n",
            "Epoch 493/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.7952e-09 - accuracy: 1.0000\n",
            "Epoch 494/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.5403e-09 - accuracy: 1.0000\n",
            "Epoch 495/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.4640e-09 - accuracy: 1.0000\n",
            "Epoch 496/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.0978e-09 - accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.0858e-09 - accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.9548e-09 - accuracy: 1.0000\n",
            "Epoch 499/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 5.8116e-09 - accuracy: 1.0000\n",
            "Epoch 500/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.7089e-09 - accuracy: 1.0000\n",
            "Epoch 501/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.4598e-09 - accuracy: 1.0000\n",
            "Epoch 502/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.3836e-09 - accuracy: 1.0000\n",
            "Epoch 503/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.2280e-09 - accuracy: 1.0000\n",
            "Epoch 504/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.0983e-09 - accuracy: 1.0000\n",
            "Epoch 505/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.1590e-09 - accuracy: 1.0000\n",
            "Epoch 506/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 5.1392e-09 - accuracy: 1.0000\n",
            "Epoch 507/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.8238e-09 - accuracy: 1.0000\n",
            "Epoch 508/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.8614e-09 - accuracy: 1.0000\n",
            "Epoch 509/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.7172e-09 - accuracy: 1.0000\n",
            "Epoch 510/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.6631e-09 - accuracy: 1.0000\n",
            "Epoch 511/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.5617e-09 - accuracy: 1.0000\n",
            "Epoch 512/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.4462e-09 - accuracy: 1.0000\n",
            "Epoch 513/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.3394e-09 - accuracy: 1.0000\n",
            "Epoch 514/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.1881e-09 - accuracy: 1.0000\n",
            "Epoch 515/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.3265e-09 - accuracy: 1.0000\n",
            "Epoch 516/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.1129e-09 - accuracy: 1.0000\n",
            "Epoch 517/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.1140e-09 - accuracy: 1.0000\n",
            "Epoch 518/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 4.0800e-09 - accuracy: 1.0000\n",
            "Epoch 519/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.9167e-09 - accuracy: 1.0000\n",
            "Epoch 520/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.7782e-09 - accuracy: 1.0000\n",
            "Epoch 521/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.7950e-09 - accuracy: 1.0000\n",
            "Epoch 522/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.7012e-09 - accuracy: 1.0000\n",
            "Epoch 523/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.4951e-09 - accuracy: 1.0000\n",
            "Epoch 524/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.5045e-09 - accuracy: 1.0000\n",
            "Epoch 525/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.5966e-09 - accuracy: 1.0000\n",
            "Epoch 526/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.5522e-09 - accuracy: 1.0000\n",
            "Epoch 527/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.4395e-09 - accuracy: 1.0000\n",
            "Epoch 528/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.3720e-09 - accuracy: 1.0000\n",
            "Epoch 529/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.3810e-09 - accuracy: 1.0000\n",
            "Epoch 530/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.4052e-09 - accuracy: 1.0000\n",
            "Epoch 531/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.3694e-09 - accuracy: 1.0000\n",
            "Epoch 532/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.1216e-09 - accuracy: 1.0000\n",
            "Epoch 533/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.2836e-09 - accuracy: 1.0000\n",
            "Epoch 534/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.3428e-09 - accuracy: 1.0000\n",
            "Epoch 535/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.1526e-09 - accuracy: 1.0000\n",
            "Epoch 536/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.1484e-09 - accuracy: 1.0000\n",
            "Epoch 537/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.1987e-09 - accuracy: 1.0000\n",
            "Epoch 538/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.0311e-09 - accuracy: 1.0000\n",
            "Epoch 539/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.0642e-09 - accuracy: 1.0000\n",
            "Epoch 540/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 3.0142e-09 - accuracy: 1.0000\n",
            "Epoch 541/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.8526e-09 - accuracy: 1.0000\n",
            "Epoch 542/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.7647e-09 - accuracy: 1.0000\n",
            "Epoch 543/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.8326e-09 - accuracy: 1.0000\n",
            "Epoch 544/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.7729e-09 - accuracy: 1.0000\n",
            "Epoch 545/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.9628e-09 - accuracy: 1.0000\n",
            "Epoch 546/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.5886e-09 - accuracy: 1.0000\n",
            "Epoch 547/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.7145e-09 - accuracy: 1.0000\n",
            "Epoch 548/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.8217e-09 - accuracy: 1.0000\n",
            "Epoch 549/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.7628e-09 - accuracy: 1.0000\n",
            "Epoch 550/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.6152e-09 - accuracy: 1.0000\n",
            "Epoch 551/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 2.3797e-09 - accuracy: 1.0000\n",
            "Epoch 552/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 2.8190e-09 - accuracy: 1.0000\n",
            "Epoch 553/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.7472e-09 - accuracy: 1.0000\n",
            "Epoch 554/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.5163e-09 - accuracy: 1.0000\n",
            "Epoch 555/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2335e-09 - accuracy: 1.0000\n",
            "Epoch 556/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.5310e-09 - accuracy: 1.0000\n",
            "Epoch 557/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.3196e-09 - accuracy: 1.0000\n",
            "Epoch 558/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.4299e-09 - accuracy: 1.0000\n",
            "Epoch 559/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.5409e-09 - accuracy: 1.0000\n",
            "Epoch 560/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.3333e-09 - accuracy: 1.0000\n",
            "Epoch 561/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2259e-09 - accuracy: 1.0000\n",
            "Epoch 562/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2879e-09 - accuracy: 1.0000\n",
            "Epoch 563/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1470e-09 - accuracy: 1.0000\n",
            "Epoch 564/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2902e-09 - accuracy: 1.0000\n",
            "Epoch 565/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.3269e-09 - accuracy: 1.0000\n",
            "Epoch 566/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1672e-09 - accuracy: 1.0000\n",
            "Epoch 567/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.2820e-09 - accuracy: 1.0000\n",
            "Epoch 568/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.0912e-09 - accuracy: 1.0000\n",
            "Epoch 569/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.0243e-09 - accuracy: 1.0000\n",
            "Epoch 570/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1488e-09 - accuracy: 1.0000\n",
            "Epoch 571/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1037e-09 - accuracy: 1.0000\n",
            "Epoch 572/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9696e-09 - accuracy: 1.0000\n",
            "Epoch 573/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.0888e-09 - accuracy: 1.0000\n",
            "Epoch 574/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9420e-09 - accuracy: 1.0000\n",
            "Epoch 575/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9955e-09 - accuracy: 1.0000\n",
            "Epoch 576/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7081e-09 - accuracy: 1.0000\n",
            "Epoch 577/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 2.1571e-09 - accuracy: 1.0000\n",
            "Epoch 578/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8743e-09 - accuracy: 1.0000\n",
            "Epoch 579/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.7592e-09 - accuracy: 1.0000\n",
            "Epoch 580/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8067e-09 - accuracy: 1.0000\n",
            "Epoch 581/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6530e-09 - accuracy: 1.0000\n",
            "Epoch 582/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8790e-09 - accuracy: 1.0000\n",
            "Epoch 583/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.6895e-09 - accuracy: 1.0000\n",
            "Epoch 584/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6565e-09 - accuracy: 1.0000\n",
            "Epoch 585/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7575e-09 - accuracy: 1.0000\n",
            "Epoch 586/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7105e-09 - accuracy: 1.0000\n",
            "Epoch 587/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7870e-09 - accuracy: 1.0000\n",
            "Epoch 588/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8946e-09 - accuracy: 1.0000\n",
            "Epoch 589/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5241e-09 - accuracy: 1.0000\n",
            "Epoch 590/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6906e-09 - accuracy: 1.0000\n",
            "Epoch 591/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8994e-09 - accuracy: 1.0000\n",
            "Epoch 592/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6392e-09 - accuracy: 1.0000\n",
            "Epoch 593/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.6446e-09 - accuracy: 1.0000\n",
            "Epoch 594/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.9501e-09 - accuracy: 1.0000\n",
            "Epoch 595/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6851e-09 - accuracy: 1.0000\n",
            "Epoch 596/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7322e-09 - accuracy: 1.0000\n",
            "Epoch 597/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5424e-09 - accuracy: 1.0000\n",
            "Epoch 598/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.2510e-09 - accuracy: 1.0000\n",
            "Epoch 599/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5119e-09 - accuracy: 1.0000\n",
            "Epoch 600/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7839e-09 - accuracy: 1.0000\n",
            "Epoch 601/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5084e-09 - accuracy: 1.0000\n",
            "Epoch 602/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.6744e-09 - accuracy: 1.0000\n",
            "Epoch 603/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2920e-09 - accuracy: 1.0000\n",
            "Epoch 604/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7200e-09 - accuracy: 1.0000\n",
            "Epoch 605/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.4011e-09 - accuracy: 1.0000\n",
            "Epoch 606/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7494e-09 - accuracy: 1.0000\n",
            "Epoch 607/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3447e-09 - accuracy: 1.0000\n",
            "Epoch 608/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2484e-09 - accuracy: 1.0000\n",
            "Epoch 609/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6915e-09 - accuracy: 1.0000\n",
            "Epoch 610/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5764e-09 - accuracy: 1.0000\n",
            "Epoch 611/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5146e-09 - accuracy: 1.0000\n",
            "Epoch 612/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.2892e-09 - accuracy: 1.0000\n",
            "Epoch 613/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5585e-09 - accuracy: 1.0000\n",
            "Epoch 614/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2956e-09 - accuracy: 1.0000\n",
            "Epoch 615/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7852e-09 - accuracy: 1.0000\n",
            "Epoch 616/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3563e-09 - accuracy: 1.0000\n",
            "Epoch 617/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4537e-09 - accuracy: 1.0000\n",
            "Epoch 618/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4824e-09 - accuracy: 1.0000\n",
            "Epoch 619/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5646e-09 - accuracy: 1.0000\n",
            "Epoch 620/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6113e-09 - accuracy: 1.0000\n",
            "Epoch 621/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3049e-09 - accuracy: 1.0000\n",
            "Epoch 622/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7314e-09 - accuracy: 1.0000\n",
            "Epoch 623/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3009e-09 - accuracy: 1.0000\n",
            "Epoch 624/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6002e-09 - accuracy: 1.0000\n",
            "Epoch 625/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3738e-09 - accuracy: 1.0000\n",
            "Epoch 626/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6695e-09 - accuracy: 1.0000\n",
            "Epoch 627/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3383e-09 - accuracy: 1.0000\n",
            "Epoch 628/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4352e-09 - accuracy: 1.0000\n",
            "Epoch 629/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0774e-09 - accuracy: 1.0000\n",
            "Epoch 630/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4418e-09 - accuracy: 1.0000\n",
            "Epoch 631/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2713e-09 - accuracy: 1.0000\n",
            "Epoch 632/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3907e-09 - accuracy: 1.0000\n",
            "Epoch 633/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4748e-09 - accuracy: 1.0000\n",
            "Epoch 634/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2737e-09 - accuracy: 1.0000\n",
            "Epoch 635/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3797e-09 - accuracy: 1.0000\n",
            "Epoch 636/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2786e-09 - accuracy: 1.0000\n",
            "Epoch 637/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5959e-09 - accuracy: 1.0000\n",
            "Epoch 638/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2802e-09 - accuracy: 1.0000\n",
            "Epoch 639/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4435e-09 - accuracy: 1.0000\n",
            "Epoch 640/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1809e-09 - accuracy: 1.0000\n",
            "Epoch 641/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5804e-09 - accuracy: 1.0000\n",
            "Epoch 642/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.8857e-09 - accuracy: 1.0000\n",
            "Epoch 643/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5530e-09 - accuracy: 1.0000\n",
            "Epoch 644/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4523e-09 - accuracy: 1.0000\n",
            "Epoch 645/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3854e-09 - accuracy: 1.0000\n",
            "Epoch 646/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1351e-09 - accuracy: 1.0000\n",
            "Epoch 647/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.5034e-09 - accuracy: 1.0000\n",
            "Epoch 648/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3760e-09 - accuracy: 1.0000\n",
            "Epoch 649/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4581e-09 - accuracy: 1.0000\n",
            "Epoch 650/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2986e-09 - accuracy: 1.0000\n",
            "Epoch 651/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3751e-09 - accuracy: 1.0000\n",
            "Epoch 652/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2260e-09 - accuracy: 1.0000\n",
            "Epoch 653/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4556e-09 - accuracy: 1.0000\n",
            "Epoch 654/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0655e-09 - accuracy: 1.0000\n",
            "Epoch 655/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3361e-09 - accuracy: 1.0000\n",
            "Epoch 656/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6373e-09 - accuracy: 1.0000\n",
            "Epoch 657/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2004e-09 - accuracy: 1.0000\n",
            "Epoch 658/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4451e-09 - accuracy: 1.0000\n",
            "Epoch 659/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2763e-09 - accuracy: 1.0000\n",
            "Epoch 660/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1175e-09 - accuracy: 1.0000\n",
            "Epoch 661/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5212e-09 - accuracy: 1.0000\n",
            "Epoch 662/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0290e-09 - accuracy: 1.0000\n",
            "Epoch 663/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2228e-09 - accuracy: 1.0000\n",
            "Epoch 664/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 8.6545e-10 - accuracy: 1.0000\n",
            "Epoch 665/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1115e-09 - accuracy: 1.0000\n",
            "Epoch 666/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3876e-09 - accuracy: 1.0000\n",
            "Epoch 667/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6271e-09 - accuracy: 1.0000\n",
            "Epoch 668/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3577e-09 - accuracy: 1.0000\n",
            "Epoch 669/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4555e-09 - accuracy: 1.0000\n",
            "Epoch 670/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1971e-09 - accuracy: 1.0000\n",
            "Epoch 671/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2465e-09 - accuracy: 1.0000\n",
            "Epoch 672/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4774e-09 - accuracy: 1.0000\n",
            "Epoch 673/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7201e-09 - accuracy: 1.0000\n",
            "Epoch 674/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.8261e-09 - accuracy: 1.0000\n",
            "Epoch 675/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0480e-09 - accuracy: 1.0000\n",
            "Epoch 676/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2702e-09 - accuracy: 1.0000\n",
            "Epoch 677/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4879e-09 - accuracy: 1.0000\n",
            "Epoch 678/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7342e-09 - accuracy: 1.0000\n",
            "Epoch 679/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2977e-09 - accuracy: 1.0000\n",
            "Epoch 680/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2275e-09 - accuracy: 1.0000\n",
            "Epoch 681/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4661e-09 - accuracy: 1.0000\n",
            "Epoch 682/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7178e-09 - accuracy: 1.0000\n",
            "Epoch 683/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0806e-09 - accuracy: 1.0000\n",
            "Epoch 684/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.2275e-09 - accuracy: 1.0000\n",
            "Epoch 685/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.9374e-10 - accuracy: 1.0000\n",
            "Epoch 686/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0828e-09 - accuracy: 1.0000\n",
            "Epoch 687/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3103e-09 - accuracy: 1.0000\n",
            "Epoch 688/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1653e-09 - accuracy: 1.0000\n",
            "Epoch 689/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1571e-09 - accuracy: 1.0000\n",
            "Epoch 690/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3594e-09 - accuracy: 1.0000\n",
            "Epoch 691/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5779e-09 - accuracy: 1.0000\n",
            "Epoch 692/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6897e-09 - accuracy: 1.0000\n",
            "Epoch 693/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0490e-09 - accuracy: 1.0000\n",
            "Epoch 694/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3399e-09 - accuracy: 1.0000\n",
            "Epoch 695/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5446e-09 - accuracy: 1.0000\n",
            "Epoch 696/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.5535e-10 - accuracy: 1.0000\n",
            "Epoch 697/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1419e-09 - accuracy: 1.0000\n",
            "Epoch 698/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0231e-09 - accuracy: 1.0000\n",
            "Epoch 699/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2019e-09 - accuracy: 1.0000\n",
            "Epoch 700/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4003e-09 - accuracy: 1.0000\n",
            "Epoch 701/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5809e-09 - accuracy: 1.0000\n",
            "Epoch 702/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.7618e-09 - accuracy: 1.0000\n",
            "Epoch 703/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3491e-09 - accuracy: 1.0000\n",
            "Epoch 704/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0312e-09 - accuracy: 1.0000\n",
            "Epoch 705/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2854e-09 - accuracy: 1.0000\n",
            "Epoch 706/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3236e-09 - accuracy: 1.0000\n",
            "Epoch 707/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.3694e-10 - accuracy: 1.0000\n",
            "Epoch 708/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.7538e-10 - accuracy: 1.0000\n",
            "Epoch 709/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.0661e-10 - accuracy: 1.0000\n",
            "Epoch 710/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.9288e-10 - accuracy: 1.0000\n",
            "Epoch 711/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0449e-09 - accuracy: 1.0000\n",
            "Epoch 712/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2458e-09 - accuracy: 1.0000\n",
            "Epoch 713/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4221e-09 - accuracy: 1.0000\n",
            "Epoch 714/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6015e-09 - accuracy: 1.0000\n",
            "Epoch 715/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6017e-09 - accuracy: 1.0000\n",
            "Epoch 716/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0445e-09 - accuracy: 1.0000\n",
            "Epoch 717/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1894e-09 - accuracy: 1.0000\n",
            "Epoch 718/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3641e-09 - accuracy: 1.0000\n",
            "Epoch 719/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5222e-09 - accuracy: 1.0000\n",
            "Epoch 720/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2172e-09 - accuracy: 1.0000\n",
            "Epoch 721/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0599e-09 - accuracy: 1.0000\n",
            "Epoch 722/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2210e-09 - accuracy: 1.0000\n",
            "Epoch 723/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3711e-09 - accuracy: 1.0000\n",
            "Epoch 724/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3240e-09 - accuracy: 1.0000\n",
            "Epoch 725/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.2068e-10 - accuracy: 1.0000\n",
            "Epoch 726/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.7381e-10 - accuracy: 1.0000\n",
            "Epoch 727/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.1348e-09 - accuracy: 1.0000\n",
            "Epoch 728/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.2874e-09 - accuracy: 1.0000\n",
            "Epoch 729/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2666e-09 - accuracy: 1.0000\n",
            "Epoch 730/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.0259e-10 - accuracy: 1.0000\n",
            "Epoch 731/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.7739e-10 - accuracy: 1.0000\n",
            "Epoch 732/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1315e-09 - accuracy: 1.0000\n",
            "Epoch 733/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2850e-09 - accuracy: 1.0000\n",
            "Epoch 734/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4280e-09 - accuracy: 1.0000\n",
            "Epoch 735/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5713e-09 - accuracy: 1.0000\n",
            "Epoch 736/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.9495e-10 - accuracy: 1.0000\n",
            "Epoch 737/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.1156e-10 - accuracy: 1.0000\n",
            "Epoch 738/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.8914e-10 - accuracy: 1.0000\n",
            "Epoch 739/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1325e-09 - accuracy: 1.0000\n",
            "Epoch 740/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3031e-09 - accuracy: 1.0000\n",
            "Epoch 741/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2849e-09 - accuracy: 1.0000\n",
            "Epoch 742/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.2511e-10 - accuracy: 1.0000\n",
            "Epoch 743/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.5798e-10 - accuracy: 1.0000\n",
            "Epoch 744/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0927e-09 - accuracy: 1.0000\n",
            "Epoch 745/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2331e-09 - accuracy: 1.0000\n",
            "Epoch 746/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3456e-09 - accuracy: 1.0000\n",
            "Epoch 747/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1261e-09 - accuracy: 1.0000\n",
            "Epoch 748/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.5545e-10 - accuracy: 1.0000\n",
            "Epoch 749/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0110e-09 - accuracy: 1.0000\n",
            "Epoch 750/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1370e-09 - accuracy: 1.0000\n",
            "Epoch 751/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.2658e-09 - accuracy: 1.0000\n",
            "Epoch 752/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4008e-09 - accuracy: 1.0000\n",
            "Epoch 753/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.8249e-10 - accuracy: 1.0000\n",
            "Epoch 754/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.8424e-10 - accuracy: 1.0000\n",
            "Epoch 755/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.8611e-10 - accuracy: 1.0000\n",
            "Epoch 756/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.0101e-09 - accuracy: 1.0000\n",
            "Epoch 757/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1418e-09 - accuracy: 1.0000\n",
            "Epoch 758/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2405e-09 - accuracy: 1.0000\n",
            "Epoch 759/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3467e-09 - accuracy: 1.0000\n",
            "Epoch 760/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1902e-09 - accuracy: 1.0000\n",
            "Epoch 761/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.3891e-10 - accuracy: 1.0000\n",
            "Epoch 762/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.5392e-10 - accuracy: 1.0000\n",
            "Epoch 763/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.8908e-10 - accuracy: 1.0000\n",
            "Epoch 764/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1126e-09 - accuracy: 1.0000\n",
            "Epoch 765/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2291e-09 - accuracy: 1.0000\n",
            "Epoch 766/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3318e-09 - accuracy: 1.0000\n",
            "Epoch 767/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.0724e-09 - accuracy: 1.0000\n",
            "Epoch 768/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.7543e-10 - accuracy: 1.0000\n",
            "Epoch 769/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.0713e-10 - accuracy: 1.0000\n",
            "Epoch 770/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0240e-09 - accuracy: 1.0000\n",
            "Epoch 771/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1467e-09 - accuracy: 1.0000\n",
            "Epoch 772/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1104e-09 - accuracy: 1.0000\n",
            "Epoch 773/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.8216e-10 - accuracy: 1.0000\n",
            "Epoch 774/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.0940e-10 - accuracy: 1.0000\n",
            "Epoch 775/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.1836e-10 - accuracy: 1.0000\n",
            "Epoch 776/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0149e-09 - accuracy: 1.0000\n",
            "Epoch 777/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1327e-09 - accuracy: 1.0000\n",
            "Epoch 778/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2368e-09 - accuracy: 1.0000\n",
            "Epoch 779/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2320e-09 - accuracy: 1.0000\n",
            "Epoch 780/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.3934e-10 - accuracy: 1.0000\n",
            "Epoch 781/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.3895e-10 - accuracy: 1.0000\n",
            "Epoch 782/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0488e-09 - accuracy: 1.0000\n",
            "Epoch 783/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1452e-09 - accuracy: 1.0000\n",
            "Epoch 784/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2356e-09 - accuracy: 1.0000\n",
            "Epoch 785/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3282e-09 - accuracy: 1.0000\n",
            "Epoch 786/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4458e-09 - accuracy: 1.0000\n",
            "Epoch 787/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0867e-09 - accuracy: 1.0000\n",
            "Epoch 788/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.4897e-10 - accuracy: 1.0000\n",
            "Epoch 789/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0494e-09 - accuracy: 1.0000\n",
            "Epoch 790/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1429e-09 - accuracy: 1.0000\n",
            "Epoch 791/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2439e-09 - accuracy: 1.0000\n",
            "Epoch 792/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3539e-09 - accuracy: 1.0000\n",
            "Epoch 793/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4456e-09 - accuracy: 1.0000\n",
            "Epoch 794/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5364e-09 - accuracy: 1.0000\n",
            "Epoch 795/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3385e-09 - accuracy: 1.0000\n",
            "Epoch 796/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.2207e-10 - accuracy: 1.0000\n",
            "Epoch 797/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0242e-09 - accuracy: 1.0000\n",
            "Epoch 798/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1316e-09 - accuracy: 1.0000\n",
            "Epoch 799/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2329e-09 - accuracy: 1.0000\n",
            "Epoch 800/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2257e-09 - accuracy: 1.0000\n",
            "Epoch 801/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.0941e-10 - accuracy: 1.0000\n",
            "Epoch 802/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.9870e-10 - accuracy: 1.0000\n",
            "Epoch 803/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.1344e-10 - accuracy: 1.0000\n",
            "Epoch 804/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0008e-09 - accuracy: 1.0000\n",
            "Epoch 805/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0973e-09 - accuracy: 1.0000\n",
            "Epoch 806/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2059e-09 - accuracy: 1.0000\n",
            "Epoch 807/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2999e-09 - accuracy: 1.0000\n",
            "Epoch 808/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3919e-09 - accuracy: 1.0000\n",
            "Epoch 809/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.4557e-09 - accuracy: 1.0000\n",
            "Epoch 810/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.0751e-10 - accuracy: 1.0000\n",
            "Epoch 811/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.5498e-10 - accuracy: 1.0000\n",
            "Epoch 812/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.6504e-10 - accuracy: 1.0000\n",
            "Epoch 813/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.8002e-10 - accuracy: 1.0000\n",
            "Epoch 814/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0895e-09 - accuracy: 1.0000\n",
            "Epoch 815/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1735e-09 - accuracy: 1.0000\n",
            "Epoch 816/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2691e-09 - accuracy: 1.0000\n",
            "Epoch 817/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2398e-09 - accuracy: 1.0000\n",
            "Epoch 818/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.5500e-10 - accuracy: 1.0000\n",
            "Epoch 819/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 8.5580e-10 - accuracy: 1.0000\n",
            "Epoch 820/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 9.7333e-10 - accuracy: 1.0000\n",
            "Epoch 821/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0784e-09 - accuracy: 1.0000\n",
            "Epoch 822/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1814e-09 - accuracy: 1.0000\n",
            "Epoch 823/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1767e-09 - accuracy: 1.0000\n",
            "Epoch 824/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1167e-09 - accuracy: 1.0000\n",
            "Epoch 825/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.3188e-10 - accuracy: 1.0000\n",
            "Epoch 826/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.0828e-10 - accuracy: 1.0000\n",
            "Epoch 827/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.0598e-10 - accuracy: 1.0000\n",
            "Epoch 828/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.9998e-10 - accuracy: 1.0000\n",
            "Epoch 829/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.8014e-10 - accuracy: 1.0000\n",
            "Epoch 830/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.7378e-10 - accuracy: 1.0000\n",
            "Epoch 831/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.3218e-10 - accuracy: 1.0000\n",
            "Epoch 832/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.1788e-10 - accuracy: 1.0000\n",
            "Epoch 833/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.9780e-10 - accuracy: 1.0000\n",
            "Epoch 834/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.7739e-10 - accuracy: 1.0000\n",
            "Epoch 835/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0592e-09 - accuracy: 1.0000\n",
            "Epoch 836/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1367e-09 - accuracy: 1.0000\n",
            "Epoch 837/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2119e-09 - accuracy: 1.0000\n",
            "Epoch 838/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2779e-09 - accuracy: 1.0000\n",
            "Epoch 839/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3571e-09 - accuracy: 1.0000\n",
            "Epoch 840/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4377e-09 - accuracy: 1.0000\n",
            "Epoch 841/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5174e-09 - accuracy: 1.0000\n",
            "Epoch 842/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6057e-09 - accuracy: 1.0000\n",
            "Epoch 843/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6792e-09 - accuracy: 1.0000\n",
            "Epoch 844/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5033e-09 - accuracy: 1.0000\n",
            "Epoch 845/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.9594e-10 - accuracy: 1.0000\n",
            "Epoch 846/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.7932e-10 - accuracy: 1.0000\n",
            "Epoch 847/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.5882e-10 - accuracy: 1.0000\n",
            "Epoch 848/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0193e-09 - accuracy: 1.0000\n",
            "Epoch 849/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0897e-09 - accuracy: 1.0000\n",
            "Epoch 850/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1773e-09 - accuracy: 1.0000\n",
            "Epoch 851/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2664e-09 - accuracy: 1.0000\n",
            "Epoch 852/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3412e-09 - accuracy: 1.0000\n",
            "Epoch 853/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4291e-09 - accuracy: 1.0000\n",
            "Epoch 854/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5017e-09 - accuracy: 1.0000\n",
            "Epoch 855/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5838e-09 - accuracy: 1.0000\n",
            "Epoch 856/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2446e-09 - accuracy: 1.0000\n",
            "Epoch 857/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.6479e-10 - accuracy: 1.0000\n",
            "Epoch 858/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.5718e-10 - accuracy: 1.0000\n",
            "Epoch 859/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0446e-09 - accuracy: 1.0000\n",
            "Epoch 860/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1089e-09 - accuracy: 1.0000\n",
            "Epoch 861/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.0955e-09 - accuracy: 1.0000\n",
            "Epoch 862/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.5457e-10 - accuracy: 1.0000\n",
            "Epoch 863/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.2992e-10 - accuracy: 1.0000\n",
            "Epoch 864/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0083e-09 - accuracy: 1.0000\n",
            "Epoch 865/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0739e-09 - accuracy: 1.0000\n",
            "Epoch 866/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1431e-09 - accuracy: 1.0000\n",
            "Epoch 867/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2118e-09 - accuracy: 1.0000\n",
            "Epoch 868/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2863e-09 - accuracy: 1.0000\n",
            "Epoch 869/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3535e-09 - accuracy: 1.0000\n",
            "Epoch 870/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.8540e-10 - accuracy: 1.0000\n",
            "Epoch 871/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.9528e-10 - accuracy: 1.0000\n",
            "Epoch 872/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 8.6085e-10 - accuracy: 1.0000\n",
            "Epoch 873/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.2818e-10 - accuracy: 1.0000\n",
            "Epoch 874/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0054e-09 - accuracy: 1.0000\n",
            "Epoch 875/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0742e-09 - accuracy: 1.0000\n",
            "Epoch 876/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1426e-09 - accuracy: 1.0000\n",
            "Epoch 877/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2131e-09 - accuracy: 1.0000\n",
            "Epoch 878/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2798e-09 - accuracy: 1.0000\n",
            "Epoch 879/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3484e-09 - accuracy: 1.0000\n",
            "Epoch 880/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0720e-09 - accuracy: 1.0000\n",
            "Epoch 881/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.5826e-10 - accuracy: 1.0000\n",
            "Epoch 882/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 8.2284e-10 - accuracy: 1.0000\n",
            "Epoch 883/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.9183e-10 - accuracy: 1.0000\n",
            "Epoch 884/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.4914e-10 - accuracy: 1.0000\n",
            "Epoch 885/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0190e-09 - accuracy: 1.0000\n",
            "Epoch 886/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0806e-09 - accuracy: 1.0000\n",
            "Epoch 887/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1414e-09 - accuracy: 1.0000\n",
            "Epoch 888/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2114e-09 - accuracy: 1.0000\n",
            "Epoch 889/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2699e-09 - accuracy: 1.0000\n",
            "Epoch 890/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3349e-09 - accuracy: 1.0000\n",
            "Epoch 891/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3946e-09 - accuracy: 1.0000\n",
            "Epoch 892/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0583e-09 - accuracy: 1.0000\n",
            "Epoch 893/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.8358e-10 - accuracy: 1.0000\n",
            "Epoch 894/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.7249e-10 - accuracy: 1.0000\n",
            "Epoch 895/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.4991e-10 - accuracy: 1.0000\n",
            "Epoch 896/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0088e-09 - accuracy: 1.0000\n",
            "Epoch 897/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0889e-09 - accuracy: 1.0000\n",
            "Epoch 898/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1691e-09 - accuracy: 1.0000\n",
            "Epoch 899/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2344e-09 - accuracy: 1.0000\n",
            "Epoch 900/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3090e-09 - accuracy: 1.0000\n",
            "Epoch 901/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3742e-09 - accuracy: 1.0000\n",
            "Epoch 902/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4390e-09 - accuracy: 1.0000\n",
            "Epoch 903/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5198e-09 - accuracy: 1.0000\n",
            "Epoch 904/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3995e-09 - accuracy: 1.0000\n",
            "Epoch 905/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.7565e-10 - accuracy: 1.0000\n",
            "Epoch 906/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.3103e-10 - accuracy: 1.0000\n",
            "Epoch 907/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.0987e-10 - accuracy: 1.0000\n",
            "Epoch 908/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.8175e-10 - accuracy: 1.0000\n",
            "Epoch 909/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0483e-09 - accuracy: 1.0000\n",
            "Epoch 910/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1152e-09 - accuracy: 1.0000\n",
            "Epoch 911/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1950e-09 - accuracy: 1.0000\n",
            "Epoch 912/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2524e-09 - accuracy: 1.0000\n",
            "Epoch 913/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3142e-09 - accuracy: 1.0000\n",
            "Epoch 914/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2806e-09 - accuracy: 1.0000\n",
            "Epoch 915/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.5472e-10 - accuracy: 1.0000\n",
            "Epoch 916/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0153e-09 - accuracy: 1.0000\n",
            "Epoch 917/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0773e-09 - accuracy: 1.0000\n",
            "Epoch 918/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1334e-09 - accuracy: 1.0000\n",
            "Epoch 919/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1912e-09 - accuracy: 1.0000\n",
            "Epoch 920/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2592e-09 - accuracy: 1.0000\n",
            "Epoch 921/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3195e-09 - accuracy: 1.0000\n",
            "Epoch 922/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3891e-09 - accuracy: 1.0000\n",
            "Epoch 923/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4402e-09 - accuracy: 1.0000\n",
            "Epoch 924/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5167e-09 - accuracy: 1.0000\n",
            "Epoch 925/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5760e-09 - accuracy: 1.0000\n",
            "Epoch 926/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.5925e-09 - accuracy: 1.0000\n",
            "Epoch 927/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.6443e-09 - accuracy: 1.0000\n",
            "Epoch 928/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2192e-09 - accuracy: 1.0000\n",
            "Epoch 929/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.7463e-10 - accuracy: 1.0000\n",
            "Epoch 930/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.4258e-10 - accuracy: 1.0000\n",
            "Epoch 931/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.1132e-10 - accuracy: 1.0000\n",
            "Epoch 932/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.6867e-10 - accuracy: 1.0000\n",
            "Epoch 933/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0330e-09 - accuracy: 1.0000\n",
            "Epoch 934/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0936e-09 - accuracy: 1.0000\n",
            "Epoch 935/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1606e-09 - accuracy: 1.0000\n",
            "Epoch 936/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2116e-09 - accuracy: 1.0000\n",
            "Epoch 937/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0888e-09 - accuracy: 1.0000\n",
            "Epoch 938/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 7.1954e-10 - accuracy: 1.0000\n",
            "Epoch 939/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.7558e-10 - accuracy: 1.0000\n",
            "Epoch 940/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.2812e-10 - accuracy: 1.0000\n",
            "Epoch 941/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.8480e-10 - accuracy: 1.0000\n",
            "Epoch 942/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.4217e-10 - accuracy: 1.0000\n",
            "Epoch 943/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0024e-09 - accuracy: 1.0000\n",
            "Epoch 944/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0491e-09 - accuracy: 1.0000\n",
            "Epoch 945/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1009e-09 - accuracy: 1.0000\n",
            "Epoch 946/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1630e-09 - accuracy: 1.0000\n",
            "Epoch 947/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2167e-09 - accuracy: 1.0000\n",
            "Epoch 948/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2749e-09 - accuracy: 1.0000\n",
            "Epoch 949/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3237e-09 - accuracy: 1.0000\n",
            "Epoch 950/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3822e-09 - accuracy: 1.0000\n",
            "Epoch 951/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3678e-09 - accuracy: 1.0000\n",
            "Epoch 952/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.0657e-10 - accuracy: 1.0000\n",
            "Epoch 953/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.5557e-10 - accuracy: 1.0000\n",
            "Epoch 954/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.2701e-10 - accuracy: 1.0000\n",
            "Epoch 955/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.9538e-10 - accuracy: 1.0000\n",
            "Epoch 956/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.5550e-10 - accuracy: 1.0000\n",
            "Epoch 957/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.1973e-10 - accuracy: 1.0000\n",
            "Epoch 958/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.8059e-10 - accuracy: 1.0000\n",
            "Epoch 959/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0462e-09 - accuracy: 1.0000\n",
            "Epoch 960/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1037e-09 - accuracy: 1.0000\n",
            "Epoch 961/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1641e-09 - accuracy: 1.0000\n",
            "Epoch 962/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2263e-09 - accuracy: 1.0000\n",
            "Epoch 963/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2916e-09 - accuracy: 1.0000\n",
            "Epoch 964/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3459e-09 - accuracy: 1.0000\n",
            "Epoch 965/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.4043e-09 - accuracy: 1.0000\n",
            "Epoch 966/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 1.1525e-09 - accuracy: 1.0000\n",
            "Epoch 967/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.6783e-10 - accuracy: 1.0000\n",
            "Epoch 968/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.3262e-10 - accuracy: 1.0000\n",
            "Epoch 969/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.8975e-10 - accuracy: 1.0000\n",
            "Epoch 970/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.6845e-10 - accuracy: 1.0000\n",
            "Epoch 971/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.2476e-10 - accuracy: 1.0000\n",
            "Epoch 972/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.9217e-10 - accuracy: 1.0000\n",
            "Epoch 973/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0492e-09 - accuracy: 1.0000\n",
            "Epoch 974/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1026e-09 - accuracy: 1.0000\n",
            "Epoch 975/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1674e-09 - accuracy: 1.0000\n",
            "Epoch 976/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2226e-09 - accuracy: 1.0000\n",
            "Epoch 977/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.6319e-10 - accuracy: 1.0000\n",
            "Epoch 978/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.9208e-10 - accuracy: 1.0000\n",
            "Epoch 979/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.4634e-10 - accuracy: 1.0000\n",
            "Epoch 980/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.0028e-10 - accuracy: 1.0000\n",
            "Epoch 981/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.4739e-10 - accuracy: 1.0000\n",
            "Epoch 982/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0009e-09 - accuracy: 1.0000\n",
            "Epoch 983/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0498e-09 - accuracy: 1.0000\n",
            "Epoch 984/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1022e-09 - accuracy: 1.0000\n",
            "Epoch 985/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1583e-09 - accuracy: 1.0000\n",
            "Epoch 986/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 9.6116e-10 - accuracy: 1.0000\n",
            "Epoch 987/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 9.7773e-10 - accuracy: 1.0000\n",
            "Epoch 988/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0295e-09 - accuracy: 1.0000\n",
            "Epoch 989/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.0763e-09 - accuracy: 1.0000\n",
            "Epoch 990/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1225e-09 - accuracy: 1.0000\n",
            "Epoch 991/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.1754e-09 - accuracy: 1.0000\n",
            "Epoch 992/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2274e-09 - accuracy: 1.0000\n",
            "Epoch 993/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.2778e-09 - accuracy: 1.0000\n",
            "Epoch 994/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3322e-09 - accuracy: 1.0000\n",
            "Epoch 995/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 1.3231e-09 - accuracy: 1.0000\n",
            "Epoch 996/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 6.9816e-10 - accuracy: 1.0000\n",
            "Epoch 997/1000\n",
            "69/69 [==============================] - 0s 2ms/step - loss: 7.3200e-10 - accuracy: 1.0000\n",
            "Epoch 998/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 7.8679e-10 - accuracy: 1.0000\n",
            "Epoch 999/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.3396e-10 - accuracy: 1.0000\n",
            "Epoch 1000/1000\n",
            "69/69 [==============================] - 0s 1ms/step - loss: 8.8190e-10 - accuracy: 1.0000\n",
            "[[202  25]\n",
            " [ 27  18]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.89       227\n",
            "           1       0.42      0.40      0.41        45\n",
            "\n",
            "    accuracy                           0.81       272\n",
            "   macro avg       0.65      0.64      0.65       272\n",
            "weighted avg       0.81      0.81      0.81       272\n",
            "\n",
            "Accuracy : 80.88235294117648\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu9lWVZ_bpwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predNN = y_predNN[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaFBDAbuU-Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain = pd.DataFrame({'XGBoost': predictionsXG, 'LogisticR': predictionsLR,'RandomF' : predictionsRF,'SVM' : y_predSVM, 'NeuralN' : y_predNN})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzNzQWgYQvqw",
        "colab_type": "text"
      },
      "source": [
        "# Training XGBClassifier on the output of previous classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zO8PL64YR7l",
        "colab_type": "code",
        "outputId": "f8fb2398-335b-4c69-dd77-595514c07ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "\n",
        "y_predXG1 = classifier.predict(X_test1)\n",
        "predictionsXG1 = [round(value) for value in y_predXG1]\n",
        "\n",
        "predictionsLR1 = logmodel.predict(X_test1)\n",
        "\n",
        "predictionsRF1 = rf.predict(X_test1)\n",
        "\n",
        "y_predSVM1 = svclassifier.predict(X_test1)\n",
        "\n",
        "# for i in range(0,51):\n",
        "#   for j in range(0,688):\n",
        "#     if X_test1.iloc[j,i] < 0.5:\n",
        "#       X_test1.iloc[j,i] = -1\n",
        "y_predNN1 = classifierNN.predict(X_test1)\n",
        "y_predNN1 = y_predNN1.round()\n",
        "y_predNN1 = y_predNN1[:,0]\n",
        "\n",
        "Xtest1 = pd.DataFrame({'XGBoost': predictionsXG1, 'LogisticR': predictionsLR1,'RandomF' : predictionsRF1,'SVM' : y_predSVM1, 'NeuralN' : y_predNN1})\n",
        "\n",
        "# Finally here we train a XGBClassifier with the output of the previous classifiers \n",
        "classifierF = XGBClassifier()\n",
        "classifierF.fit(Xtrain,y_test)\n",
        "\n",
        "y_predF = classifierF.predict(Xtest1)\n",
        "# predictionsF = [round(value) for value in y_predF]\n",
        "# evaluate predictions\n",
        "# predictionsF = predictionsF[:,0]\n",
        "accuracy = accuracy_score(y_test1, y_predF)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 85.29%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}