{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SHALAAssignment6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjinkyaRaghuwanshi/IMLAssignments/blob/master/SHALAAssignment6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lnS8bdSWnuK",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 2: **Machine learning with tree based models** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bF8pLu6VdCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_MZLq8wXoXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "fb70d170-72b7-4860-c43c-48ef711f77bb"
      },
      "source": [
        "titanic_data = pd.read_csv('titanic.csv')\n",
        "titanic_data.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFMp-MZ2IBrm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9bd0153-1d14-4cc6-ed70-9f5c1e9dc427"
      },
      "source": [
        "atc = titanic_data.corr()\n",
        "titanic_data.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g-6946GX7mJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7096681e-4d9f-45a5-a920-63cfbc963900"
      },
      "source": [
        "print(titanic_data.isna().sum())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYMvmU2TI1FA",
        "colab_type": "code",
        "outputId": "f595924b-47e3-4aef-dad1-9fa7934e9d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(atc)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe6e68865c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "bgYtBzelQQ6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "r--gY8YzQQ6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "import csv\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import scale, normalize\n",
        "from math import *\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "cXaNhZhWQQ6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "df1747e9-b90c-480b-c583-31e315f046df"
      },
      "source": [
        "# load data\n",
        "df = titanic_data\n",
        "df.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8pjvjoyMKx7",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYPGa8QXbUaH",
        "colab_type": "text"
      },
      "source": [
        "Removing Null values from data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTKllH-nfEBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43e95772-1995-4c6c-bc97-4dbedd81e481"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STrYNKphbTVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Age = df.Age.fillna(df.Age.mean())\n",
        "df = df.drop(['Cabin'],axis=\"columns\")\n",
        "df = df.dropna(axis=\"rows\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkMrMkJWc_jZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3ace2338-4dbc-45b8-cfa9-07272e9a02f6"
      },
      "source": [
        "print(df.isna().sum())"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-UiB0Xvd_Mh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "080286c0-b37b-4909-a337-2808b335488e"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(889, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrxcACXzcGKA",
        "colab_type": "text"
      },
      "source": [
        "Encoding Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2-B3tV8-QQ6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dummy0 = pd.get_dummies(df.Sex)\n",
        "dummy1 = pd.get_dummies(df.Embarked)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "l1WwvwhQQQ6w",
        "colab_type": "code",
        "outputId": "3b339ab2-3cdc-4a6e-abdc-12df1903328b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "merged =pd.concat([df,dummy0,dummy1],axis='columns')\n",
        "display(merged)\n",
        "final = merged.drop(['Name','Ticket','Sex','PassengerId','Embarked'],axis= 'columns')\n",
        "display(final)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "      <th>C</th>\n",
              "      <th>Q</th>\n",
              "      <th>S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>889 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...  C  Q  S\n",
              "0              1         0       3  ...  0  0  1\n",
              "1              2         1       1  ...  1  0  0\n",
              "2              3         1       3  ...  0  0  1\n",
              "3              4         1       1  ...  0  0  1\n",
              "4              5         0       3  ...  0  0  1\n",
              "..           ...       ...     ...  ... .. .. ..\n",
              "886          887         0       2  ...  0  0  1\n",
              "887          888         1       1  ...  0  0  1\n",
              "888          889         0       3  ...  0  0  1\n",
              "889          890         1       1  ...  1  0  0\n",
              "890          891         0       3  ...  0  1  0\n",
              "\n",
              "[889 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "      <th>C</th>\n",
              "      <th>Q</th>\n",
              "      <th>S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>889 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived  Pclass        Age  SibSp  Parch     Fare  female  male  C  Q  S\n",
              "0           0       3  22.000000      1      0   7.2500       0     1  0  0  1\n",
              "1           1       1  38.000000      1      0  71.2833       1     0  1  0  0\n",
              "2           1       3  26.000000      0      0   7.9250       1     0  0  0  1\n",
              "3           1       1  35.000000      1      0  53.1000       1     0  0  0  1\n",
              "4           0       3  35.000000      0      0   8.0500       0     1  0  0  1\n",
              "..        ...     ...        ...    ...    ...      ...     ...   ... .. .. ..\n",
              "886         0       2  27.000000      0      0  13.0000       0     1  0  0  1\n",
              "887         1       1  19.000000      0      0  30.0000       1     0  0  0  1\n",
              "888         0       3  29.699118      1      2  23.4500       1     0  0  0  1\n",
              "889         1       1  26.000000      0      0  30.0000       0     1  1  0  0\n",
              "890         0       3  32.000000      0      0   7.7500       0     1  0  1  0\n",
              "\n",
              "[889 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3ThKJ9WXQQ6y",
        "colab_type": "code",
        "outputId": "4a05dfad-5e3f-4460-a125-12e7955bda6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X = final.drop(['Survived'],axis= 'columns')\n",
        "Y = final[['Survived']]\n",
        "\n",
        "# encode = LabelEncoder()\n",
        "print('Original Features: \\n',list(X.columns),'\\n')\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Features: \n",
            " ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'female', 'male', 'C', 'Q', 'S'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIocV-2Ff72v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebaebc38-f701-4bb7-b21d-f0a9a16e61a8"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(889, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIhdb8bIQJHE",
        "colab_type": "text"
      },
      "source": [
        "# XGBClassifier training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rfL-WR3yQQ62",
        "colab_type": "code",
        "outputId": "54b6f0bf-4b03-4694-81f3-fc71034cfa20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "#Normalizing X\n",
        "cols = []\n",
        "count = 1\n",
        "for column in X.columns:\n",
        "    if column == 'Human Resources':\n",
        "        cols.append(f'Human Resources{count}')\n",
        "        count+=1\n",
        "        continue\n",
        "    cols.append(column)\n",
        "X.columns = cols\n",
        "\n",
        "x = X.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(X)\n",
        "X = pd.DataFrame(x_scaled)\n",
        "\n",
        "# display(X)\n",
        "# split data into train and test sets\n",
        "seed = 7\n",
        "test_size = 0.33\n",
        "X_train, X_test0, y_train, y_test0 = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "X_test, X_test1, y_test, y_test1 = train_test_split(X_test0, y_test0, test_size=0.2, random_state=seed)\n",
        "\n",
        "# # fit model no training data For XGBoost\n",
        "\n",
        "\n",
        "classifier = XGBClassifier(\n",
        " learning_rate =0.1,\n",
        " n_estimators=10000,\n",
        " max_depth=25,\n",
        " min_child_weight=1,\n",
        " gamma=0,\n",
        " subsample=0.8,\n",
        " colsample_bytree=0.8,\n",
        " objective= 'binary:logistic',\n",
        " nthread=4,\n",
        " scale_pos_weight=1,\n",
        " seed=7)\n",
        "classifier.fit(X_train,y_train)\n",
        "\n",
        "y_predXG = classifier.predict(X_test)\n",
        "predictionsXG = [round(value) for value in y_predXG]\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, predictionsXG)\n",
        "print(classification_report(y_test, predictionsXG))\n",
        "print(confusion_matrix(y_test, predictionsXG))\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "print(predictionsXG)\n",
        "display(y_predXG)\n",
        "\n",
        "print(\"\\n \\n \\n\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.85       141\n",
            "           1       0.79      0.71      0.75        94\n",
            "\n",
            "    accuracy                           0.81       235\n",
            "   macro avg       0.80      0.79      0.80       235\n",
            "weighted avg       0.81      0.81      0.81       235\n",
            "\n",
            "[[123  18]\n",
            " [ 27  67]]\n",
            "Accuracy: 80.85%\n",
            "[1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1W5eRWcOQeRK",
        "colab_type": "text"
      },
      "source": [
        "# Logistic regression training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjYSLs8TQYog",
        "colab_type": "code",
        "outputId": "3cce5a19-ec32-4d5c-cd72-678735b3a4e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "#Now the model of Logistic regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        " \n",
        "\n",
        "logmodel = LogisticRegression()\n",
        "logmodel.fit(X_train, y_train)\n",
        " \n",
        "predictionsLR = logmodel.predict(X_test)\n",
        "print(classification_report(y_test, predictionsLR))\n",
        "print(confusion_matrix(y_test, predictionsLR))\n",
        "print('Accuracy :',end=\" \")\n",
        "print(accuracy_score(y_test, predictionsLR)*100)\n",
        "display(predictionsLR)\n",
        "print(\"\\n \\n \\n\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.82      0.80       141\n",
            "           1       0.71      0.67      0.69        94\n",
            "\n",
            "    accuracy                           0.76       235\n",
            "   macro avg       0.75      0.74      0.74       235\n",
            "weighted avg       0.76      0.76      0.76       235\n",
            "\n",
            "[[115  26]\n",
            " [ 31  63]]\n",
            "Accuracy : 75.74468085106383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWK3-MfLQkFy",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJtUZcu_OK5P",
        "colab_type": "code",
        "outputId": "873aec0e-270c-451b-f070-7e40d76d1046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Now using Random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42,max_depth=100)\n",
        "# Train the model on training data\n",
        "rf.fit(X_train, y_train);\n",
        "\n",
        "\n",
        "predictionsRF = rf.predict(X_test)\n",
        "#Import scikit-learn metrics module for accuracy calculation\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",100*metrics.accuracy_score(y_test, predictionsRF.round()))\n",
        "display(predictionsRF)\n",
        "print(\"\\n \\n \\n\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 84.68085106382979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([7.62697619e-01, 1.00000000e+00, 9.18000000e-01, 1.75000000e-01,\n",
              "       7.06000000e-01, 1.00000000e+00, 7.45000000e-01, 4.46333333e-02,\n",
              "       7.25283333e-01, 6.72309524e-02, 9.20000000e-02, 1.00000000e+00,\n",
              "       0.00000000e+00, 3.75583333e-01, 6.77000000e-01, 8.08000000e-01,\n",
              "       8.40000000e-02, 2.11565476e-01, 8.00000000e-02, 9.03333333e-02,\n",
              "       1.72500000e-02, 9.16000000e-01, 4.73000000e-01, 3.10000000e-02,\n",
              "       2.69000000e-01, 1.28866667e-01, 1.92000000e-01, 1.54000000e-01,\n",
              "       8.11000000e-01, 3.56666667e-02, 8.60166667e-01, 9.72000000e-01,\n",
              "       3.71166667e-01, 1.00000000e-03, 6.00000000e-03, 6.13500000e-01,\n",
              "       8.18566667e-01, 7.00000000e-03, 5.00000000e-03, 1.34411905e-01,\n",
              "       9.83833333e-01, 5.08000000e-01, 0.00000000e+00, 0.00000000e+00,\n",
              "       3.41333333e-01, 5.10000000e-02, 0.00000000e+00, 9.83000000e-01,\n",
              "       2.91000000e-01, 3.33061905e-01, 1.30000000e-01, 1.06000000e-01,\n",
              "       1.30000000e-02, 8.70000000e-01, 2.80000000e-02, 1.28783333e-01,\n",
              "       7.50000000e-04, 0.00000000e+00, 8.74516667e-01, 2.04000000e-01,\n",
              "       3.87166667e-02, 9.48000000e-01, 6.50000000e-01, 1.06000000e-01,\n",
              "       1.70000000e-02, 3.64000000e-01, 5.12466667e-01, 5.02000000e-01,\n",
              "       2.50000000e-02, 4.20000000e-02, 1.92500000e-01, 6.41083333e-01,\n",
              "       2.11000000e-01, 2.18000000e-01, 4.40000000e-02, 9.50033333e-01,\n",
              "       9.98000000e-01, 9.44000000e-01, 5.80000000e-02, 5.64000000e-01,\n",
              "       4.00000000e-02, 0.00000000e+00, 3.13000000e-01, 0.00000000e+00,\n",
              "       9.10531746e-02, 1.00000000e+00, 1.00000000e+00, 8.89050000e-01,\n",
              "       4.90000000e-02, 1.80000000e-02, 5.00000000e-04, 9.97000000e-01,\n",
              "       5.98000000e-01, 5.45000000e-01, 9.97000000e-01, 3.31511905e-01,\n",
              "       4.10000000e-02, 6.57000000e-01, 2.84000000e-01, 2.28300000e-01,\n",
              "       7.64238095e-02, 3.10000000e-02, 2.60000000e-02, 8.92000000e-01,\n",
              "       9.99000000e-01, 9.93000000e-01, 7.78000000e-01, 1.70000000e-02,\n",
              "       7.91991667e-01, 2.49063237e-01, 1.66266667e-01, 9.28000000e-01,\n",
              "       5.63000000e-01, 4.20000000e-01, 7.90000000e-02, 9.99000000e-01,\n",
              "       9.97000000e-01, 6.65316667e-01, 2.54389030e-01, 9.19000000e-01,\n",
              "       3.16000000e-01, 2.81000000e-01, 1.14023810e-02, 2.50000000e-01,\n",
              "       6.85000000e-01, 7.00000000e-03, 3.00000000e-03, 5.55000000e-01,\n",
              "       3.00000000e-03, 3.20000000e-02, 0.00000000e+00, 6.00000000e-01,\n",
              "       9.17000000e-01, 0.00000000e+00, 1.43333333e-02, 8.88166667e-01,\n",
              "       4.65184524e-01, 8.39000000e-01, 1.68000000e-01, 1.66850000e-01,\n",
              "       2.13000000e-01, 9.95916667e-01, 9.66966667e-01, 1.25214286e-02,\n",
              "       1.02000000e-01, 1.74000000e-01, 3.00000000e-03, 9.54000000e-01,\n",
              "       4.43000000e-01, 3.00000000e-03, 7.78000000e-01, 3.66666667e-03,\n",
              "       7.70000000e-02, 1.00000000e-03, 2.64000000e-01, 2.81000000e-01,\n",
              "       9.58000000e-01, 2.80166667e-02, 9.64000000e-01, 4.10000000e-01,\n",
              "       4.72000000e-01, 8.73666667e-01, 9.70000000e-02, 1.00000000e-03,\n",
              "       9.50000000e-02, 1.65333333e-01, 2.42000000e-01, 2.54389030e-01,\n",
              "       9.84000000e-01, 4.20600000e-01, 4.52000000e-01, 9.13666667e-01,\n",
              "       1.61516667e-01, 1.00000000e-03, 3.31511905e-01, 5.85642857e-02,\n",
              "       5.84000000e-01, 9.74166667e-01, 2.78000000e-01, 2.08916667e-02,\n",
              "       9.97000000e-01, 1.00000000e-03, 2.53333333e-01, 5.63000000e-01,\n",
              "       2.70000000e-02, 1.30000000e-02, 5.51016667e-01, 1.12000000e-01,\n",
              "       1.09000000e-01, 1.42000000e-01, 1.45449206e-01, 8.04000000e-01,\n",
              "       8.25666667e-01, 9.48000000e-01, 4.10000000e-02, 7.56000000e-01,\n",
              "       1.00000000e+00, 2.02000000e-01, 5.02000000e-01, 9.67000000e-01,\n",
              "       1.00000000e+00, 6.63000000e-01, 7.02000000e-01, 1.00000000e-03,\n",
              "       5.89000000e-01, 5.78000000e-01, 5.00000000e-03, 2.80000000e-02,\n",
              "       1.00000000e+00, 9.97000000e-01, 9.83000000e-01, 2.36000000e-01,\n",
              "       7.06904762e-03, 9.68000000e-01, 9.60000000e-02, 1.02600000e-01,\n",
              "       5.94402597e-02, 2.30000000e-02, 7.70000000e-02, 4.50000000e-02,\n",
              "       9.99000000e-01, 3.69003571e-01, 4.73000000e-01, 1.28152381e-01,\n",
              "       6.11000000e-01, 2.80166667e-02, 2.76000000e-01, 8.70000000e-02,\n",
              "       2.00000000e-02, 3.03000000e-01, 1.50000000e-02, 2.10000000e-02,\n",
              "       5.08000000e-01, 0.00000000e+00, 8.20000000e-02])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1oZfmqLQny3",
        "colab_type": "text"
      },
      "source": [
        "# SVM Classifier training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfmS9CPzPFw0",
        "colab_type": "code",
        "outputId": "7f227bde-ad42-40f3-f697-d66c5ae6775a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# Now using SVM Classifier\n",
        "from sklearn.svm import SVC\n",
        "svclassifier = SVC(kernel='linear')\n",
        "svclassifier.fit(X_train, y_train)\n",
        "\n",
        "y_predSVM = svclassifier.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test,y_predSVM))\n",
        "print(classification_report(y_test,y_predSVM))\n",
        "print('Accuracy :',end=\" \")\n",
        "print(accuracy_score(y_test, predictionsLR)*100)\n",
        "display(y_predSVM)\n",
        "print(\"\\n \\n \\n\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[113  28]\n",
            " [ 29  65]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80       141\n",
            "           1       0.70      0.69      0.70        94\n",
            "\n",
            "    accuracy                           0.76       235\n",
            "   macro avg       0.75      0.75      0.75       235\n",
            "weighted avg       0.76      0.76      0.76       235\n",
            "\n",
            "Accuracy : 75.74468085106383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrC69JvAQq3w",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpsRhPVgRPSo",
        "colab_type": "code",
        "outputId": "7176e9d6-25ff-44b1-b527-b774abc73467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "\n",
        "#Initializing Neural Network\n",
        "classifierNN = Sequential()\n",
        "classifierNN.add(Dense(15, input_dim = 10, activation = 'relu'))\n",
        "classifierNN.add(Dense(5, activation = 'relu'))\n",
        "classifierNN.add(Dense(8, activation = 'relu'))\n",
        "classifierNN.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "# Compiling Neural Network\n",
        "classifierNN.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Training our Model\n",
        "#for i in range(0,9):\n",
        "#  for j in range(0,888):\n",
        "#    if X_train.iloc[j,i] < 0.5:\n",
        "#      X_train.iloc[j,i] = -1\n",
        "classifierNN.fit(X_train, y_train, batch_size = 10, epochs = 1000)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_predNN = classifierNN.predict(X_test)\n",
        "y_predNN = y_predNN.round()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_predNN)\n",
        "print(cm)\n",
        "print(classification_report(y_test,y_predNN))\n",
        "print('Accuracy :',end=\" \")\n",
        "print(accuracy_score(y_test, y_predNN)*100)\n",
        "# display(y_predNN)\n",
        "\n",
        "\n",
        "print('\\n\\n\\n')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6748 - accuracy: 0.7328\n",
            "Epoch 2/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.7277\n",
            "Epoch 3/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.7445\n",
            "Epoch 4/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.7815\n",
            "Epoch 5/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5503 - accuracy: 0.7832\n",
            "Epoch 6/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7983\n",
            "Epoch 7/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.5012 - accuracy: 0.8034\n",
            "Epoch 8/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.8000\n",
            "Epoch 9/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.8067\n",
            "Epoch 10/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.8168\n",
            "Epoch 11/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.8118\n",
            "Epoch 12/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.8050\n",
            "Epoch 13/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8134\n",
            "Epoch 14/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.8067\n",
            "Epoch 15/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.8168\n",
            "Epoch 16/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8084\n",
            "Epoch 17/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.8118\n",
            "Epoch 18/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.8168\n",
            "Epoch 19/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8185\n",
            "Epoch 20/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.8185\n",
            "Epoch 21/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.8134\n",
            "Epoch 22/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.8118\n",
            "Epoch 23/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.8185\n",
            "Epoch 24/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4322 - accuracy: 0.8218\n",
            "Epoch 25/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.8118\n",
            "Epoch 26/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.8202\n",
            "Epoch 27/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.8185\n",
            "Epoch 28/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.8202\n",
            "Epoch 29/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.8168\n",
            "Epoch 30/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.8168\n",
            "Epoch 31/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.8218\n",
            "Epoch 32/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.8202\n",
            "Epoch 33/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.8168\n",
            "Epoch 34/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.8185\n",
            "Epoch 35/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.8202\n",
            "Epoch 36/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.8218\n",
            "Epoch 37/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.8185\n",
            "Epoch 38/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8185\n",
            "Epoch 39/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.8218\n",
            "Epoch 40/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.8185\n",
            "Epoch 41/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.8269\n",
            "Epoch 42/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.8235\n",
            "Epoch 43/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8252\n",
            "Epoch 44/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.8235\n",
            "Epoch 45/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.8286\n",
            "Epoch 46/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8269\n",
            "Epoch 47/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.8286\n",
            "Epoch 48/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8218\n",
            "Epoch 49/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4210 - accuracy: 0.8286\n",
            "Epoch 50/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8235\n",
            "Epoch 51/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4189 - accuracy: 0.8235\n",
            "Epoch 52/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.8319\n",
            "Epoch 53/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.8319\n",
            "Epoch 54/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4181 - accuracy: 0.8319\n",
            "Epoch 55/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4158 - accuracy: 0.8269\n",
            "Epoch 56/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8286\n",
            "Epoch 57/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4159 - accuracy: 0.8286\n",
            "Epoch 58/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8303\n",
            "Epoch 59/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.8319\n",
            "Epoch 60/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8252\n",
            "Epoch 61/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8353\n",
            "Epoch 62/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.8370\n",
            "Epoch 63/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8252\n",
            "Epoch 64/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4116 - accuracy: 0.8370\n",
            "Epoch 65/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4106 - accuracy: 0.8353\n",
            "Epoch 66/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8336\n",
            "Epoch 67/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4110 - accuracy: 0.8269\n",
            "Epoch 68/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4104 - accuracy: 0.8235\n",
            "Epoch 69/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4093 - accuracy: 0.8370\n",
            "Epoch 70/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4096 - accuracy: 0.8303\n",
            "Epoch 71/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4079 - accuracy: 0.8303\n",
            "Epoch 72/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4077 - accuracy: 0.8336\n",
            "Epoch 73/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4119 - accuracy: 0.8235\n",
            "Epoch 74/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4082 - accuracy: 0.8303\n",
            "Epoch 75/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4065 - accuracy: 0.8319\n",
            "Epoch 76/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4063 - accuracy: 0.8353\n",
            "Epoch 77/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8303\n",
            "Epoch 78/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4050 - accuracy: 0.8370\n",
            "Epoch 79/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.8319\n",
            "Epoch 80/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4049 - accuracy: 0.8336\n",
            "Epoch 81/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4041 - accuracy: 0.8319\n",
            "Epoch 82/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4041 - accuracy: 0.8336\n",
            "Epoch 83/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4052 - accuracy: 0.8303\n",
            "Epoch 84/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4043 - accuracy: 0.8336\n",
            "Epoch 85/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4028 - accuracy: 0.8336\n",
            "Epoch 86/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8353\n",
            "Epoch 87/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8319\n",
            "Epoch 88/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4027 - accuracy: 0.8336\n",
            "Epoch 89/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4013 - accuracy: 0.8336\n",
            "Epoch 90/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4027 - accuracy: 0.8286\n",
            "Epoch 91/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 0.8319\n",
            "Epoch 92/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4042 - accuracy: 0.8286\n",
            "Epoch 93/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4033 - accuracy: 0.8235\n",
            "Epoch 94/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4001 - accuracy: 0.8336\n",
            "Epoch 95/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4051 - accuracy: 0.8303\n",
            "Epoch 96/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3995 - accuracy: 0.8269\n",
            "Epoch 97/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.8353\n",
            "Epoch 98/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4014 - accuracy: 0.8286\n",
            "Epoch 99/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3988 - accuracy: 0.8319\n",
            "Epoch 100/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3983 - accuracy: 0.8370\n",
            "Epoch 101/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3998 - accuracy: 0.8336\n",
            "Epoch 102/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.4011 - accuracy: 0.8370\n",
            "Epoch 103/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3972 - accuracy: 0.8303\n",
            "Epoch 104/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3971 - accuracy: 0.8353\n",
            "Epoch 105/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3978 - accuracy: 0.8336\n",
            "Epoch 106/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8319\n",
            "Epoch 107/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8370\n",
            "Epoch 108/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3964 - accuracy: 0.8319\n",
            "Epoch 109/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3967 - accuracy: 0.8303\n",
            "Epoch 110/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8336\n",
            "Epoch 111/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.8403\n",
            "Epoch 112/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.8303\n",
            "Epoch 113/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8370\n",
            "Epoch 114/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8319\n",
            "Epoch 115/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3951 - accuracy: 0.8370\n",
            "Epoch 116/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3956 - accuracy: 0.8336\n",
            "Epoch 117/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3940 - accuracy: 0.8319\n",
            "Epoch 118/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8387\n",
            "Epoch 119/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3958 - accuracy: 0.8252\n",
            "Epoch 120/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3948 - accuracy: 0.8319\n",
            "Epoch 121/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3940 - accuracy: 0.8303\n",
            "Epoch 122/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3968 - accuracy: 0.8286\n",
            "Epoch 123/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8420\n",
            "Epoch 124/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8353\n",
            "Epoch 125/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8353\n",
            "Epoch 126/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3935 - accuracy: 0.8387\n",
            "Epoch 127/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8319\n",
            "Epoch 128/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3931 - accuracy: 0.8353\n",
            "Epoch 129/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.8370\n",
            "Epoch 130/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3916 - accuracy: 0.8336\n",
            "Epoch 131/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3929 - accuracy: 0.8353\n",
            "Epoch 132/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3915 - accuracy: 0.8370\n",
            "Epoch 133/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3921 - accuracy: 0.8319\n",
            "Epoch 134/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8286\n",
            "Epoch 135/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3925 - accuracy: 0.8319\n",
            "Epoch 136/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3908 - accuracy: 0.8336\n",
            "Epoch 137/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3905 - accuracy: 0.8387\n",
            "Epoch 138/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8353\n",
            "Epoch 139/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8336\n",
            "Epoch 140/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3908 - accuracy: 0.8336\n",
            "Epoch 141/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3894 - accuracy: 0.8353\n",
            "Epoch 142/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.8387\n",
            "Epoch 143/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.8336\n",
            "Epoch 144/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3895 - accuracy: 0.8387\n",
            "Epoch 145/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8387\n",
            "Epoch 146/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8353\n",
            "Epoch 147/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3882 - accuracy: 0.8353\n",
            "Epoch 148/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3883 - accuracy: 0.8387\n",
            "Epoch 149/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8370\n",
            "Epoch 150/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8420\n",
            "Epoch 151/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3866 - accuracy: 0.8387\n",
            "Epoch 152/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8370\n",
            "Epoch 153/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3887 - accuracy: 0.8336\n",
            "Epoch 154/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.8387\n",
            "Epoch 155/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3891 - accuracy: 0.8336\n",
            "Epoch 156/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8387\n",
            "Epoch 157/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8286\n",
            "Epoch 158/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3871 - accuracy: 0.8387\n",
            "Epoch 159/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.8370\n",
            "Epoch 160/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8387\n",
            "Epoch 161/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3855 - accuracy: 0.8420\n",
            "Epoch 162/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3855 - accuracy: 0.8353\n",
            "Epoch 163/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8403\n",
            "Epoch 164/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3863 - accuracy: 0.8353\n",
            "Epoch 165/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3853 - accuracy: 0.8403\n",
            "Epoch 166/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.8370\n",
            "Epoch 167/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8353\n",
            "Epoch 168/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.8353\n",
            "Epoch 169/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3842 - accuracy: 0.8403\n",
            "Epoch 170/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8403\n",
            "Epoch 171/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3850 - accuracy: 0.8387\n",
            "Epoch 172/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3835 - accuracy: 0.8454\n",
            "Epoch 173/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3835 - accuracy: 0.8403\n",
            "Epoch 174/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3837 - accuracy: 0.8319\n",
            "Epoch 175/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8387\n",
            "Epoch 176/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8370\n",
            "Epoch 177/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8303\n",
            "Epoch 178/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8370\n",
            "Epoch 179/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3835 - accuracy: 0.8387\n",
            "Epoch 180/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3821 - accuracy: 0.8370\n",
            "Epoch 181/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8370\n",
            "Epoch 182/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.8387\n",
            "Epoch 183/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8403\n",
            "Epoch 184/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8319\n",
            "Epoch 185/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8403\n",
            "Epoch 186/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8387\n",
            "Epoch 187/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8403\n",
            "Epoch 188/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.8403\n",
            "Epoch 189/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8336\n",
            "Epoch 190/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3802 - accuracy: 0.8387\n",
            "Epoch 191/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8353\n",
            "Epoch 192/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3830 - accuracy: 0.8353\n",
            "Epoch 193/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8353\n",
            "Epoch 194/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3802 - accuracy: 0.8353\n",
            "Epoch 195/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3782 - accuracy: 0.8387\n",
            "Epoch 196/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8370\n",
            "Epoch 197/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8353\n",
            "Epoch 198/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3784 - accuracy: 0.8387\n",
            "Epoch 199/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.8387\n",
            "Epoch 200/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8370\n",
            "Epoch 201/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8403\n",
            "Epoch 202/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3796 - accuracy: 0.8370\n",
            "Epoch 203/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3779 - accuracy: 0.8370\n",
            "Epoch 204/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3798 - accuracy: 0.8370\n",
            "Epoch 205/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3776 - accuracy: 0.8387\n",
            "Epoch 206/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3772 - accuracy: 0.8403\n",
            "Epoch 207/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3801 - accuracy: 0.8403\n",
            "Epoch 208/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8387\n",
            "Epoch 209/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8403\n",
            "Epoch 210/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3773 - accuracy: 0.8353\n",
            "Epoch 211/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8336\n",
            "Epoch 212/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3788 - accuracy: 0.8403\n",
            "Epoch 213/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8370\n",
            "Epoch 214/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8420\n",
            "Epoch 215/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8370\n",
            "Epoch 216/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8403\n",
            "Epoch 217/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8370\n",
            "Epoch 218/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3778 - accuracy: 0.8387\n",
            "Epoch 219/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8387\n",
            "Epoch 220/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3745 - accuracy: 0.8420\n",
            "Epoch 221/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3769 - accuracy: 0.8420\n",
            "Epoch 222/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8387\n",
            "Epoch 223/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8387\n",
            "Epoch 224/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8403\n",
            "Epoch 225/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8437\n",
            "Epoch 226/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8353\n",
            "Epoch 227/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8420\n",
            "Epoch 228/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8370\n",
            "Epoch 229/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8420\n",
            "Epoch 230/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8387\n",
            "Epoch 231/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8387\n",
            "Epoch 232/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8370\n",
            "Epoch 233/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3733 - accuracy: 0.8420\n",
            "Epoch 234/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3737 - accuracy: 0.8353\n",
            "Epoch 235/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3776 - accuracy: 0.8370\n",
            "Epoch 236/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8420\n",
            "Epoch 237/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3742 - accuracy: 0.8387\n",
            "Epoch 238/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3742 - accuracy: 0.8370\n",
            "Epoch 239/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8420\n",
            "Epoch 240/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8471\n",
            "Epoch 241/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3729 - accuracy: 0.8420\n",
            "Epoch 242/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8437\n",
            "Epoch 243/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8420\n",
            "Epoch 244/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3754 - accuracy: 0.8387\n",
            "Epoch 245/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3736 - accuracy: 0.8420\n",
            "Epoch 246/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3748 - accuracy: 0.8403\n",
            "Epoch 247/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3804 - accuracy: 0.8387\n",
            "Epoch 248/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8437\n",
            "Epoch 249/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8420\n",
            "Epoch 250/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3738 - accuracy: 0.8420\n",
            "Epoch 251/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8454\n",
            "Epoch 252/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8403\n",
            "Epoch 253/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8403\n",
            "Epoch 254/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3719 - accuracy: 0.8437\n",
            "Epoch 255/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8420\n",
            "Epoch 256/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8387\n",
            "Epoch 257/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8420\n",
            "Epoch 258/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3711 - accuracy: 0.8454\n",
            "Epoch 259/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3713 - accuracy: 0.8403\n",
            "Epoch 260/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3724 - accuracy: 0.8403\n",
            "Epoch 261/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8437\n",
            "Epoch 262/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8403\n",
            "Epoch 263/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8420\n",
            "Epoch 264/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3735 - accuracy: 0.8437\n",
            "Epoch 265/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8437\n",
            "Epoch 266/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3739 - accuracy: 0.8387\n",
            "Epoch 267/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8454\n",
            "Epoch 268/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8403\n",
            "Epoch 269/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8437\n",
            "Epoch 270/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3729 - accuracy: 0.8437\n",
            "Epoch 271/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8454\n",
            "Epoch 272/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8420\n",
            "Epoch 273/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3713 - accuracy: 0.8437\n",
            "Epoch 274/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3707 - accuracy: 0.8420\n",
            "Epoch 275/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3750 - accuracy: 0.8403\n",
            "Epoch 276/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3717 - accuracy: 0.8420\n",
            "Epoch 277/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8420\n",
            "Epoch 278/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3712 - accuracy: 0.8420\n",
            "Epoch 279/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3706 - accuracy: 0.8420\n",
            "Epoch 280/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8437\n",
            "Epoch 281/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8353\n",
            "Epoch 282/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8437\n",
            "Epoch 283/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8420\n",
            "Epoch 284/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8437\n",
            "Epoch 285/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8420\n",
            "Epoch 286/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3718 - accuracy: 0.8387\n",
            "Epoch 287/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8387\n",
            "Epoch 288/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3694 - accuracy: 0.8420\n",
            "Epoch 289/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3726 - accuracy: 0.8387\n",
            "Epoch 290/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8403\n",
            "Epoch 291/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3702 - accuracy: 0.8370\n",
            "Epoch 292/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8387\n",
            "Epoch 293/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8471\n",
            "Epoch 294/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8370\n",
            "Epoch 295/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3693 - accuracy: 0.8454\n",
            "Epoch 296/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8420\n",
            "Epoch 297/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8454\n",
            "Epoch 298/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8454\n",
            "Epoch 299/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8403\n",
            "Epoch 300/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3740 - accuracy: 0.8471\n",
            "Epoch 301/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8454\n",
            "Epoch 302/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8403\n",
            "Epoch 303/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.8387\n",
            "Epoch 304/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8437\n",
            "Epoch 305/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8437\n",
            "Epoch 306/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8420\n",
            "Epoch 307/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3705 - accuracy: 0.8403\n",
            "Epoch 308/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3723 - accuracy: 0.8420\n",
            "Epoch 309/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8437\n",
            "Epoch 310/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8437\n",
            "Epoch 311/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3698 - accuracy: 0.8420\n",
            "Epoch 312/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8403\n",
            "Epoch 313/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8487\n",
            "Epoch 314/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3684 - accuracy: 0.8454\n",
            "Epoch 315/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8387\n",
            "Epoch 316/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8403\n",
            "Epoch 317/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8420\n",
            "Epoch 318/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8403\n",
            "Epoch 319/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8454\n",
            "Epoch 320/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8437\n",
            "Epoch 321/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8387\n",
            "Epoch 322/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3699 - accuracy: 0.8403\n",
            "Epoch 323/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8454\n",
            "Epoch 324/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3659 - accuracy: 0.8420\n",
            "Epoch 325/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8420\n",
            "Epoch 326/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8420\n",
            "Epoch 327/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3671 - accuracy: 0.8403\n",
            "Epoch 328/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8370\n",
            "Epoch 329/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8454\n",
            "Epoch 330/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8370\n",
            "Epoch 331/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3668 - accuracy: 0.8420\n",
            "Epoch 332/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3668 - accuracy: 0.8454\n",
            "Epoch 333/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3661 - accuracy: 0.8437\n",
            "Epoch 334/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8403\n",
            "Epoch 335/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8403\n",
            "Epoch 336/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8437\n",
            "Epoch 337/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.8437\n",
            "Epoch 338/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8437\n",
            "Epoch 339/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8420\n",
            "Epoch 340/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3696 - accuracy: 0.8437\n",
            "Epoch 341/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3677 - accuracy: 0.8403\n",
            "Epoch 342/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3636 - accuracy: 0.8487\n",
            "Epoch 343/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3679 - accuracy: 0.8420\n",
            "Epoch 344/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3664 - accuracy: 0.8437\n",
            "Epoch 345/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8403\n",
            "Epoch 346/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3664 - accuracy: 0.8403\n",
            "Epoch 347/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3678 - accuracy: 0.8437\n",
            "Epoch 348/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8387\n",
            "Epoch 349/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8403\n",
            "Epoch 350/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3658 - accuracy: 0.8420\n",
            "Epoch 351/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3651 - accuracy: 0.8437\n",
            "Epoch 352/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8420\n",
            "Epoch 353/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.8420\n",
            "Epoch 354/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8471\n",
            "Epoch 355/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3669 - accuracy: 0.8437\n",
            "Epoch 356/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8336\n",
            "Epoch 357/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3647 - accuracy: 0.8420\n",
            "Epoch 358/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8454\n",
            "Epoch 359/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8420\n",
            "Epoch 360/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3660 - accuracy: 0.8437\n",
            "Epoch 361/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3670 - accuracy: 0.8420\n",
            "Epoch 362/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.8437\n",
            "Epoch 363/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8437\n",
            "Epoch 364/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8454\n",
            "Epoch 365/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3648 - accuracy: 0.8437\n",
            "Epoch 366/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3645 - accuracy: 0.8454\n",
            "Epoch 367/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8437\n",
            "Epoch 368/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8420\n",
            "Epoch 369/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8437\n",
            "Epoch 370/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8420\n",
            "Epoch 371/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3659 - accuracy: 0.8437\n",
            "Epoch 372/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3635 - accuracy: 0.8420\n",
            "Epoch 373/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3652 - accuracy: 0.8403\n",
            "Epoch 374/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.8437\n",
            "Epoch 375/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8454\n",
            "Epoch 376/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8420\n",
            "Epoch 377/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3659 - accuracy: 0.8420\n",
            "Epoch 378/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8420\n",
            "Epoch 379/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8437\n",
            "Epoch 380/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8437\n",
            "Epoch 381/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8387\n",
            "Epoch 382/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3644 - accuracy: 0.8471\n",
            "Epoch 383/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3642 - accuracy: 0.8420\n",
            "Epoch 384/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8437\n",
            "Epoch 385/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8454\n",
            "Epoch 386/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3624 - accuracy: 0.8471\n",
            "Epoch 387/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3621 - accuracy: 0.8471\n",
            "Epoch 388/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.8420\n",
            "Epoch 389/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8487\n",
            "Epoch 390/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3614 - accuracy: 0.8487\n",
            "Epoch 391/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8437\n",
            "Epoch 392/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8454\n",
            "Epoch 393/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8437\n",
            "Epoch 394/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3611 - accuracy: 0.8403\n",
            "Epoch 395/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8487\n",
            "Epoch 396/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8437\n",
            "Epoch 397/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8454\n",
            "Epoch 398/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8454\n",
            "Epoch 399/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.8471\n",
            "Epoch 400/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8454\n",
            "Epoch 401/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8504\n",
            "Epoch 402/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3634 - accuracy: 0.8471\n",
            "Epoch 403/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8504\n",
            "Epoch 404/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3616 - accuracy: 0.8487\n",
            "Epoch 405/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8420\n",
            "Epoch 406/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8437\n",
            "Epoch 407/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8437\n",
            "Epoch 408/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3595 - accuracy: 0.8471\n",
            "Epoch 409/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8487\n",
            "Epoch 410/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8487\n",
            "Epoch 411/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3631 - accuracy: 0.8420\n",
            "Epoch 412/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8403\n",
            "Epoch 413/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3591 - accuracy: 0.8454\n",
            "Epoch 414/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8454\n",
            "Epoch 415/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3619 - accuracy: 0.8437\n",
            "Epoch 416/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8437\n",
            "Epoch 417/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3601 - accuracy: 0.8454\n",
            "Epoch 418/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8454\n",
            "Epoch 419/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8437\n",
            "Epoch 420/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8471\n",
            "Epoch 421/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3604 - accuracy: 0.8454\n",
            "Epoch 422/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8437\n",
            "Epoch 423/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3637 - accuracy: 0.8403\n",
            "Epoch 424/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8454\n",
            "Epoch 425/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8437\n",
            "Epoch 426/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3644 - accuracy: 0.8487\n",
            "Epoch 427/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3582 - accuracy: 0.8471\n",
            "Epoch 428/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8437\n",
            "Epoch 429/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8437\n",
            "Epoch 430/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8454\n",
            "Epoch 431/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3581 - accuracy: 0.8420\n",
            "Epoch 432/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3596 - accuracy: 0.8437\n",
            "Epoch 433/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3605 - accuracy: 0.8471\n",
            "Epoch 434/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8504\n",
            "Epoch 435/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3565 - accuracy: 0.8454\n",
            "Epoch 436/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3584 - accuracy: 0.8471\n",
            "Epoch 437/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.8471\n",
            "Epoch 438/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8487\n",
            "Epoch 439/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3578 - accuracy: 0.8454\n",
            "Epoch 440/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8504\n",
            "Epoch 441/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.8487\n",
            "Epoch 442/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8454\n",
            "Epoch 443/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3571 - accuracy: 0.8437\n",
            "Epoch 444/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8437\n",
            "Epoch 445/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8454\n",
            "Epoch 446/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.8471\n",
            "Epoch 447/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8437\n",
            "Epoch 448/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8454\n",
            "Epoch 449/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8471\n",
            "Epoch 450/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8437\n",
            "Epoch 451/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3576 - accuracy: 0.8420\n",
            "Epoch 452/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8437\n",
            "Epoch 453/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.8437\n",
            "Epoch 454/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3562 - accuracy: 0.8454\n",
            "Epoch 455/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3615 - accuracy: 0.8454\n",
            "Epoch 456/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8437\n",
            "Epoch 457/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3573 - accuracy: 0.8437\n",
            "Epoch 458/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8454\n",
            "Epoch 459/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3569 - accuracy: 0.8487\n",
            "Epoch 460/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8504\n",
            "Epoch 461/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8454\n",
            "Epoch 462/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.8454\n",
            "Epoch 463/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.8403\n",
            "Epoch 464/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3609 - accuracy: 0.8403\n",
            "Epoch 465/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8420\n",
            "Epoch 466/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3563 - accuracy: 0.8437\n",
            "Epoch 467/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8471\n",
            "Epoch 468/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8420\n",
            "Epoch 469/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8454\n",
            "Epoch 470/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8437\n",
            "Epoch 471/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8454\n",
            "Epoch 472/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8437\n",
            "Epoch 473/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8437\n",
            "Epoch 474/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8437\n",
            "Epoch 475/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8487\n",
            "Epoch 476/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8454\n",
            "Epoch 477/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.8471\n",
            "Epoch 478/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8437\n",
            "Epoch 479/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3533 - accuracy: 0.8471\n",
            "Epoch 480/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3544 - accuracy: 0.8454\n",
            "Epoch 481/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3558 - accuracy: 0.8471\n",
            "Epoch 482/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3558 - accuracy: 0.8454\n",
            "Epoch 483/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3557 - accuracy: 0.8403\n",
            "Epoch 484/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8471\n",
            "Epoch 485/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8420\n",
            "Epoch 486/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.8420\n",
            "Epoch 487/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8437\n",
            "Epoch 488/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8454\n",
            "Epoch 489/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8471\n",
            "Epoch 490/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8437\n",
            "Epoch 491/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8454\n",
            "Epoch 492/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8454\n",
            "Epoch 493/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3548 - accuracy: 0.8437\n",
            "Epoch 494/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8420\n",
            "Epoch 495/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8471\n",
            "Epoch 496/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.8454\n",
            "Epoch 497/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8437\n",
            "Epoch 498/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.8454\n",
            "Epoch 499/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8437\n",
            "Epoch 500/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8437\n",
            "Epoch 501/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3526 - accuracy: 0.8454\n",
            "Epoch 502/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8437\n",
            "Epoch 503/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3534 - accuracy: 0.8387\n",
            "Epoch 504/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8504\n",
            "Epoch 505/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8454\n",
            "Epoch 506/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8454\n",
            "Epoch 507/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8487\n",
            "Epoch 508/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8420\n",
            "Epoch 509/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8437\n",
            "Epoch 510/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8437\n",
            "Epoch 511/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8454\n",
            "Epoch 512/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8454\n",
            "Epoch 513/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8471\n",
            "Epoch 514/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8504\n",
            "Epoch 515/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8454\n",
            "Epoch 516/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3533 - accuracy: 0.8471\n",
            "Epoch 517/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3545 - accuracy: 0.8403\n",
            "Epoch 518/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8437\n",
            "Epoch 519/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3535 - accuracy: 0.8454\n",
            "Epoch 520/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.8454\n",
            "Epoch 521/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8487\n",
            "Epoch 522/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8437\n",
            "Epoch 523/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.8471\n",
            "Epoch 524/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8437\n",
            "Epoch 525/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3508 - accuracy: 0.8471\n",
            "Epoch 526/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3536 - accuracy: 0.8437\n",
            "Epoch 527/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8487\n",
            "Epoch 528/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3530 - accuracy: 0.8437\n",
            "Epoch 529/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3505 - accuracy: 0.8437\n",
            "Epoch 530/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8454\n",
            "Epoch 531/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3516 - accuracy: 0.8454\n",
            "Epoch 532/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3503 - accuracy: 0.8437\n",
            "Epoch 533/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8487\n",
            "Epoch 534/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.8471\n",
            "Epoch 535/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8487\n",
            "Epoch 536/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8403\n",
            "Epoch 537/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8454\n",
            "Epoch 538/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8471\n",
            "Epoch 539/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8336\n",
            "Epoch 540/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8471\n",
            "Epoch 541/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.8504\n",
            "Epoch 542/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3507 - accuracy: 0.8471\n",
            "Epoch 543/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8471\n",
            "Epoch 544/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8487\n",
            "Epoch 545/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.8471\n",
            "Epoch 546/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.8437\n",
            "Epoch 547/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8454\n",
            "Epoch 548/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3496 - accuracy: 0.8504\n",
            "Epoch 549/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8454\n",
            "Epoch 550/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3478 - accuracy: 0.8487\n",
            "Epoch 551/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3531 - accuracy: 0.8454\n",
            "Epoch 552/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3484 - accuracy: 0.8437\n",
            "Epoch 553/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8454\n",
            "Epoch 554/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.8420\n",
            "Epoch 555/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8471\n",
            "Epoch 556/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8437\n",
            "Epoch 557/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8471\n",
            "Epoch 558/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3491 - accuracy: 0.8437\n",
            "Epoch 559/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8454\n",
            "Epoch 560/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8471\n",
            "Epoch 561/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3462 - accuracy: 0.8471\n",
            "Epoch 562/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8437\n",
            "Epoch 563/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3469 - accuracy: 0.8437\n",
            "Epoch 564/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8471\n",
            "Epoch 565/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8454\n",
            "Epoch 566/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3541 - accuracy: 0.8403\n",
            "Epoch 567/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8420\n",
            "Epoch 568/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8471\n",
            "Epoch 569/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8504\n",
            "Epoch 570/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.8437\n",
            "Epoch 571/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.8487\n",
            "Epoch 572/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8454\n",
            "Epoch 573/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3470 - accuracy: 0.8454\n",
            "Epoch 574/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8454\n",
            "Epoch 575/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8454\n",
            "Epoch 576/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8454\n",
            "Epoch 577/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8454\n",
            "Epoch 578/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8471\n",
            "Epoch 579/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8471\n",
            "Epoch 580/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3478 - accuracy: 0.8387\n",
            "Epoch 581/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8370\n",
            "Epoch 582/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8487\n",
            "Epoch 583/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3482 - accuracy: 0.8471\n",
            "Epoch 584/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3449 - accuracy: 0.8420\n",
            "Epoch 585/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8437\n",
            "Epoch 586/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8420\n",
            "Epoch 587/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8471\n",
            "Epoch 588/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8454\n",
            "Epoch 589/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3449 - accuracy: 0.8437\n",
            "Epoch 590/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8420\n",
            "Epoch 591/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8353\n",
            "Epoch 592/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8336\n",
            "Epoch 593/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.8454\n",
            "Epoch 594/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8487\n",
            "Epoch 595/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3473 - accuracy: 0.8454\n",
            "Epoch 596/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3453 - accuracy: 0.8487\n",
            "Epoch 597/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8471\n",
            "Epoch 598/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8454\n",
            "Epoch 599/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3422 - accuracy: 0.8437\n",
            "Epoch 600/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3457 - accuracy: 0.8471\n",
            "Epoch 601/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8454\n",
            "Epoch 602/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8437\n",
            "Epoch 603/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.8504\n",
            "Epoch 604/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8420\n",
            "Epoch 605/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8504\n",
            "Epoch 606/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8353\n",
            "Epoch 607/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8471\n",
            "Epoch 608/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3449 - accuracy: 0.8336\n",
            "Epoch 609/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8420\n",
            "Epoch 610/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8471\n",
            "Epoch 611/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3449 - accuracy: 0.8471\n",
            "Epoch 612/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8269\n",
            "Epoch 613/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8487\n",
            "Epoch 614/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3411 - accuracy: 0.8336\n",
            "Epoch 615/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8437\n",
            "Epoch 616/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8403\n",
            "Epoch 617/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3444 - accuracy: 0.8471\n",
            "Epoch 618/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.8471\n",
            "Epoch 619/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8487\n",
            "Epoch 620/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8437\n",
            "Epoch 621/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8420\n",
            "Epoch 622/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8437\n",
            "Epoch 623/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3461 - accuracy: 0.8454\n",
            "Epoch 624/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3434 - accuracy: 0.8454\n",
            "Epoch 625/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8487\n",
            "Epoch 626/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8471\n",
            "Epoch 627/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8454\n",
            "Epoch 628/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3412 - accuracy: 0.8437\n",
            "Epoch 629/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8454\n",
            "Epoch 630/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8471\n",
            "Epoch 631/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8420\n",
            "Epoch 632/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8437\n",
            "Epoch 633/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8437\n",
            "Epoch 634/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8454\n",
            "Epoch 635/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8487\n",
            "Epoch 636/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8471\n",
            "Epoch 637/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8403\n",
            "Epoch 638/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8521\n",
            "Epoch 639/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8487\n",
            "Epoch 640/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8487\n",
            "Epoch 641/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8487\n",
            "Epoch 642/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8454\n",
            "Epoch 643/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8387\n",
            "Epoch 644/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.8487\n",
            "Epoch 645/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3408 - accuracy: 0.8487\n",
            "Epoch 646/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3389 - accuracy: 0.8454\n",
            "Epoch 647/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8538\n",
            "Epoch 648/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8487\n",
            "Epoch 649/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8353\n",
            "Epoch 650/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8504\n",
            "Epoch 651/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8454\n",
            "Epoch 652/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8504\n",
            "Epoch 653/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8521\n",
            "Epoch 654/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.8487\n",
            "Epoch 655/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8387\n",
            "Epoch 656/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3421 - accuracy: 0.8504\n",
            "Epoch 657/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8487\n",
            "Epoch 658/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8471\n",
            "Epoch 659/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3406 - accuracy: 0.8538\n",
            "Epoch 660/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8521\n",
            "Epoch 661/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8471\n",
            "Epoch 662/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8471\n",
            "Epoch 663/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8487\n",
            "Epoch 664/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8437\n",
            "Epoch 665/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8504\n",
            "Epoch 666/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8487\n",
            "Epoch 667/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8487\n",
            "Epoch 668/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8521\n",
            "Epoch 669/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8487\n",
            "Epoch 670/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8471\n",
            "Epoch 671/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8521\n",
            "Epoch 672/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8471\n",
            "Epoch 673/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3377 - accuracy: 0.8454\n",
            "Epoch 674/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8471\n",
            "Epoch 675/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8487\n",
            "Epoch 676/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8487\n",
            "Epoch 677/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8403\n",
            "Epoch 678/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8538\n",
            "Epoch 679/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8504\n",
            "Epoch 680/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8454\n",
            "Epoch 681/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8454\n",
            "Epoch 682/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8370\n",
            "Epoch 683/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8504\n",
            "Epoch 684/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8555\n",
            "Epoch 685/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8504\n",
            "Epoch 686/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8387\n",
            "Epoch 687/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8521\n",
            "Epoch 688/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8437\n",
            "Epoch 689/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8403\n",
            "Epoch 690/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8471\n",
            "Epoch 691/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8487\n",
            "Epoch 692/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3392 - accuracy: 0.8504\n",
            "Epoch 693/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8437\n",
            "Epoch 694/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8487\n",
            "Epoch 695/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3385 - accuracy: 0.8487\n",
            "Epoch 696/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8471\n",
            "Epoch 697/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8504\n",
            "Epoch 698/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8437\n",
            "Epoch 699/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8403\n",
            "Epoch 700/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8471\n",
            "Epoch 701/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8504\n",
            "Epoch 702/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8487\n",
            "Epoch 703/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8487\n",
            "Epoch 704/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8521\n",
            "Epoch 705/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8471\n",
            "Epoch 706/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8471\n",
            "Epoch 707/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.8454\n",
            "Epoch 708/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8437\n",
            "Epoch 709/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8538\n",
            "Epoch 710/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8471\n",
            "Epoch 711/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8538\n",
            "Epoch 712/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8504\n",
            "Epoch 713/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3356 - accuracy: 0.8420\n",
            "Epoch 714/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3350 - accuracy: 0.8403\n",
            "Epoch 715/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8504\n",
            "Epoch 716/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8521\n",
            "Epoch 717/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8471\n",
            "Epoch 718/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8403\n",
            "Epoch 719/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8454\n",
            "Epoch 720/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3394 - accuracy: 0.8454\n",
            "Epoch 721/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8471\n",
            "Epoch 722/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8353\n",
            "Epoch 723/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8454\n",
            "Epoch 724/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8437\n",
            "Epoch 725/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8504\n",
            "Epoch 726/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8471\n",
            "Epoch 727/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8454\n",
            "Epoch 728/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8487\n",
            "Epoch 729/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8487\n",
            "Epoch 730/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3323 - accuracy: 0.8504\n",
            "Epoch 731/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8403\n",
            "Epoch 732/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8437\n",
            "Epoch 733/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8420\n",
            "Epoch 734/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3391 - accuracy: 0.8471\n",
            "Epoch 735/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8353\n",
            "Epoch 736/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8555\n",
            "Epoch 737/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8504\n",
            "Epoch 738/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8454\n",
            "Epoch 739/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8538\n",
            "Epoch 740/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8471\n",
            "Epoch 741/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3419 - accuracy: 0.8471\n",
            "Epoch 742/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8538\n",
            "Epoch 743/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8487\n",
            "Epoch 744/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8521\n",
            "Epoch 745/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8471\n",
            "Epoch 746/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8538\n",
            "Epoch 747/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8504\n",
            "Epoch 748/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8487\n",
            "Epoch 749/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8454\n",
            "Epoch 750/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8387\n",
            "Epoch 751/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8504\n",
            "Epoch 752/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8487\n",
            "Epoch 753/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8538\n",
            "Epoch 754/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8504\n",
            "Epoch 755/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8521\n",
            "Epoch 756/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8538\n",
            "Epoch 757/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8487\n",
            "Epoch 758/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8487\n",
            "Epoch 759/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8487\n",
            "Epoch 760/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8454\n",
            "Epoch 761/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8538\n",
            "Epoch 762/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8504\n",
            "Epoch 763/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8521\n",
            "Epoch 764/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8504\n",
            "Epoch 765/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8521\n",
            "Epoch 766/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8571\n",
            "Epoch 767/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8471\n",
            "Epoch 768/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8487\n",
            "Epoch 769/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8538\n",
            "Epoch 770/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8521\n",
            "Epoch 771/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8588\n",
            "Epoch 772/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3352 - accuracy: 0.8420\n",
            "Epoch 773/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8487\n",
            "Epoch 774/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8454\n",
            "Epoch 775/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8521\n",
            "Epoch 776/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8487\n",
            "Epoch 777/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8521\n",
            "Epoch 778/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8487\n",
            "Epoch 779/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8353\n",
            "Epoch 780/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8504\n",
            "Epoch 781/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8555\n",
            "Epoch 782/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8521\n",
            "Epoch 783/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8454\n",
            "Epoch 784/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8521\n",
            "Epoch 785/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8454\n",
            "Epoch 786/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8555\n",
            "Epoch 787/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8504\n",
            "Epoch 788/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8487\n",
            "Epoch 789/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8571\n",
            "Epoch 790/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8555\n",
            "Epoch 791/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8538\n",
            "Epoch 792/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8487\n",
            "Epoch 793/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8420\n",
            "Epoch 794/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8454\n",
            "Epoch 795/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8454\n",
            "Epoch 796/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8454\n",
            "Epoch 797/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8555\n",
            "Epoch 798/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8504\n",
            "Epoch 799/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8521\n",
            "Epoch 800/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8504\n",
            "Epoch 801/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8437\n",
            "Epoch 802/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8555\n",
            "Epoch 803/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8471\n",
            "Epoch 804/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8487\n",
            "Epoch 805/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8521\n",
            "Epoch 806/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8538\n",
            "Epoch 807/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8487\n",
            "Epoch 808/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8538\n",
            "Epoch 809/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8538\n",
            "Epoch 810/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8538\n",
            "Epoch 811/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8420\n",
            "Epoch 812/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8521\n",
            "Epoch 813/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8521\n",
            "Epoch 814/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8538\n",
            "Epoch 815/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8555\n",
            "Epoch 816/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8538\n",
            "Epoch 817/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8521\n",
            "Epoch 818/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8538\n",
            "Epoch 819/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8538\n",
            "Epoch 820/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8471\n",
            "Epoch 821/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8538\n",
            "Epoch 822/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8504\n",
            "Epoch 823/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8571\n",
            "Epoch 824/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8521\n",
            "Epoch 825/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8555\n",
            "Epoch 826/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8504\n",
            "Epoch 827/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8521\n",
            "Epoch 828/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8437\n",
            "Epoch 829/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8454\n",
            "Epoch 830/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8521\n",
            "Epoch 831/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8471\n",
            "Epoch 832/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8538\n",
            "Epoch 833/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8521\n",
            "Epoch 834/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8555\n",
            "Epoch 835/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8555\n",
            "Epoch 836/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8319\n",
            "Epoch 837/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8555\n",
            "Epoch 838/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8487\n",
            "Epoch 839/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8555\n",
            "Epoch 840/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8538\n",
            "Epoch 841/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8538\n",
            "Epoch 842/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8571\n",
            "Epoch 843/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8471\n",
            "Epoch 844/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8487\n",
            "Epoch 845/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8571\n",
            "Epoch 846/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8555\n",
            "Epoch 847/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8571\n",
            "Epoch 848/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8521\n",
            "Epoch 849/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8504\n",
            "Epoch 850/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8538\n",
            "Epoch 851/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8437\n",
            "Epoch 852/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8555\n",
            "Epoch 853/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8521\n",
            "Epoch 854/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8504\n",
            "Epoch 855/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8471\n",
            "Epoch 856/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8454\n",
            "Epoch 857/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8571\n",
            "Epoch 858/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8538\n",
            "Epoch 859/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8571\n",
            "Epoch 860/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8538\n",
            "Epoch 861/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8471\n",
            "Epoch 862/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8471\n",
            "Epoch 863/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8555\n",
            "Epoch 864/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8487\n",
            "Epoch 865/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8521\n",
            "Epoch 866/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8622\n",
            "Epoch 867/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8571\n",
            "Epoch 868/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8538\n",
            "Epoch 869/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8504\n",
            "Epoch 870/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8471\n",
            "Epoch 871/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8555\n",
            "Epoch 872/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8454\n",
            "Epoch 873/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8571\n",
            "Epoch 874/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8555\n",
            "Epoch 875/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8538\n",
            "Epoch 876/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8454\n",
            "Epoch 877/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8555\n",
            "Epoch 878/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8571\n",
            "Epoch 879/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8555\n",
            "Epoch 880/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8504\n",
            "Epoch 881/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3254 - accuracy: 0.8538\n",
            "Epoch 882/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8487\n",
            "Epoch 883/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8538\n",
            "Epoch 884/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.8571\n",
            "Epoch 885/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8521\n",
            "Epoch 886/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8454\n",
            "Epoch 887/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8504\n",
            "Epoch 888/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8571\n",
            "Epoch 889/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8504\n",
            "Epoch 890/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8538\n",
            "Epoch 891/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.8538\n",
            "Epoch 892/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8437\n",
            "Epoch 893/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8538\n",
            "Epoch 894/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3281 - accuracy: 0.8403\n",
            "Epoch 895/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8555\n",
            "Epoch 896/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8555\n",
            "Epoch 897/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8555\n",
            "Epoch 898/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.8571\n",
            "Epoch 899/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.8571\n",
            "Epoch 900/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3244 - accuracy: 0.8471\n",
            "Epoch 901/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8555\n",
            "Epoch 902/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8504\n",
            "Epoch 903/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8555\n",
            "Epoch 904/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3252 - accuracy: 0.8538\n",
            "Epoch 905/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8538\n",
            "Epoch 906/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8605\n",
            "Epoch 907/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8605\n",
            "Epoch 908/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8555\n",
            "Epoch 909/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3252 - accuracy: 0.8538\n",
            "Epoch 910/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8521\n",
            "Epoch 911/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8571\n",
            "Epoch 912/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8555\n",
            "Epoch 913/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8571\n",
            "Epoch 914/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3249 - accuracy: 0.8588\n",
            "Epoch 915/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3256 - accuracy: 0.8571\n",
            "Epoch 916/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8571\n",
            "Epoch 917/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3245 - accuracy: 0.8521\n",
            "Epoch 918/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8521\n",
            "Epoch 919/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8538\n",
            "Epoch 920/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8504\n",
            "Epoch 921/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8504\n",
            "Epoch 922/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8538\n",
            "Epoch 923/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3235 - accuracy: 0.8521\n",
            "Epoch 924/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8521\n",
            "Epoch 925/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8588\n",
            "Epoch 926/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8538\n",
            "Epoch 927/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8571\n",
            "Epoch 928/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3248 - accuracy: 0.8471\n",
            "Epoch 929/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8555\n",
            "Epoch 930/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8588\n",
            "Epoch 931/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8471\n",
            "Epoch 932/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.8471\n",
            "Epoch 933/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8403\n",
            "Epoch 934/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8521\n",
            "Epoch 935/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3210 - accuracy: 0.8588\n",
            "Epoch 936/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8555\n",
            "Epoch 937/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3257 - accuracy: 0.8538\n",
            "Epoch 938/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3261 - accuracy: 0.8521\n",
            "Epoch 939/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8454\n",
            "Epoch 940/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8588\n",
            "Epoch 941/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8437\n",
            "Epoch 942/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.8538\n",
            "Epoch 943/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8471\n",
            "Epoch 944/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8504\n",
            "Epoch 945/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3212 - accuracy: 0.8571\n",
            "Epoch 946/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3221 - accuracy: 0.8555\n",
            "Epoch 947/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3230 - accuracy: 0.8521\n",
            "Epoch 948/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3226 - accuracy: 0.8571\n",
            "Epoch 949/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3223 - accuracy: 0.8571\n",
            "Epoch 950/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3212 - accuracy: 0.8588\n",
            "Epoch 951/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3205 - accuracy: 0.8555\n",
            "Epoch 952/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3227 - accuracy: 0.8538\n",
            "Epoch 953/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3207 - accuracy: 0.8538\n",
            "Epoch 954/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8571\n",
            "Epoch 955/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3212 - accuracy: 0.8487\n",
            "Epoch 956/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8471\n",
            "Epoch 957/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3208 - accuracy: 0.8538\n",
            "Epoch 958/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8521\n",
            "Epoch 959/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8521\n",
            "Epoch 960/1000\n",
            "60/60 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8521\n",
            "Epoch 961/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3212 - accuracy: 0.8521\n",
            "Epoch 962/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3208 - accuracy: 0.8571\n",
            "Epoch 963/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8521\n",
            "Epoch 964/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3208 - accuracy: 0.8521\n",
            "Epoch 965/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8571\n",
            "Epoch 966/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3185 - accuracy: 0.8588\n",
            "Epoch 967/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8538\n",
            "Epoch 968/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.8420\n",
            "Epoch 969/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3215 - accuracy: 0.8538\n",
            "Epoch 970/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3227 - accuracy: 0.8588\n",
            "Epoch 971/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3249 - accuracy: 0.8555\n",
            "Epoch 972/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8454\n",
            "Epoch 973/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8471\n",
            "Epoch 974/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3208 - accuracy: 0.8538\n",
            "Epoch 975/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3210 - accuracy: 0.8555\n",
            "Epoch 976/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8555\n",
            "Epoch 977/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3220 - accuracy: 0.8521\n",
            "Epoch 978/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3188 - accuracy: 0.8571\n",
            "Epoch 979/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8605\n",
            "Epoch 980/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3219 - accuracy: 0.8555\n",
            "Epoch 981/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.8588\n",
            "Epoch 982/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.8504\n",
            "Epoch 983/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3247 - accuracy: 0.8521\n",
            "Epoch 984/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3226 - accuracy: 0.8555\n",
            "Epoch 985/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8538\n",
            "Epoch 986/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.8538\n",
            "Epoch 987/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3211 - accuracy: 0.8403\n",
            "Epoch 988/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8521\n",
            "Epoch 989/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3198 - accuracy: 0.8639\n",
            "Epoch 990/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3201 - accuracy: 0.8521\n",
            "Epoch 991/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8487\n",
            "Epoch 992/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3216 - accuracy: 0.8588\n",
            "Epoch 993/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.8571\n",
            "Epoch 994/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3184 - accuracy: 0.8588\n",
            "Epoch 995/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 0.8605\n",
            "Epoch 996/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3229 - accuracy: 0.8521\n",
            "Epoch 997/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3186 - accuracy: 0.8471\n",
            "Epoch 998/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3186 - accuracy: 0.8487\n",
            "Epoch 999/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3173 - accuracy: 0.8588\n",
            "Epoch 1000/1000\n",
            "60/60 [==============================] - 0s 1ms/step - loss: 0.3214 - accuracy: 0.8504\n",
            "[[121  20]\n",
            " [ 32  62]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.86      0.82       141\n",
            "           1       0.76      0.66      0.70        94\n",
            "\n",
            "    accuracy                           0.78       235\n",
            "   macro avg       0.77      0.76      0.76       235\n",
            "weighted avg       0.78      0.78      0.78       235\n",
            "\n",
            "Accuracy : 77.87234042553192\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu9lWVZ_bpwQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predNN = y_predNN[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaFBDAbuU-Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain = pd.DataFrame({'XGBoost': predictionsXG, 'LogisticR': predictionsLR,'RandomF' : predictionsRF,'SVM' : y_predSVM, 'NeuralN' : y_predNN})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzNzQWgYQvqw",
        "colab_type": "text"
      },
      "source": [
        "# Training XGBClassifier on the output of previous classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zO8PL64YR7l",
        "colab_type": "code",
        "outputId": "94f1841c-808d-4fbb-9fbd-16d862deecce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "\n",
        "y_predXG1 = classifier.predict(X_test1)\n",
        "predictionsXG1 = [round(value) for value in y_predXG1]\n",
        "\n",
        "predictionsLR1 = logmodel.predict(X_test1)\n",
        "\n",
        "predictionsRF1 = rf.predict(X_test1)\n",
        "\n",
        "y_predSVM1 = svclassifier.predict(X_test1)\n",
        "\n",
        "# for i in range(0,51):\n",
        "#   for j in range(0,688):\n",
        "#     if X_test1.iloc[j,i] < 0.5:\n",
        "#       X_test1.iloc[j,i] = -1\n",
        "y_predNN1 = classifierNN.predict(X_test1)\n",
        "y_predNN1 = y_predNN1.round()\n",
        "y_predNN1 = y_predNN1[:,0]\n",
        "\n",
        "Xtest1 = pd.DataFrame({'XGBoost': predictionsXG1, 'LogisticR': predictionsLR1,'RandomF' : predictionsRF1,'SVM' : y_predSVM1, 'NeuralN' : y_predNN1})\n",
        "\n",
        "# Finally here we train a XGBClassifier with the output of the previous classifiers \n",
        "classifierF = XGBClassifier()\n",
        "classifierF.fit(Xtrain,y_test)\n",
        "\n",
        "y_predF = classifierF.predict(Xtest1)\n",
        "# predictionsF = [round(value) for value in y_predF]\n",
        "# evaluate predictions\n",
        "# predictionsF = predictionsF[:,0]\n",
        "accuracy = accuracy_score(y_test1, y_predF)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "\n",
        "\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 79.66%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}